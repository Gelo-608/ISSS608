[
  {
    "objectID": "Take home Ex/Take-home_Ex1/Take-home_Ex1.html",
    "href": "Take home Ex/Take-home_Ex1/Take-home_Ex1.html",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "Based on the Ship Performance Clustering Dataset for 2020-2023, this report analyzes the relationship between ship performance indicators and operational efficiency to provide support for optimizing route planning and energy consumption management.\n\n\n\nData covering ship category, speed, fuel consumption, cargo load, maintenance status, sailing distance and other indicators.\n\npacman::p_load(tidyverse,ggrepel, patchwork, ggthemes, hrbrthemes,ggiraph, plotly,readxl, \n               gifski, gapminder,gganimate,HH,corrplot, ggstatsplot,ggExtra,FunnelPlotR, knitr,\n               ggdist, ggridges,colorspace,crosstalk, DT,SmartEDA,easystats, tidymodels,ggtern,\n               seriation, dendextend, heatmaply,GGally, parallelPlot\n               )\n\n\n\n\n\nlibrary(tidyverse,haven)\nship_data &lt;- read_csv(\"/Users/geloliu/Gelo-608/ISSS608/Take home Ex/Take-home_Ex1/data/Ship_Performance_Dataset.csv\")\n\n\n\n\n\n\n\nstr(ship_data)\n\nspc_tbl_ [2,736 × 18] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Date                   : Date[1:2736], format: \"2023-06-04\" \"2023-06-11\" ...\n $ Ship_Type              : chr [1:2736] \"Container Ship\" \"Fish Carrier\" \"Container Ship\" \"Bulk Carrier\" ...\n $ Route_Type             : chr [1:2736] \"None\" \"Short-haul\" \"Long-haul\" \"Transoceanic\" ...\n $ Engine_Type            : chr [1:2736] \"Heavy Fuel Oil (HFO)\" \"Steam Turbine\" \"Diesel\" \"Steam Turbine\" ...\n $ Maintenance_Status     : chr [1:2736] \"Critical\" \"Good\" \"Fair\" \"Fair\" ...\n $ Speed_Over_Ground_knots: num [1:2736] 12.6 10.4 20.7 21.1 13.7 ...\n $ Engine_Power_kW        : num [1:2736] 2063 1796 1649 915 1090 ...\n $ Distance_Traveled_nm   : num [1:2736] 1031 1060 659 1127 1445 ...\n $ Draft_meters           : num [1:2736] 14.13 14.65 7.2 11.79 9.73 ...\n $ Weather_Condition      : chr [1:2736] \"Moderate\" \"Rough\" \"Moderate\" \"Moderate\" ...\n $ Cargo_Weight_tons      : num [1:2736] 1959 162 178 1737 261 ...\n $ Operational_Cost_USD   : num [1:2736] 483832 483388 448543 261350 287718 ...\n $ Revenue_per_Voyage_USD : num [1:2736] 292183 883766 394019 87551 676121 ...\n $ Turnaround_Time_hours  : num [1:2736] 25.9 63.2 49.4 22.4 64.2 ...\n $ Efficiency_nm_per_kWh  : num [1:2736] 1.455 0.29 0.5 0.703 1.331 ...\n $ Seasonal_Impact_Score  : num [1:2736] 1.416 0.886 1.406 1.371 0.583 ...\n $ Weekly_Voyage_Count    : num [1:2736] 1 6 9 1 8 7 3 6 8 2 ...\n $ Average_Load_Percentage: num [1:2736] 93.8 93.9 96.2 66.2 80 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Date = col_date(format = \"\"),\n  ..   Ship_Type = col_character(),\n  ..   Route_Type = col_character(),\n  ..   Engine_Type = col_character(),\n  ..   Maintenance_Status = col_character(),\n  ..   Speed_Over_Ground_knots = col_double(),\n  ..   Engine_Power_kW = col_double(),\n  ..   Distance_Traveled_nm = col_double(),\n  ..   Draft_meters = col_double(),\n  ..   Weather_Condition = col_character(),\n  ..   Cargo_Weight_tons = col_double(),\n  ..   Operational_Cost_USD = col_double(),\n  ..   Revenue_per_Voyage_USD = col_double(),\n  ..   Turnaround_Time_hours = col_double(),\n  ..   Efficiency_nm_per_kWh = col_double(),\n  ..   Seasonal_Impact_Score = col_double(),\n  ..   Weekly_Voyage_Count = col_double(),\n  ..   Average_Load_Percentage = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\n\n\n\n\n\n\nNumerical Features\nCategorical Features\n\n\n\n\n\nSpeed_Over_Ground_knots: Average speed of the ship over water (in knots).\nEngine_Power_kW: Engine power output (in kilowatts).\nDistance_Traveled_nm: Total distance traveled by the ship (in nautical miles).\nOperational_Cost_USD: Total operational cost per voyage (in USD).\nRevenue_per_Voyage_USD: Revenue generated per voyage (in USD).\nEfficiency_nm_per_kWh: Energy efficiency calculated in nautical miles per kilowatt-hour.\n\n\nShip_Type: Type of ship (e.g., Tanker, Container Ship, Fish Carrier, Bulk Carrier).\nRoute_Type: Shipping route type (e.g., Short-haul, Long-haul, Transoceanic).\nEngine_Type: Type of engine (e.g., Diesel, Heavy Fuel Oil).\nMaintenance_Status: Maintenance condition of the ship (e.g., Fair, Critical, Good).\nWeather_Condition: Prevailing weather conditions during voyages (e.g., Calm, Moderate, Rough).\n\n\n\n\n\nglimpse(ship_data)\n\nRows: 2,736\nColumns: 18\n$ Date                    &lt;date&gt; 2023-06-04, 2023-06-11, 2023-06-18, 2023-06-2…\n$ Ship_Type               &lt;chr&gt; \"Container Ship\", \"Fish Carrier\", \"Container S…\n$ Route_Type              &lt;chr&gt; \"None\", \"Short-haul\", \"Long-haul\", \"Transocean…\n$ Engine_Type             &lt;chr&gt; \"Heavy Fuel Oil (HFO)\", \"Steam Turbine\", \"Dies…\n$ Maintenance_Status      &lt;chr&gt; \"Critical\", \"Good\", \"Fair\", \"Fair\", \"Fair\", \"F…\n$ Speed_Over_Ground_knots &lt;dbl&gt; 12.59756, 10.38758, 20.74975, 21.05510, 13.742…\n$ Engine_Power_kW         &lt;dbl&gt; 2062.9840, 1796.0574, 1648.5567, 915.2618, 108…\n$ Distance_Traveled_nm    &lt;dbl&gt; 1030.9436, 1060.4864, 658.8741, 1126.8225, 144…\n$ Draft_meters            &lt;dbl&gt; 14.132284, 14.653083, 7.199261, 11.789063, 9.7…\n$ Weather_Condition       &lt;chr&gt; \"Moderate\", \"Rough\", \"Moderate\", \"Moderate\", \"…\n$ Cargo_Weight_tons       &lt;dbl&gt; 1959.0179, 162.3947, 178.0409, 1737.3853, 260.…\n$ Operational_Cost_USD    &lt;dbl&gt; 483832.35, 483388.00, 448543.40, 261349.61, 28…\n$ Revenue_per_Voyage_USD  &lt;dbl&gt; 292183.27, 883765.79, 394018.75, 87551.38, 676…\n$ Turnaround_Time_hours   &lt;dbl&gt; 25.86708, 63.24820, 49.41815, 22.40911, 64.158…\n$ Efficiency_nm_per_kWh   &lt;dbl&gt; 1.4551789, 0.2903614, 0.4995945, 0.7029057, 1.…\n$ Seasonal_Impact_Score   &lt;dbl&gt; 1.4156533, 0.8856478, 1.4058132, 1.3707043, 0.…\n$ Weekly_Voyage_Count     &lt;dbl&gt; 1, 6, 9, 1, 8, 7, 3, 6, 8, 2, 9, 4, 3, 7, 7, 3…\n$ Average_Load_Percentage &lt;dbl&gt; 93.76925, 93.89537, 96.21824, 66.19370, 80.008…\n\n\n\nsummary(ship_data)\n\n      Date             Ship_Type          Route_Type        Engine_Type       \n Min.   :2023-06-04   Length:2736        Length:2736        Length:2736       \n 1st Qu.:2023-09-10   Class :character   Class :character   Class :character  \n Median :2023-12-17   Mode  :character   Mode  :character   Mode  :character  \n Mean   :2023-12-17                                                           \n 3rd Qu.:2024-03-24                                                           \n Max.   :2024-06-30                                                           \n Maintenance_Status Speed_Over_Ground_knots Engine_Power_kW\n Length:2736        Min.   :10.01           Min.   : 501   \n Class :character   1st Qu.:13.93           1st Qu.:1148   \n Mode  :character   Median :17.71           Median :1757   \n                    Mean   :17.60           Mean   :1758   \n                    3rd Qu.:21.28           3rd Qu.:2383   \n                    Max.   :25.00           Max.   :2999   \n Distance_Traveled_nm  Draft_meters    Weather_Condition  Cargo_Weight_tons\n Min.   :  50.43      Min.   : 5.002   Length:2736        Min.   :  50.23  \n 1st Qu.: 548.51      1st Qu.: 7.437   Class :character   1st Qu.: 553.98  \n Median :1037.82      Median : 9.919   Mode  :character   Median :1043.21  \n Mean   :1036.41      Mean   : 9.929                      Mean   :1032.57  \n 3rd Qu.:1540.93      3rd Qu.:12.413                      3rd Qu.:1527.72  \n Max.   :1998.34      Max.   :14.993                      Max.   :1999.13  \n Operational_Cost_USD Revenue_per_Voyage_USD Turnaround_Time_hours\n Min.   : 10092       Min.   : 50352         Min.   :12.02        \n 1st Qu.:131293       1st Qu.:290346         1st Qu.:26.17        \n Median :257158       Median :520177         Median :41.59        \n Mean   :255143       Mean   :521362         Mean   :41.75        \n 3rd Qu.:381797       3rd Qu.:750073         3rd Qu.:57.36        \n Max.   :499735       Max.   :999917         Max.   :71.97        \n Efficiency_nm_per_kWh Seasonal_Impact_Score Weekly_Voyage_Count\n Min.   :0.1002        Min.   :0.500         Min.   :1.000      \n 1st Qu.:0.4636        1st Qu.:0.758         1st Qu.:3.000      \n Median :0.7899        Median :1.009         Median :5.000      \n Mean   :0.7987        Mean   :1.004         Mean   :4.915      \n 3rd Qu.:1.1474        3rd Qu.:1.253         3rd Qu.:7.000      \n Max.   :1.4993        Max.   :1.499         Max.   :9.000      \n Average_Load_Percentage\n Min.   : 50.01         \n 1st Qu.: 62.70         \n Median : 75.50         \n Mean   : 75.22         \n 3rd Qu.: 87.72         \n Max.   :100.00         \n\nhead(ship_data)\n\n# A tibble: 6 × 18\n  Date       Ship_Type      Route_Type   Engine_Type          Maintenance_Status\n  &lt;date&gt;     &lt;chr&gt;          &lt;chr&gt;        &lt;chr&gt;                &lt;chr&gt;             \n1 2023-06-04 Container Ship None         Heavy Fuel Oil (HFO) Critical          \n2 2023-06-11 Fish Carrier   Short-haul   Steam Turbine        Good              \n3 2023-06-18 Container Ship Long-haul    Diesel               Fair              \n4 2023-06-25 Bulk Carrier   Transoceanic Steam Turbine        Fair              \n5 2023-07-02 Fish Carrier   Transoceanic Diesel               Fair              \n6 2023-07-09 Fish Carrier   Long-haul    Heavy Fuel Oil (HFO) Fair              \n# ℹ 13 more variables: Speed_Over_Ground_knots &lt;dbl&gt;, Engine_Power_kW &lt;dbl&gt;,\n#   Distance_Traveled_nm &lt;dbl&gt;, Draft_meters &lt;dbl&gt;, Weather_Condition &lt;chr&gt;,\n#   Cargo_Weight_tons &lt;dbl&gt;, Operational_Cost_USD &lt;dbl&gt;,\n#   Revenue_per_Voyage_USD &lt;dbl&gt;, Turnaround_Time_hours &lt;dbl&gt;,\n#   Efficiency_nm_per_kWh &lt;dbl&gt;, Seasonal_Impact_Score &lt;dbl&gt;,\n#   Weekly_Voyage_Count &lt;dbl&gt;, Average_Load_Percentage &lt;dbl&gt;\n\n\n\n\n\n\ncolSums(is.na(ship_data))\n\n                   Date               Ship_Type              Route_Type \n                      0                       0                       0 \n            Engine_Type      Maintenance_Status Speed_Over_Ground_knots \n                      0                       0                       0 \n        Engine_Power_kW    Distance_Traveled_nm            Draft_meters \n                      0                       0                       0 \n      Weather_Condition       Cargo_Weight_tons    Operational_Cost_USD \n                      0                       0                       0 \n Revenue_per_Voyage_USD   Turnaround_Time_hours   Efficiency_nm_per_kWh \n                      0                       0                       0 \n  Seasonal_Impact_Score     Weekly_Voyage_Count Average_Load_Percentage \n                      0                       0                       0 \n\n\n\n\n\n\n# Count the number of different ship types\nship_count &lt;- ship_data %&gt;%\n  count(Ship_Type, sort = TRUE)  \n\np &lt;- ggplot(ship_count, aes(x = reorder(Ship_Type, n), y = n, fill = Ship_Type)) +\n  geom_bar_interactive(stat = \"identity\", width = 0.6, aes(tooltip = paste0(\"Ship Type: \", Ship_Type, \"\\nCount: \", n))) +  \n  coord_flip() +\n  labs(title = \"Ship Type Distribution (Interactive)\", \n       x = \"Ship Type\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\", legend.title = element_blank())\n\ngirafe(ggobj = p, options = list(opts_hover(css = \"fill:red;\")))\n\n\n\n\n\n\nggplot(ship_data, aes(x = Ship_Type, y = Operational_Cost_USD, fill = Ship_Type)) +\n  geom_boxplot() +\n  labs(title = \"Operating Cost by Ship Type\", x = \"Ship Type\", y = \"Cost (USD)\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) \n\n\n\n\n\n\n\n\n\nggplot(ship_data, aes(x = Engine_Power_kW, y = Speed_Over_Ground_knots, color = Ship_Type)) +\n  geom_point(alpha = 0.6) +\n  labs(title = \"Engine Power vs. Speed\", x = \"Engine Power (kW)\", y = \"Speed (knots)\")\n\n\n\n\n\n\n\n\n\nggplot(ship_data, aes(x = Ship_Type, fill = Ship_Type)) +\n  geom_bar() +\n  labs(title = \"Frequency of Ship Types\", x = \"Ship Type\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCorrelation Heat Map (Heatmap)：\n\nTo see correlations between multiple variables.\n\n\ncor_matrix &lt;- ship_data %&gt;%\n  dplyr::select(Speed_Over_Ground_knots, Cargo_Weight_tons, \n                Operational_Cost_USD, Revenue_per_Voyage_USD, \n                Efficiency_nm_per_kWh) %&gt;%\n  cor(use = \"pairwise.complete.obs\")\n\nheatmaply(cor_matrix, \n          xlab = \"Variables\", ylab = \"Variables\",\n          main = \"Ship Performance Correlation Heatmap\",\n          colors = colorRampPalette(c(\"darkred\", \"white\", \"darkblue\"))(256),\n          cellnote = round(cor_matrix, 2),\n          fontsize_row = 12, fontsize_col = 12,\n          dendrogram = \"none\")\n\n\n\n\n\nInteractive scatterplot of speed vs fuel efficiency：\n\nThe interactive scatter plot shows that there is little difference in fuel efficiency between different ship types, and the relationship between speed and fuel efficiency is relatively stable.\n\n\nlibrary(plotly)\n\np &lt;- ggplot(ship_data, aes(x = Speed_Over_Ground_knots, y = Efficiency_nm_per_kWh, \n                           color = Ship_Type)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  labs(title = \"Interactive: Speed vs Fuel Efficiency\",\n       x = \"Speed (knots)\", y = \"Efficiency (nm per kWh)\") +\n  theme_minimal()\n\nggplotly(p)\n\n\n\n\n\nSpeed vs fuel efficiency correlation for different ship types:\n\nTo analyze whether the relationship between speed and fuel efficiency is different in different ship types.\n\n\nship_corr_by_type &lt;- ship_data %&gt;%\n  group_by(Ship_Type) %&gt;%\n  summarise(correlation = cor(Speed_Over_Ground_knots, Efficiency_nm_per_kWh, use = \"complete.obs\"))\n\nggplot(ship_corr_by_type, aes(x = Ship_Type, y = correlation, fill = Ship_Type)) +\n  geom_col() +\n  labs(title = \"Correlation between Speed and Fuel Efficiency by Ship Type\",\n       x = \"Ship Type\", y = \"Correlation Coefficient\") +\n  theme_minimal()\n\n\n\n\n\n\n\nggplot(ship_data, aes(x = Ship_Type, y = Efficiency_nm_per_kWh, fill = Ship_Type)) +\n  geom_violin(trim = FALSE, alpha = 0.7) +\n  geom_boxplot(width = 0.2, color = \"black\", outlier.shape = NA, alpha = 0.5) +\n  labs(title = \"Fuel Efficiency Across Different Ship Types\",\n       x = \"Ship Type\",\n       y = \"Efficiency (nm per kWh)\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nCosts with speed\n\nProfits rise in certain speed ranges, but fall after a certain speed, which means that there may be an optimal speed.\n\n\np1 &lt;- ggplot(ship_data, aes(x = Speed_Over_Ground_knots, y = Operational_Cost_USD)) +\n  geom_smooth(method = \"loess\", color = \"red\", se = FALSE) +\n  labs(title = \"Operational Cost vs Speed\", x = \"Speed (knots)\", y = \"Operational Cost (USD)\") +\n  theme_minimal()\n\np2 &lt;- ggplot(ship_data, aes(x = Speed_Over_Ground_knots, y = Revenue_per_Voyage_USD)) +\n  geom_smooth(method = \"loess\", color = \"green\", se = FALSE) +\n  labs(title = \"Revenue vs Speed\", x = \"Speed (knots)\", y = \"Revenue per Voyage (USD)\") +\n  theme_minimal()\n\np1 + p2\n\n\n\n\n\n\n\n\nOptimal velocity analysis\n\nThe optimal speed calculated by smoothing curves is ≈ 10.44 knots, at which time the profit reaches the maximum.However, the Profit-to-Cost Ratio gradually decreases with increasing speed, suggesting that higher speed, while it may bring higher total profits, is not necessarily the most economical option.\n\n\nggplot(ship_data, aes(x = Speed_Over_Ground_knots, y = Efficiency_nm_per_kWh)) +\n  geom_point(alpha = 0.3, color = \"blue\") +\n  geom_smooth(method = \"loess\", se = TRUE, color = \"red\") +\n  labs(title = \"Optimal Speed for Fuel Efficiency\",\n       x = \"Speed (knots)\", y = \"Fuel Efficiency (nm per kWh)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nship_data &lt;- ship_data %&gt;%\n  mutate(Profit = Revenue_per_Voyage_USD - Operational_Cost_USD)\n\noptimal_speed &lt;- ship_data %&gt;%\n  group_by(Speed_Over_Ground_knots) %&gt;%\n  summarise(avg_profit = mean(Profit, na.rm = TRUE)) %&gt;%\n  filter(avg_profit == max(avg_profit)) %&gt;%\n  pull(Speed_Over_Ground_knots)\n\nggplot(ship_data, aes(x = Speed_Over_Ground_knots, y = Profit)) +\n  geom_smooth(method = \"loess\", se = FALSE, size = 1, color = \"green\") +\n  geom_vline(xintercept = optimal_speed, linetype = \"dashed\", color = \"blue\") +\n  annotate(\"text\", x = optimal_speed, y = max(ship_data$Profit) * 0.9,\n           label = paste(\"Optimal Speed =\", round(optimal_speed, 2), \"knots\"),\n           color = \"blue\") +\n  labs(title = \"Optimal Speed for Maximum Profit\",\n       x = \"Speed (knots)\", y = \"Profit (USD)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nship_data &lt;- ship_data %&gt;%\n  mutate(Profit = Revenue_per_Voyage_USD - Operational_Cost_USD)\n\nship_data &lt;- ship_data %&gt;%\n  mutate(Profit_Cost_Ratio = Profit / Operational_Cost_USD)\n\nggplot(ship_data, aes(x = Speed_Over_Ground_knots, y = Profit_Cost_Ratio)) +\n  geom_smooth(method = \"loess\", color = \"purple\", se = FALSE) +\n  labs(title = \"Profit-to-Cost Ratio vs Speed\",\n       x = \"Speed (knots)\", y = \"Profit-to-Cost Ratio\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n🛎️ Insight:\nBased on the analysis, there is minimal direct correlation between speed, fuel efficiency, operational cost, and cargo weight, indicating that linear relationships alone do not explain ship performance. The optimal speed for maximum profit is approximately 10.44 knots, beyond which profit declines due to rising costs. Fuel efficiency remains relatively stable across ship types, but tankers show the strongest correlation with speed. To optimize operations, a dynamic speed adjustment strategy should be adopted, balancing cost, fuel efficiency, and profitability while integrating weather and route conditions.\n\n\n\n\nship_efficiency_summary &lt;- ship_data %&gt;%\n  group_by(Ship_Type, Route_Type) %&gt;%\n  summarise(\n    mean_efficiency = mean(Efficiency_nm_per_kWh, na.rm = TRUE),\n    sd_efficiency = sd(Efficiency_nm_per_kWh, na.rm = TRUE),\n  )\n\npa &lt;- ggplot(ship_efficiency_summary, aes(x = Ship_Type, y = mean_efficiency, fill = Route_Type)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  geom_errorbar(\n    aes(ymin = mean_efficiency - sd_efficiency, ymax = mean_efficiency + sd_efficiency),\n    position = position_dodge(0.9), width = 0.2\n  ) +\n  labs(\n    title = \"Mean Fuel Efficiency by Ship Type and Route\",\n    x = \"Ship Type\", y = \"Mean Efficiency (nm per kWh)\"\n  ) +\n  theme_minimal()\n\nprint(pa)\n\n\n\n\n\n\n\n\n\nCompare the variation of operating costs (Operational_Cost_USD) for different ship types and routes.\n\n\nggplot(ship_data, aes(x = Ship_Type, y = Operational_Cost_USD, fill = Route_Type)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +  \n  geom_point(aes(y = Efficiency_nm_per_kWh * 100000), color = \"black\", size = 2, position = position_dodge(width = 0.9)) +  \n  scale_y_continuous(\n    sec.axis = sec_axis(~./100000, name = \"Fuel Efficiency (nm per kWh)\")\n  ) +  \n  labs(title = \"Operational Cost & Fuel Efficiency by Ship Type and Route\",\n       x = \"Ship Type\", y = \"Operational Cost (USD)\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nUnit operating cost vs ship type & Route.\n\n\npb &lt;- ship_data &lt;- ship_data %&gt;%\n  mutate(Cost_per_Nautical_Mile = Operational_Cost_USD / Distance_Traveled_nm)\n\nggplot(ship_data, aes(x = Ship_Type, y = Cost_per_Nautical_Mile, fill = Route_Type)) +\n  geom_bar(stat = \"summary\", fun = mean, position = \"dodge\") + \n  labs(title = \"Operational Cost per Nautical Mile by Ship Type and Route\",\n       x = \"Ship Type\", y = \"Cost per Nautical Mile (USD)\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) \n\n\n\n\n\n\n\n\n\nThe Mean Turnaround Time (mean turnaround time) was calculated to help analyze the turnaround efficiency of different ship types on different routes.\n\n\npc &lt;- ggplot(ship_data, aes(x = Ship_Type, y = Turnaround_Time_hours, fill = Route_Type)) +\n  geom_boxplot(outlier.shape = NA, alpha = 0.6) + \n  stat_summary(fun = mean, geom = \"point\", color = \"red\", size = 3) + \n  labs(title = \"Mean Turnaround Time by Ship Type and Route\",\n       x = \"Ship Type\", y = \"Turnaround Time (Hours)\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) \n\n\nThe Mean Profit-Cost Ratio is marked with the mean of the scatter chart to help identify the profitability of different ship types on different routes.\n\n\nmean_data &lt;- ship_data %&gt;%\n  group_by(Ship_Type) %&gt;%\n  summarise(Mean_Profit = mean(Profit_Cost_Ratio, na.rm = TRUE), .groups = \"drop\")\n\np &lt;- plot_ly() %&gt;%\n  add_trace(\n    data = ship_data,\n    x = ~Ship_Type, \n    y = ~Profit_Cost_Ratio, \n    color = ~Route_Type, \n    type = \"scatter\", \n    mode = \"markers\",\n    text = ~paste(\"Ship Type:\", Ship_Type, \"&lt;br&gt;\",\n                  \"Route:\", Route_Type, \"&lt;br&gt;\",\n                  \"Profit-Cost Ratio:\", round(Profit_Cost_Ratio, 2)),\n    hoverinfo = \"text\",\n    marker = list(opacity = 0.5)\n  ) %&gt;%\n  add_trace(\n    data = mean_data,\n    x = ~Ship_Type,\n    y = ~Mean_Profit,\n    type = \"scatter\",\n    mode = \"markers+text\",\n    text = ~paste(\"Mean:\", round(Mean_Profit, 2)), \n    textposition = \"top center\",\n    marker = list(symbol = \"diamond\", size = 8, color = \"black\"), \n    name = \"Mean Profitability\",\n    hoverinfo = \"text\"\n  ) %&gt;%\n  layout(\n    title = \"Profitability Ratio by Ship Type and Route\",\n    xaxis = list(title = \"Ship Type\"),\n    yaxis = list(title = \"Profit-Cost Ratio\"),\n    legend = list(title = list(text = \"Route Type\"))\n  )\n\np\n\n\n\n\n\n\ngrid.arrange(pa, pc, ncol = 1)\n\n\n\n\n\n\n\n\n🛎️ Insight:\nBased on the analysis, fuel efficiency varies across ship types and routes, with container ships and fish carriers being more stable, while tankers show lower efficiency. Operational costs remain high across all routes, with no strong correlation between cost and fuel efficiency, indicating other influencing factors. Turnaround times are longer for long-haul and transoceanic routes, especially for bulk carriers and tankers. Profitability is highest for bulk carriers on short-haul routes, while tankers and container ships have stable but lower margins. Optimizing speed, route planning, and cost management can enhance efficiency and profitability.\n\n\n\n\nCalculate fuel efficiency averages for different weather conditions and plot error bars\n\n\nweather_efficiency_summary &lt;- ship_data %&gt;%\n  group_by(Weather_Condition) %&gt;%\n  summarise(\n    mean_efficiency = mean(Efficiency_nm_per_kWh, na.rm = TRUE),\n    sd_efficiency = sd(Efficiency_nm_per_kWh, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\nggplot(weather_efficiency_summary, aes(x = Weather_Condition, y = mean_efficiency, fill = Weather_Condition)) +\n  geom_bar(stat = \"identity\", alpha = 0.7) +\n  geom_errorbar(aes(ymin = mean_efficiency - sd_efficiency, ymax = mean_efficiency + sd_efficiency),\n                width = 0.2) +\n  labs(title = \"Fuel Efficiency across Different Weather Conditions\",\n       x = \"Weather Condition\", y = \"Mean Efficiency (nm per kWh)\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) \n\n\n\n\n\n\n\n\n\nggplot(ship_data, aes(x = Weather_Condition, y = Speed_Over_Ground_knots, fill = Ship_Type)) +\n  geom_boxplot(outlier.shape = NA, alpha = 0.6) +  \n  geom_jitter(aes(color = Ship_Type), width = 0.2, alpha = 0.3) + \n  facet_wrap(~ Ship_Type, scales = \"free_y\") +\n  labs(title \n       = \"Speed Distribution Across Different Weather Conditions\",\n       x = \"Weather Condition\",\n       y = \"Speed (knots)\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nship_data &lt;- ship_data %&gt;%\n  mutate(Month = format(as.Date(Date), \"%m\"))\n\nmonthly_cost_summary &lt;- ship_data %&gt;%\n  group_by(Month) %&gt;%\n  summarise(mean_cost = mean(Operational_Cost_USD, na.rm = TRUE),\n            sd_cost = sd(Operational_Cost_USD, na.rm = TRUE),\n            .groups = \"drop\")\n\nggplot(monthly_cost_summary, aes(x = Month, y = mean_cost, group = 1)) +\n  geom_line(color = \"blue\", size = 1) +  \n  geom_point(size = 3, color = \"red\") +  \n  geom_errorbar(aes(ymin = mean_cost - sd_cost, ymax = mean_cost + sd_cost), width = 0.2) +\n  labs(title = \"Monthly Operational Cost Trend\",\n       x = \"Month\", y = \"Mean Operational Cost (USD)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nmonthly_weather_cost &lt;- ship_data %&gt;%\n  group_by(Month, Weather_Condition) %&gt;%\n  summarise(mean_cost = mean(Operational_Cost_USD, na.rm = TRUE), .groups = \"drop\")\n\nggplot(monthly_weather_cost, aes(x = Month, y = mean_cost, fill = Weather_Condition)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Monthly Operational Cost by Weather Condition\",\n       x = \"Month\", y = \"Mean Operational Cost (USD)\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nweather_cost_summary &lt;- ship_data %&gt;%\n  group_by(Weather_Condition) %&gt;%\n  summarise(\n    mean_cost = mean(Operational_Cost_USD, na.rm = TRUE),\n    sd_cost = sd(Operational_Cost_USD, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\nggplot(weather_cost_summary, aes(x = Weather_Condition, y = mean_cost, fill = Weather_Condition)) +\n  geom_bar(stat = \"identity\", alpha = 0.7) +\n  geom_errorbar(aes(ymin = mean_cost - sd_cost, ymax = mean_cost + sd_cost), width = 0.2) +\n  labs(title = \"Operational Cost Across Different Weather Conditions\",\n       x = \"Weather Condition\", y = \"Mean Operational Cost (USD)\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nanova_result &lt;- aov(Operational_Cost_USD ~ Weather_Condition, data = ship_data)\nsummary(anova_result)\n\n                    Df    Sum Sq   Mean Sq F value Pr(&gt;F)\nWeather_Condition    3 9.117e+10 3.039e+10   1.532  0.204\nResiduals         2732 5.420e+13 1.984e+10               \n\n\n🛎️ Insight:\nBased on the analysis, different weather conditions have a limited impact on fuel efficiency (Efficiency_nm_per_kWh). The boxplots and mean error bars show minimal variation in fuel efficiency across weather conditions. Further validation using ANOVA reveals a p-value of 0.204, which is greater than 0.05, indicating that the effect of weather on operational cost is not statistically significant. This suggests that fuel efficiency is more influenced by ship type, speed, cargo weight, and operational strategies rather than weather conditions. It is recommended to further analyze speed optimization and operational adjustments to improve fuel consumption efficiency rather than focusing on weather-related factors.\n\n\n\n\nIn this analysis,different ship types (Ship_Type) and routes (Route_Type) have minimal impact on fuel efficiency, but tankers show a stronger correlation between speed and fuel efficiency. Operational costs (Operational_Cost_USD) are higher for long-haul and transoceanic routes, though weather conditions do not significantly affect costs. Some routes exhibit higher cost per nautical mile, indicating potential inefficiencies. Turnaround time is longest for transoceanic routes, possibly affecting operational efficiency. To optimize performance, companies should refine route planning, implement dynamic speed adjustment strategies, and further investigate the impact of weather on specific routes."
  },
  {
    "objectID": "Take home Ex/Take-home_Ex1/Take-home_Ex1.html#background",
    "href": "Take home Ex/Take-home_Ex1/Take-home_Ex1.html#background",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "Based on the Ship Performance Clustering Dataset for 2020-2023, this report analyzes the relationship between ship performance indicators and operational efficiency to provide support for optimizing route planning and energy consumption management."
  },
  {
    "objectID": "Take home Ex/Take-home_Ex1/Take-home_Ex1.html#dataset-associated-libraries",
    "href": "Take home Ex/Take-home_Ex1/Take-home_Ex1.html#dataset-associated-libraries",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "Data covering ship category, speed, fuel consumption, cargo load, maintenance status, sailing distance and other indicators.\n\npacman::p_load(tidyverse,ggrepel, patchwork, ggthemes, hrbrthemes,ggiraph, plotly,readxl, \n               gifski, gapminder,gganimate,HH,corrplot, ggstatsplot,ggExtra,FunnelPlotR, knitr,\n               ggdist, ggridges,colorspace,crosstalk, DT,SmartEDA,easystats, tidymodels,ggtern,\n               seriation, dendextend, heatmaply,GGally, parallelPlot\n               )"
  },
  {
    "objectID": "Take home Ex/Take-home_Ex1/Take-home_Ex1.html#import-data",
    "href": "Take home Ex/Take-home_Ex1/Take-home_Ex1.html#import-data",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "library(tidyverse,haven)\nship_data &lt;- read_csv(\"/Users/geloliu/Gelo-608/ISSS608/Take home Ex/Take-home_Ex1/data/Ship_Performance_Dataset.csv\")"
  },
  {
    "objectID": "Take home Ex/Take-home_Ex1/Take-home_Ex1.html#data-pre-processing-data-exploration",
    "href": "Take home Ex/Take-home_Ex1/Take-home_Ex1.html#data-pre-processing-data-exploration",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "str(ship_data)\n\nspc_tbl_ [2,736 × 18] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Date                   : Date[1:2736], format: \"2023-06-04\" \"2023-06-11\" ...\n $ Ship_Type              : chr [1:2736] \"Container Ship\" \"Fish Carrier\" \"Container Ship\" \"Bulk Carrier\" ...\n $ Route_Type             : chr [1:2736] \"None\" \"Short-haul\" \"Long-haul\" \"Transoceanic\" ...\n $ Engine_Type            : chr [1:2736] \"Heavy Fuel Oil (HFO)\" \"Steam Turbine\" \"Diesel\" \"Steam Turbine\" ...\n $ Maintenance_Status     : chr [1:2736] \"Critical\" \"Good\" \"Fair\" \"Fair\" ...\n $ Speed_Over_Ground_knots: num [1:2736] 12.6 10.4 20.7 21.1 13.7 ...\n $ Engine_Power_kW        : num [1:2736] 2063 1796 1649 915 1090 ...\n $ Distance_Traveled_nm   : num [1:2736] 1031 1060 659 1127 1445 ...\n $ Draft_meters           : num [1:2736] 14.13 14.65 7.2 11.79 9.73 ...\n $ Weather_Condition      : chr [1:2736] \"Moderate\" \"Rough\" \"Moderate\" \"Moderate\" ...\n $ Cargo_Weight_tons      : num [1:2736] 1959 162 178 1737 261 ...\n $ Operational_Cost_USD   : num [1:2736] 483832 483388 448543 261350 287718 ...\n $ Revenue_per_Voyage_USD : num [1:2736] 292183 883766 394019 87551 676121 ...\n $ Turnaround_Time_hours  : num [1:2736] 25.9 63.2 49.4 22.4 64.2 ...\n $ Efficiency_nm_per_kWh  : num [1:2736] 1.455 0.29 0.5 0.703 1.331 ...\n $ Seasonal_Impact_Score  : num [1:2736] 1.416 0.886 1.406 1.371 0.583 ...\n $ Weekly_Voyage_Count    : num [1:2736] 1 6 9 1 8 7 3 6 8 2 ...\n $ Average_Load_Percentage: num [1:2736] 93.8 93.9 96.2 66.2 80 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Date = col_date(format = \"\"),\n  ..   Ship_Type = col_character(),\n  ..   Route_Type = col_character(),\n  ..   Engine_Type = col_character(),\n  ..   Maintenance_Status = col_character(),\n  ..   Speed_Over_Ground_knots = col_double(),\n  ..   Engine_Power_kW = col_double(),\n  ..   Distance_Traveled_nm = col_double(),\n  ..   Draft_meters = col_double(),\n  ..   Weather_Condition = col_character(),\n  ..   Cargo_Weight_tons = col_double(),\n  ..   Operational_Cost_USD = col_double(),\n  ..   Revenue_per_Voyage_USD = col_double(),\n  ..   Turnaround_Time_hours = col_double(),\n  ..   Efficiency_nm_per_kWh = col_double(),\n  ..   Seasonal_Impact_Score = col_double(),\n  ..   Weekly_Voyage_Count = col_double(),\n  ..   Average_Load_Percentage = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\n\n\n\n\n\n\nNumerical Features\nCategorical Features\n\n\n\n\n\nSpeed_Over_Ground_knots: Average speed of the ship over water (in knots).\nEngine_Power_kW: Engine power output (in kilowatts).\nDistance_Traveled_nm: Total distance traveled by the ship (in nautical miles).\nOperational_Cost_USD: Total operational cost per voyage (in USD).\nRevenue_per_Voyage_USD: Revenue generated per voyage (in USD).\nEfficiency_nm_per_kWh: Energy efficiency calculated in nautical miles per kilowatt-hour.\n\n\nShip_Type: Type of ship (e.g., Tanker, Container Ship, Fish Carrier, Bulk Carrier).\nRoute_Type: Shipping route type (e.g., Short-haul, Long-haul, Transoceanic).\nEngine_Type: Type of engine (e.g., Diesel, Heavy Fuel Oil).\nMaintenance_Status: Maintenance condition of the ship (e.g., Fair, Critical, Good).\nWeather_Condition: Prevailing weather conditions during voyages (e.g., Calm, Moderate, Rough).\n\n\n\n\n\nglimpse(ship_data)\n\nRows: 2,736\nColumns: 18\n$ Date                    &lt;date&gt; 2023-06-04, 2023-06-11, 2023-06-18, 2023-06-2…\n$ Ship_Type               &lt;chr&gt; \"Container Ship\", \"Fish Carrier\", \"Container S…\n$ Route_Type              &lt;chr&gt; \"None\", \"Short-haul\", \"Long-haul\", \"Transocean…\n$ Engine_Type             &lt;chr&gt; \"Heavy Fuel Oil (HFO)\", \"Steam Turbine\", \"Dies…\n$ Maintenance_Status      &lt;chr&gt; \"Critical\", \"Good\", \"Fair\", \"Fair\", \"Fair\", \"F…\n$ Speed_Over_Ground_knots &lt;dbl&gt; 12.59756, 10.38758, 20.74975, 21.05510, 13.742…\n$ Engine_Power_kW         &lt;dbl&gt; 2062.9840, 1796.0574, 1648.5567, 915.2618, 108…\n$ Distance_Traveled_nm    &lt;dbl&gt; 1030.9436, 1060.4864, 658.8741, 1126.8225, 144…\n$ Draft_meters            &lt;dbl&gt; 14.132284, 14.653083, 7.199261, 11.789063, 9.7…\n$ Weather_Condition       &lt;chr&gt; \"Moderate\", \"Rough\", \"Moderate\", \"Moderate\", \"…\n$ Cargo_Weight_tons       &lt;dbl&gt; 1959.0179, 162.3947, 178.0409, 1737.3853, 260.…\n$ Operational_Cost_USD    &lt;dbl&gt; 483832.35, 483388.00, 448543.40, 261349.61, 28…\n$ Revenue_per_Voyage_USD  &lt;dbl&gt; 292183.27, 883765.79, 394018.75, 87551.38, 676…\n$ Turnaround_Time_hours   &lt;dbl&gt; 25.86708, 63.24820, 49.41815, 22.40911, 64.158…\n$ Efficiency_nm_per_kWh   &lt;dbl&gt; 1.4551789, 0.2903614, 0.4995945, 0.7029057, 1.…\n$ Seasonal_Impact_Score   &lt;dbl&gt; 1.4156533, 0.8856478, 1.4058132, 1.3707043, 0.…\n$ Weekly_Voyage_Count     &lt;dbl&gt; 1, 6, 9, 1, 8, 7, 3, 6, 8, 2, 9, 4, 3, 7, 7, 3…\n$ Average_Load_Percentage &lt;dbl&gt; 93.76925, 93.89537, 96.21824, 66.19370, 80.008…\n\n\n\nsummary(ship_data)\n\n      Date             Ship_Type          Route_Type        Engine_Type       \n Min.   :2023-06-04   Length:2736        Length:2736        Length:2736       \n 1st Qu.:2023-09-10   Class :character   Class :character   Class :character  \n Median :2023-12-17   Mode  :character   Mode  :character   Mode  :character  \n Mean   :2023-12-17                                                           \n 3rd Qu.:2024-03-24                                                           \n Max.   :2024-06-30                                                           \n Maintenance_Status Speed_Over_Ground_knots Engine_Power_kW\n Length:2736        Min.   :10.01           Min.   : 501   \n Class :character   1st Qu.:13.93           1st Qu.:1148   \n Mode  :character   Median :17.71           Median :1757   \n                    Mean   :17.60           Mean   :1758   \n                    3rd Qu.:21.28           3rd Qu.:2383   \n                    Max.   :25.00           Max.   :2999   \n Distance_Traveled_nm  Draft_meters    Weather_Condition  Cargo_Weight_tons\n Min.   :  50.43      Min.   : 5.002   Length:2736        Min.   :  50.23  \n 1st Qu.: 548.51      1st Qu.: 7.437   Class :character   1st Qu.: 553.98  \n Median :1037.82      Median : 9.919   Mode  :character   Median :1043.21  \n Mean   :1036.41      Mean   : 9.929                      Mean   :1032.57  \n 3rd Qu.:1540.93      3rd Qu.:12.413                      3rd Qu.:1527.72  \n Max.   :1998.34      Max.   :14.993                      Max.   :1999.13  \n Operational_Cost_USD Revenue_per_Voyage_USD Turnaround_Time_hours\n Min.   : 10092       Min.   : 50352         Min.   :12.02        \n 1st Qu.:131293       1st Qu.:290346         1st Qu.:26.17        \n Median :257158       Median :520177         Median :41.59        \n Mean   :255143       Mean   :521362         Mean   :41.75        \n 3rd Qu.:381797       3rd Qu.:750073         3rd Qu.:57.36        \n Max.   :499735       Max.   :999917         Max.   :71.97        \n Efficiency_nm_per_kWh Seasonal_Impact_Score Weekly_Voyage_Count\n Min.   :0.1002        Min.   :0.500         Min.   :1.000      \n 1st Qu.:0.4636        1st Qu.:0.758         1st Qu.:3.000      \n Median :0.7899        Median :1.009         Median :5.000      \n Mean   :0.7987        Mean   :1.004         Mean   :4.915      \n 3rd Qu.:1.1474        3rd Qu.:1.253         3rd Qu.:7.000      \n Max.   :1.4993        Max.   :1.499         Max.   :9.000      \n Average_Load_Percentage\n Min.   : 50.01         \n 1st Qu.: 62.70         \n Median : 75.50         \n Mean   : 75.22         \n 3rd Qu.: 87.72         \n Max.   :100.00         \n\nhead(ship_data)\n\n# A tibble: 6 × 18\n  Date       Ship_Type      Route_Type   Engine_Type          Maintenance_Status\n  &lt;date&gt;     &lt;chr&gt;          &lt;chr&gt;        &lt;chr&gt;                &lt;chr&gt;             \n1 2023-06-04 Container Ship None         Heavy Fuel Oil (HFO) Critical          \n2 2023-06-11 Fish Carrier   Short-haul   Steam Turbine        Good              \n3 2023-06-18 Container Ship Long-haul    Diesel               Fair              \n4 2023-06-25 Bulk Carrier   Transoceanic Steam Turbine        Fair              \n5 2023-07-02 Fish Carrier   Transoceanic Diesel               Fair              \n6 2023-07-09 Fish Carrier   Long-haul    Heavy Fuel Oil (HFO) Fair              \n# ℹ 13 more variables: Speed_Over_Ground_knots &lt;dbl&gt;, Engine_Power_kW &lt;dbl&gt;,\n#   Distance_Traveled_nm &lt;dbl&gt;, Draft_meters &lt;dbl&gt;, Weather_Condition &lt;chr&gt;,\n#   Cargo_Weight_tons &lt;dbl&gt;, Operational_Cost_USD &lt;dbl&gt;,\n#   Revenue_per_Voyage_USD &lt;dbl&gt;, Turnaround_Time_hours &lt;dbl&gt;,\n#   Efficiency_nm_per_kWh &lt;dbl&gt;, Seasonal_Impact_Score &lt;dbl&gt;,\n#   Weekly_Voyage_Count &lt;dbl&gt;, Average_Load_Percentage &lt;dbl&gt;\n\n\n\n\n\n\ncolSums(is.na(ship_data))\n\n                   Date               Ship_Type              Route_Type \n                      0                       0                       0 \n            Engine_Type      Maintenance_Status Speed_Over_Ground_knots \n                      0                       0                       0 \n        Engine_Power_kW    Distance_Traveled_nm            Draft_meters \n                      0                       0                       0 \n      Weather_Condition       Cargo_Weight_tons    Operational_Cost_USD \n                      0                       0                       0 \n Revenue_per_Voyage_USD   Turnaround_Time_hours   Efficiency_nm_per_kWh \n                      0                       0                       0 \n  Seasonal_Impact_Score     Weekly_Voyage_Count Average_Load_Percentage \n                      0                       0                       0 \n\n\n\n\n\n\n# Count the number of different ship types\nship_count &lt;- ship_data %&gt;%\n  count(Ship_Type, sort = TRUE)  \n\np &lt;- ggplot(ship_count, aes(x = reorder(Ship_Type, n), y = n, fill = Ship_Type)) +\n  geom_bar_interactive(stat = \"identity\", width = 0.6, aes(tooltip = paste0(\"Ship Type: \", Ship_Type, \"\\nCount: \", n))) +  \n  coord_flip() +\n  labs(title = \"Ship Type Distribution (Interactive)\", \n       x = \"Ship Type\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\", legend.title = element_blank())\n\ngirafe(ggobj = p, options = list(opts_hover(css = \"fill:red;\")))\n\n\n\n\n\n\nggplot(ship_data, aes(x = Ship_Type, y = Operational_Cost_USD, fill = Ship_Type)) +\n  geom_boxplot() +\n  labs(title = \"Operating Cost by Ship Type\", x = \"Ship Type\", y = \"Cost (USD)\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) \n\n\n\n\n\n\n\n\n\nggplot(ship_data, aes(x = Engine_Power_kW, y = Speed_Over_Ground_knots, color = Ship_Type)) +\n  geom_point(alpha = 0.6) +\n  labs(title = \"Engine Power vs. Speed\", x = \"Engine Power (kW)\", y = \"Speed (knots)\")\n\n\n\n\n\n\n\n\n\nggplot(ship_data, aes(x = Ship_Type, fill = Ship_Type)) +\n  geom_bar() +\n  labs(title = \"Frequency of Ship Types\", x = \"Ship Type\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "Take home Ex/Take-home_Ex1/Take-home_Ex1.html#tasks",
    "href": "Take home Ex/Take-home_Ex1/Take-home_Ex1.html#tasks",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "Correlation Heat Map (Heatmap)：\n\nTo see correlations between multiple variables.\n\n\ncor_matrix &lt;- ship_data %&gt;%\n  dplyr::select(Speed_Over_Ground_knots, Cargo_Weight_tons, \n                Operational_Cost_USD, Revenue_per_Voyage_USD, \n                Efficiency_nm_per_kWh) %&gt;%\n  cor(use = \"pairwise.complete.obs\")\n\nheatmaply(cor_matrix, \n          xlab = \"Variables\", ylab = \"Variables\",\n          main = \"Ship Performance Correlation Heatmap\",\n          colors = colorRampPalette(c(\"darkred\", \"white\", \"darkblue\"))(256),\n          cellnote = round(cor_matrix, 2),\n          fontsize_row = 12, fontsize_col = 12,\n          dendrogram = \"none\")\n\n\n\n\n\nInteractive scatterplot of speed vs fuel efficiency：\n\nThe interactive scatter plot shows that there is little difference in fuel efficiency between different ship types, and the relationship between speed and fuel efficiency is relatively stable.\n\n\nlibrary(plotly)\n\np &lt;- ggplot(ship_data, aes(x = Speed_Over_Ground_knots, y = Efficiency_nm_per_kWh, \n                           color = Ship_Type)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  labs(title = \"Interactive: Speed vs Fuel Efficiency\",\n       x = \"Speed (knots)\", y = \"Efficiency (nm per kWh)\") +\n  theme_minimal()\n\nggplotly(p)\n\n\n\n\n\nSpeed vs fuel efficiency correlation for different ship types:\n\nTo analyze whether the relationship between speed and fuel efficiency is different in different ship types.\n\n\nship_corr_by_type &lt;- ship_data %&gt;%\n  group_by(Ship_Type) %&gt;%\n  summarise(correlation = cor(Speed_Over_Ground_knots, Efficiency_nm_per_kWh, use = \"complete.obs\"))\n\nggplot(ship_corr_by_type, aes(x = Ship_Type, y = correlation, fill = Ship_Type)) +\n  geom_col() +\n  labs(title = \"Correlation between Speed and Fuel Efficiency by Ship Type\",\n       x = \"Ship Type\", y = \"Correlation Coefficient\") +\n  theme_minimal()\n\n\n\n\n\n\n\nggplot(ship_data, aes(x = Ship_Type, y = Efficiency_nm_per_kWh, fill = Ship_Type)) +\n  geom_violin(trim = FALSE, alpha = 0.7) +\n  geom_boxplot(width = 0.2, color = \"black\", outlier.shape = NA, alpha = 0.5) +\n  labs(title = \"Fuel Efficiency Across Different Ship Types\",\n       x = \"Ship Type\",\n       y = \"Efficiency (nm per kWh)\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nCosts with speed\n\nProfits rise in certain speed ranges, but fall after a certain speed, which means that there may be an optimal speed.\n\n\np1 &lt;- ggplot(ship_data, aes(x = Speed_Over_Ground_knots, y = Operational_Cost_USD)) +\n  geom_smooth(method = \"loess\", color = \"red\", se = FALSE) +\n  labs(title = \"Operational Cost vs Speed\", x = \"Speed (knots)\", y = \"Operational Cost (USD)\") +\n  theme_minimal()\n\np2 &lt;- ggplot(ship_data, aes(x = Speed_Over_Ground_knots, y = Revenue_per_Voyage_USD)) +\n  geom_smooth(method = \"loess\", color = \"green\", se = FALSE) +\n  labs(title = \"Revenue vs Speed\", x = \"Speed (knots)\", y = \"Revenue per Voyage (USD)\") +\n  theme_minimal()\n\np1 + p2\n\n\n\n\n\n\n\n\nOptimal velocity analysis\n\nThe optimal speed calculated by smoothing curves is ≈ 10.44 knots, at which time the profit reaches the maximum.However, the Profit-to-Cost Ratio gradually decreases with increasing speed, suggesting that higher speed, while it may bring higher total profits, is not necessarily the most economical option.\n\n\nggplot(ship_data, aes(x = Speed_Over_Ground_knots, y = Efficiency_nm_per_kWh)) +\n  geom_point(alpha = 0.3, color = \"blue\") +\n  geom_smooth(method = \"loess\", se = TRUE, color = \"red\") +\n  labs(title = \"Optimal Speed for Fuel Efficiency\",\n       x = \"Speed (knots)\", y = \"Fuel Efficiency (nm per kWh)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nship_data &lt;- ship_data %&gt;%\n  mutate(Profit = Revenue_per_Voyage_USD - Operational_Cost_USD)\n\noptimal_speed &lt;- ship_data %&gt;%\n  group_by(Speed_Over_Ground_knots) %&gt;%\n  summarise(avg_profit = mean(Profit, na.rm = TRUE)) %&gt;%\n  filter(avg_profit == max(avg_profit)) %&gt;%\n  pull(Speed_Over_Ground_knots)\n\nggplot(ship_data, aes(x = Speed_Over_Ground_knots, y = Profit)) +\n  geom_smooth(method = \"loess\", se = FALSE, size = 1, color = \"green\") +\n  geom_vline(xintercept = optimal_speed, linetype = \"dashed\", color = \"blue\") +\n  annotate(\"text\", x = optimal_speed, y = max(ship_data$Profit) * 0.9,\n           label = paste(\"Optimal Speed =\", round(optimal_speed, 2), \"knots\"),\n           color = \"blue\") +\n  labs(title = \"Optimal Speed for Maximum Profit\",\n       x = \"Speed (knots)\", y = \"Profit (USD)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nship_data &lt;- ship_data %&gt;%\n  mutate(Profit = Revenue_per_Voyage_USD - Operational_Cost_USD)\n\nship_data &lt;- ship_data %&gt;%\n  mutate(Profit_Cost_Ratio = Profit / Operational_Cost_USD)\n\nggplot(ship_data, aes(x = Speed_Over_Ground_knots, y = Profit_Cost_Ratio)) +\n  geom_smooth(method = \"loess\", color = \"purple\", se = FALSE) +\n  labs(title = \"Profit-to-Cost Ratio vs Speed\",\n       x = \"Speed (knots)\", y = \"Profit-to-Cost Ratio\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n🛎️ Insight:\nBased on the analysis, there is minimal direct correlation between speed, fuel efficiency, operational cost, and cargo weight, indicating that linear relationships alone do not explain ship performance. The optimal speed for maximum profit is approximately 10.44 knots, beyond which profit declines due to rising costs. Fuel efficiency remains relatively stable across ship types, but tankers show the strongest correlation with speed. To optimize operations, a dynamic speed adjustment strategy should be adopted, balancing cost, fuel efficiency, and profitability while integrating weather and route conditions.\n\n\n\n\nship_efficiency_summary &lt;- ship_data %&gt;%\n  group_by(Ship_Type, Route_Type) %&gt;%\n  summarise(\n    mean_efficiency = mean(Efficiency_nm_per_kWh, na.rm = TRUE),\n    sd_efficiency = sd(Efficiency_nm_per_kWh, na.rm = TRUE),\n  )\n\npa &lt;- ggplot(ship_efficiency_summary, aes(x = Ship_Type, y = mean_efficiency, fill = Route_Type)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  geom_errorbar(\n    aes(ymin = mean_efficiency - sd_efficiency, ymax = mean_efficiency + sd_efficiency),\n    position = position_dodge(0.9), width = 0.2\n  ) +\n  labs(\n    title = \"Mean Fuel Efficiency by Ship Type and Route\",\n    x = \"Ship Type\", y = \"Mean Efficiency (nm per kWh)\"\n  ) +\n  theme_minimal()\n\nprint(pa)\n\n\n\n\n\n\n\n\n\nCompare the variation of operating costs (Operational_Cost_USD) for different ship types and routes.\n\n\nggplot(ship_data, aes(x = Ship_Type, y = Operational_Cost_USD, fill = Route_Type)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +  \n  geom_point(aes(y = Efficiency_nm_per_kWh * 100000), color = \"black\", size = 2, position = position_dodge(width = 0.9)) +  \n  scale_y_continuous(\n    sec.axis = sec_axis(~./100000, name = \"Fuel Efficiency (nm per kWh)\")\n  ) +  \n  labs(title = \"Operational Cost & Fuel Efficiency by Ship Type and Route\",\n       x = \"Ship Type\", y = \"Operational Cost (USD)\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nUnit operating cost vs ship type & Route.\n\n\npb &lt;- ship_data &lt;- ship_data %&gt;%\n  mutate(Cost_per_Nautical_Mile = Operational_Cost_USD / Distance_Traveled_nm)\n\nggplot(ship_data, aes(x = Ship_Type, y = Cost_per_Nautical_Mile, fill = Route_Type)) +\n  geom_bar(stat = \"summary\", fun = mean, position = \"dodge\") + \n  labs(title = \"Operational Cost per Nautical Mile by Ship Type and Route\",\n       x = \"Ship Type\", y = \"Cost per Nautical Mile (USD)\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) \n\n\n\n\n\n\n\n\n\nThe Mean Turnaround Time (mean turnaround time) was calculated to help analyze the turnaround efficiency of different ship types on different routes.\n\n\npc &lt;- ggplot(ship_data, aes(x = Ship_Type, y = Turnaround_Time_hours, fill = Route_Type)) +\n  geom_boxplot(outlier.shape = NA, alpha = 0.6) + \n  stat_summary(fun = mean, geom = \"point\", color = \"red\", size = 3) + \n  labs(title = \"Mean Turnaround Time by Ship Type and Route\",\n       x = \"Ship Type\", y = \"Turnaround Time (Hours)\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) \n\n\nThe Mean Profit-Cost Ratio is marked with the mean of the scatter chart to help identify the profitability of different ship types on different routes.\n\n\nmean_data &lt;- ship_data %&gt;%\n  group_by(Ship_Type) %&gt;%\n  summarise(Mean_Profit = mean(Profit_Cost_Ratio, na.rm = TRUE), .groups = \"drop\")\n\np &lt;- plot_ly() %&gt;%\n  add_trace(\n    data = ship_data,\n    x = ~Ship_Type, \n    y = ~Profit_Cost_Ratio, \n    color = ~Route_Type, \n    type = \"scatter\", \n    mode = \"markers\",\n    text = ~paste(\"Ship Type:\", Ship_Type, \"&lt;br&gt;\",\n                  \"Route:\", Route_Type, \"&lt;br&gt;\",\n                  \"Profit-Cost Ratio:\", round(Profit_Cost_Ratio, 2)),\n    hoverinfo = \"text\",\n    marker = list(opacity = 0.5)\n  ) %&gt;%\n  add_trace(\n    data = mean_data,\n    x = ~Ship_Type,\n    y = ~Mean_Profit,\n    type = \"scatter\",\n    mode = \"markers+text\",\n    text = ~paste(\"Mean:\", round(Mean_Profit, 2)), \n    textposition = \"top center\",\n    marker = list(symbol = \"diamond\", size = 8, color = \"black\"), \n    name = \"Mean Profitability\",\n    hoverinfo = \"text\"\n  ) %&gt;%\n  layout(\n    title = \"Profitability Ratio by Ship Type and Route\",\n    xaxis = list(title = \"Ship Type\"),\n    yaxis = list(title = \"Profit-Cost Ratio\"),\n    legend = list(title = list(text = \"Route Type\"))\n  )\n\np\n\n\n\n\n\n\ngrid.arrange(pa, pc, ncol = 1)\n\n\n\n\n\n\n\n\n🛎️ Insight:\nBased on the analysis, fuel efficiency varies across ship types and routes, with container ships and fish carriers being more stable, while tankers show lower efficiency. Operational costs remain high across all routes, with no strong correlation between cost and fuel efficiency, indicating other influencing factors. Turnaround times are longer for long-haul and transoceanic routes, especially for bulk carriers and tankers. Profitability is highest for bulk carriers on short-haul routes, while tankers and container ships have stable but lower margins. Optimizing speed, route planning, and cost management can enhance efficiency and profitability.\n\n\n\n\nCalculate fuel efficiency averages for different weather conditions and plot error bars\n\n\nweather_efficiency_summary &lt;- ship_data %&gt;%\n  group_by(Weather_Condition) %&gt;%\n  summarise(\n    mean_efficiency = mean(Efficiency_nm_per_kWh, na.rm = TRUE),\n    sd_efficiency = sd(Efficiency_nm_per_kWh, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\nggplot(weather_efficiency_summary, aes(x = Weather_Condition, y = mean_efficiency, fill = Weather_Condition)) +\n  geom_bar(stat = \"identity\", alpha = 0.7) +\n  geom_errorbar(aes(ymin = mean_efficiency - sd_efficiency, ymax = mean_efficiency + sd_efficiency),\n                width = 0.2) +\n  labs(title = \"Fuel Efficiency across Different Weather Conditions\",\n       x = \"Weather Condition\", y = \"Mean Efficiency (nm per kWh)\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) \n\n\n\n\n\n\n\n\n\nggplot(ship_data, aes(x = Weather_Condition, y = Speed_Over_Ground_knots, fill = Ship_Type)) +\n  geom_boxplot(outlier.shape = NA, alpha = 0.6) +  \n  geom_jitter(aes(color = Ship_Type), width = 0.2, alpha = 0.3) + \n  facet_wrap(~ Ship_Type, scales = \"free_y\") +\n  labs(title \n       = \"Speed Distribution Across Different Weather Conditions\",\n       x = \"Weather Condition\",\n       y = \"Speed (knots)\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nship_data &lt;- ship_data %&gt;%\n  mutate(Month = format(as.Date(Date), \"%m\"))\n\nmonthly_cost_summary &lt;- ship_data %&gt;%\n  group_by(Month) %&gt;%\n  summarise(mean_cost = mean(Operational_Cost_USD, na.rm = TRUE),\n            sd_cost = sd(Operational_Cost_USD, na.rm = TRUE),\n            .groups = \"drop\")\n\nggplot(monthly_cost_summary, aes(x = Month, y = mean_cost, group = 1)) +\n  geom_line(color = \"blue\", size = 1) +  \n  geom_point(size = 3, color = \"red\") +  \n  geom_errorbar(aes(ymin = mean_cost - sd_cost, ymax = mean_cost + sd_cost), width = 0.2) +\n  labs(title = \"Monthly Operational Cost Trend\",\n       x = \"Month\", y = \"Mean Operational Cost (USD)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nmonthly_weather_cost &lt;- ship_data %&gt;%\n  group_by(Month, Weather_Condition) %&gt;%\n  summarise(mean_cost = mean(Operational_Cost_USD, na.rm = TRUE), .groups = \"drop\")\n\nggplot(monthly_weather_cost, aes(x = Month, y = mean_cost, fill = Weather_Condition)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Monthly Operational Cost by Weather Condition\",\n       x = \"Month\", y = \"Mean Operational Cost (USD)\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nweather_cost_summary &lt;- ship_data %&gt;%\n  group_by(Weather_Condition) %&gt;%\n  summarise(\n    mean_cost = mean(Operational_Cost_USD, na.rm = TRUE),\n    sd_cost = sd(Operational_Cost_USD, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\nggplot(weather_cost_summary, aes(x = Weather_Condition, y = mean_cost, fill = Weather_Condition)) +\n  geom_bar(stat = \"identity\", alpha = 0.7) +\n  geom_errorbar(aes(ymin = mean_cost - sd_cost, ymax = mean_cost + sd_cost), width = 0.2) +\n  labs(title = \"Operational Cost Across Different Weather Conditions\",\n       x = \"Weather Condition\", y = \"Mean Operational Cost (USD)\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nanova_result &lt;- aov(Operational_Cost_USD ~ Weather_Condition, data = ship_data)\nsummary(anova_result)\n\n                    Df    Sum Sq   Mean Sq F value Pr(&gt;F)\nWeather_Condition    3 9.117e+10 3.039e+10   1.532  0.204\nResiduals         2732 5.420e+13 1.984e+10               \n\n\n🛎️ Insight:\nBased on the analysis, different weather conditions have a limited impact on fuel efficiency (Efficiency_nm_per_kWh). The boxplots and mean error bars show minimal variation in fuel efficiency across weather conditions. Further validation using ANOVA reveals a p-value of 0.204, which is greater than 0.05, indicating that the effect of weather on operational cost is not statistically significant. This suggests that fuel efficiency is more influenced by ship type, speed, cargo weight, and operational strategies rather than weather conditions. It is recommended to further analyze speed optimization and operational adjustments to improve fuel consumption efficiency rather than focusing on weather-related factors."
  },
  {
    "objectID": "Take home Ex/Take-home_Ex1/Take-home_Ex1.html#summary",
    "href": "Take home Ex/Take-home_Ex1/Take-home_Ex1.html#summary",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "In this analysis,different ship types (Ship_Type) and routes (Route_Type) have minimal impact on fuel efficiency, but tankers show a stronger correlation between speed and fuel efficiency. Operational costs (Operational_Cost_USD) are higher for long-haul and transoceanic routes, though weather conditions do not significantly affect costs. Some routes exhibit higher cost per nautical mile, indicating potential inefficiencies. Turnaround time is longest for transoceanic routes, possibly affecting operational efficiency. To optimize performance, companies should refine route planning, implement dynamic speed adjustment strategies, and further investigate the impact of weather on specific routes."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608",
    "section": "",
    "text": "This website serves as a collection of my coursework, assignments, and projects for ISSS608. Throughout this course, I explore various data visualization techniques, analytical frameworks, and interactive tools to uncover insights from complex datasets. The focus is on transforming raw data into meaningful visual narratives that drive decision-making.\nHere, you’ll find hands-on exercises, case studies, and key takeaways from my learning journey. The course covers topics such as exploratory data analysis, statistical graphics, interactive dashboards, and geospatial visualization, equipping me with the skills to analyze and present data effectively.\nBy integrating data storytelling with advanced visualization methods, this course enhances my ability to interpret patterns, detect trends, and communicate findings clearly. Feel free to browse through my coursework and see how visual analytics plays a crucial role in data-driven decision-making!"
  },
  {
    "objectID": "index.html#welcome-to-isss608-visual-analytics-and-applications",
    "href": "index.html#welcome-to-isss608-visual-analytics-and-applications",
    "title": "ISSS608",
    "section": "",
    "text": "This website serves as a collection of my coursework, assignments, and projects for ISSS608. Throughout this course, I explore various data visualization techniques, analytical frameworks, and interactive tools to uncover insights from complex datasets. The focus is on transforming raw data into meaningful visual narratives that drive decision-making.\nHere, you’ll find hands-on exercises, case studies, and key takeaways from my learning journey. The course covers topics such as exploratory data analysis, statistical graphics, interactive dashboards, and geospatial visualization, equipping me with the skills to analyze and present data effectively.\nBy integrating data storytelling with advanced visualization methods, this course enhances my ability to interpret patterns, detect trends, and communicate findings clearly. Feel free to browse through my coursework and see how visual analytics plays a crucial role in data-driven decision-making!"
  },
  {
    "objectID": "In-class ex/In-class ex05/In-class Ex05.html",
    "href": "In-class ex/In-class ex05/In-class Ex05.html",
    "title": "In-class_Ex05",
    "section": "",
    "text": "pacman::p_load(tidyverse,readxl,SmartEDA,easystats,gtsummary,ggstatsplot)"
  },
  {
    "objectID": "In-class ex/In-class ex05/In-class Ex05.html#getting-started",
    "href": "In-class ex/In-class ex05/In-class Ex05.html#getting-started",
    "title": "In-class_Ex05",
    "section": "",
    "text": "pacman::p_load(tidyverse,readxl,SmartEDA,easystats,gtsummary,ggstatsplot)"
  },
  {
    "objectID": "In-class ex/In-class ex05/In-class Ex05.html#importing-data",
    "href": "In-class ex/In-class ex05/In-class Ex05.html#importing-data",
    "title": "In-class_Ex05",
    "section": "Importing Data",
    "text": "Importing Data\n\ncar_resale &lt;-\nread_xls(\"/Users/geloliu/Gelo-608/ISSS608/In-class ex/In-class ex05/data/ToyotaCorolla.xls\")\n\n\nlist(car_resale)\n\n[[1]]\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\n\nsummary(car_resale)\n\n       Id            Model               Price         Age_08_04    \n Min.   :   1.0   Length:1436        Min.   : 4350   Min.   : 1.00  \n 1st Qu.: 361.8   Class :character   1st Qu.: 8450   1st Qu.:44.00  \n Median : 721.5   Mode  :character   Median : 9900   Median :61.00  \n Mean   : 721.6                      Mean   :10731   Mean   :55.95  \n 3rd Qu.:1081.2                      3rd Qu.:11950   3rd Qu.:70.00  \n Max.   :1442.0                      Max.   :32500   Max.   :80.00  \n   Mfg_Month         Mfg_Year          KM         Quarterly_Tax   \n Min.   : 1.000   Min.   :1998   Min.   :     1   Min.   : 19.00  \n 1st Qu.: 3.000   1st Qu.:1998   1st Qu.: 43000   1st Qu.: 69.00  \n Median : 5.000   Median :1999   Median : 63390   Median : 85.00  \n Mean   : 5.549   Mean   :2000   Mean   : 68533   Mean   : 87.12  \n 3rd Qu.: 8.000   3rd Qu.:2001   3rd Qu.: 87021   3rd Qu.: 85.00  \n Max.   :12.000   Max.   :2004   Max.   :243000   Max.   :283.00  \n     Weight     Guarantee_Period    HP_Bin             CC_bin         \n Min.   :1000   Min.   : 3.000   Length:1436        Length:1436       \n 1st Qu.:1040   1st Qu.: 3.000   Class :character   Class :character  \n Median :1070   Median : 3.000   Mode  :character   Mode  :character  \n Mean   :1072   Mean   : 3.815                                        \n 3rd Qu.:1085   3rd Qu.: 3.000                                        \n Max.   :1615   Max.   :36.000                                        \n     Doors           Gears         Cylinders  Fuel_Type        \n Min.   :2.000   Min.   :3.000   Min.   :4   Length:1436       \n 1st Qu.:3.000   1st Qu.:5.000   1st Qu.:4   Class :character  \n Median :4.000   Median :5.000   Median :4   Mode  :character  \n Mean   :4.033   Mean   :5.026   Mean   :4                     \n 3rd Qu.:5.000   3rd Qu.:5.000   3rd Qu.:4                     \n Max.   :5.000   Max.   :6.000   Max.   :4                     \n    Color             Met_Color        Automatic       Mfr_Guarantee   \n Length:1436        Min.   :0.0000   Min.   :0.00000   Min.   :0.0000  \n Class :character   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000  \n Mode  :character   Median :1.0000   Median :0.00000   Median :0.0000  \n                    Mean   :0.6748   Mean   :0.05571   Mean   :0.4095  \n                    3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:1.0000  \n                    Max.   :1.0000   Max.   :1.00000   Max.   :1.0000  \n BOVAG_Guarantee       ABS            Airbag_1         Airbag_2     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:1.0000   1st Qu.:1.0000   1st Qu.:1.0000   1st Qu.:0.0000  \n Median :1.0000   Median :1.0000   Median :1.0000   Median :1.0000  \n Mean   :0.8955   Mean   :0.8134   Mean   :0.9708   Mean   :0.7228  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n     Airco        Automatic_airco   Boardcomputer      CD_Player     \n Min.   :0.0000   Min.   :0.00000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :1.0000   Median :0.00000   Median :0.0000   Median :0.0000  \n Mean   :0.5084   Mean   :0.05641   Mean   :0.2946   Mean   :0.2187  \n 3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:1.0000   3rd Qu.:0.0000  \n Max.   :1.0000   Max.   :1.00000   Max.   :1.0000   Max.   :1.0000  \n  Central_Lock    Powered_Windows Power_Steering       Radio       \n Min.   :0.0000   Min.   :0.000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:1.0000   1st Qu.:0.0000  \n Median :1.0000   Median :1.000   Median :1.0000   Median :0.0000  \n Mean   :0.5801   Mean   :0.562   Mean   :0.9777   Mean   :0.1462  \n 3rd Qu.:1.0000   3rd Qu.:1.000   3rd Qu.:1.0000   3rd Qu.:0.0000  \n Max.   :1.0000   Max.   :1.000   Max.   :1.0000   Max.   :1.0000  \n   Mistlamps      Sport_Model     Backseat_Divider  Metallic_Rim   \n Min.   :0.000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.000   1st Qu.:0.0000   1st Qu.:1.0000   1st Qu.:0.0000  \n Median :0.000   Median :0.0000   Median :1.0000   Median :0.0000  \n Mean   :0.257   Mean   :0.3001   Mean   :0.7702   Mean   :0.2047  \n 3rd Qu.:1.000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000  \n Max.   :1.000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n Radio_cassette      Tow_Bar      \n Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000  \n Mean   :0.1455   Mean   :0.2779  \n 3rd Qu.:0.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000  \n\n\n\nglimpse(car_resale)\n\nRows: 1,436\nColumns: 38\n$ Id               &lt;dbl&gt; 81, 1, 2, 3, 4, 5, 6, 7, 8, 44, 45, 46, 47, 49, 51, 6…\n$ Model            &lt;chr&gt; \"TOYOTA Corolla 1.6 5drs 1 4/5-Doors\", \"TOYOTA Coroll…\n$ Price            &lt;dbl&gt; 18950, 13500, 13750, 13950, 14950, 13750, 12950, 1690…\n$ Age_08_04        &lt;dbl&gt; 25, 23, 23, 24, 26, 30, 32, 27, 30, 27, 22, 23, 27, 2…\n$ Mfg_Month        &lt;dbl&gt; 8, 10, 10, 9, 7, 3, 1, 6, 3, 6, 11, 10, 6, 11, 11, 11…\n$ Mfg_Year         &lt;dbl&gt; 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002,…\n$ KM               &lt;dbl&gt; 20019, 46986, 72937, 41711, 48000, 38500, 61000, 9461…\n$ Quarterly_Tax    &lt;dbl&gt; 100, 210, 210, 210, 210, 210, 210, 210, 210, 234, 234…\n$ Weight           &lt;dbl&gt; 1180, 1165, 1165, 1165, 1165, 1170, 1170, 1245, 1245,…\n$ Guarantee_Period &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,…\n$ HP_Bin           &lt;chr&gt; \"100-120\", \"&lt; 100\", \"&lt; 100\", \"&lt; 100\", \"&lt; 100\", \"&lt; 100…\n$ CC_bin           &lt;chr&gt; \"1600\", \"&gt;1600\", \"&gt;1600\", \"&gt;1600\", \"&gt;1600\", \"&gt;1600\", …\n$ Doors            &lt;dbl&gt; 5, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 3, 3,…\n$ Gears            &lt;dbl&gt; 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,…\n$ Cylinders        &lt;dbl&gt; 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,…\n$ Fuel_Type        &lt;chr&gt; \"Petrol\", \"Diesel\", \"Diesel\", \"Diesel\", \"Diesel\", \"Di…\n$ Color            &lt;chr&gt; \"Blue\", \"Blue\", \"Silver\", \"Blue\", \"Black\", \"Black\", \"…\n$ Met_Color        &lt;dbl&gt; 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,…\n$ Automatic        &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Mfr_Guarantee    &lt;dbl&gt; 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1,…\n$ BOVAG_Guarantee  &lt;dbl&gt; 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ ABS              &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Airbag_1         &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Airbag_2         &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Airco            &lt;dbl&gt; 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Automatic_airco  &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,…\n$ Boardcomputer    &lt;dbl&gt; 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ CD_Player        &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,…\n$ Central_Lock     &lt;dbl&gt; 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Powered_Windows  &lt;dbl&gt; 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Power_Steering   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Radio            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Mistlamps        &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Sport_Model      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,…\n$ Backseat_Divider &lt;dbl&gt; 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Metallic_Rim     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Radio_cassette   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Tow_Bar          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…"
  },
  {
    "objectID": "In-class ex/In-class ex05/In-class Ex05.html#data-overview",
    "href": "In-class ex/In-class ex05/In-class Ex05.html#data-overview",
    "title": "In-class_Ex05",
    "section": "Data Overview",
    "text": "Data Overview\n\ncar_resale %&gt;%\n  ExpData(type = 1)\n\n                                          Descriptions     Value\n1                                   Sample size (nrow)      1436\n2                              No. of variables (ncol)        38\n3                    No. of numeric/interger variables        33\n4                              No. of factor variables         0\n5                                No. of text variables         5\n6                             No. of logical variables         0\n7                          No. of identifier variables         1\n8                                No. of date variables         0\n9             No. of zero variance variables (uniform)         1\n10               %. of variables having complete cases 100% (38)\n11   %. of variables having &gt;0% and &lt;50% missing cases    0% (0)\n12 %. of variables having &gt;=50% and &lt;90% missing cases    0% (0)\n13          %. of variables having &gt;=90% missing cases    0% (0)\n\n\n\ncar_resale %&gt;%\n  ExpData(type = 2)\n\n   Index    Variable_Name Variable_Type Sample_n Missing_Count Per_of_Missing\n1      1               Id       numeric     1436             0              0\n2      2            Model     character     1436             0              0\n3      3            Price       numeric     1436             0              0\n4      4        Age_08_04       numeric     1436             0              0\n5      5        Mfg_Month       numeric     1436             0              0\n6      6         Mfg_Year       numeric     1436             0              0\n7      7               KM       numeric     1436             0              0\n8      8    Quarterly_Tax       numeric     1436             0              0\n9      9           Weight       numeric     1436             0              0\n10    10 Guarantee_Period       numeric     1436             0              0\n11    11           HP_Bin     character     1436             0              0\n12    12           CC_bin     character     1436             0              0\n13    13            Doors       numeric     1436             0              0\n14    14            Gears       numeric     1436             0              0\n15    15        Cylinders       numeric     1436             0              0\n16    16        Fuel_Type     character     1436             0              0\n17    17            Color     character     1436             0              0\n18    18        Met_Color       numeric     1436             0              0\n19    19        Automatic       numeric     1436             0              0\n20    20    Mfr_Guarantee       numeric     1436             0              0\n21    21  BOVAG_Guarantee       numeric     1436             0              0\n22    22              ABS       numeric     1436             0              0\n23    23         Airbag_1       numeric     1436             0              0\n24    24         Airbag_2       numeric     1436             0              0\n25    25            Airco       numeric     1436             0              0\n26    26  Automatic_airco       numeric     1436             0              0\n27    27    Boardcomputer       numeric     1436             0              0\n28    28        CD_Player       numeric     1436             0              0\n29    29     Central_Lock       numeric     1436             0              0\n30    30  Powered_Windows       numeric     1436             0              0\n31    31   Power_Steering       numeric     1436             0              0\n32    32            Radio       numeric     1436             0              0\n33    33        Mistlamps       numeric     1436             0              0\n34    34      Sport_Model       numeric     1436             0              0\n35    35 Backseat_Divider       numeric     1436             0              0\n36    36     Metallic_Rim       numeric     1436             0              0\n37    37   Radio_cassette       numeric     1436             0              0\n38    38          Tow_Bar       numeric     1436             0              0\n   No_of_distinct_values\n1                   1436\n2                    372\n3                    236\n4                     77\n5                     12\n6                      7\n7                   1263\n8                     13\n9                     59\n10                     9\n11                     3\n12                     3\n13                     4\n14                     4\n15                     1\n16                     3\n17                    10\n18                     2\n19                     2\n20                     2\n21                     2\n22                     2\n23                     2\n24                     2\n25                     2\n26                     2\n27                     2\n28                     2\n29                     2\n30                     2\n31                     2\n32                     2\n33                     2\n34                     2\n35                     2\n36                     2\n37                     2\n38                     2\n\n\n\ncols &lt;- c(\"Mfg_Month\", \"HP_Bin\", \"CC_bin\", \"Doors\", \"Gears\", \"Cylinders\",\n          \"Fuel_Type\", \"Color\", \"Met_Color\", \"Automatic\", \"Mfr_Guarantee\",\n          \"BOVAG_Guarantee\", \"ABS\",\"Airbag_1\", \"Airbag_2\", \"Airco\",\n          \"Automatic_airco\", \"Boardcomputer\", \n          \"CD_Player\", \"Central_Lock\", \"Powered_Windows\", \"Power_Steering\",\n          \"Radio\",\"Mistlamps\", \"Sport_Model\", \"Backseat_Divider\", \"Metallic_Rim\", \n          \"Radio_cassette\", \"Tow_Bar\")\n\n\ncar_resale &lt;- read_xls(\"/Users/geloliu/Gelo-608/ISSS608/In-class ex/In-class ex05/data/ToyotaCorolla.xls\", sheet = \"data\") %&gt;%\n  mutate(Id = as.character(Id)) %&gt;%\n  mutate(across(cols, as.factor))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(cols, as.factor)`.\nCaused by warning:\n! Using an external vector in selections was deprecated in tidyselect 1.1.0.\nℹ Please use `all_of()` or `any_of()` instead.\n  # Was:\n  data %&gt;% select(cols)\n\n  # Now:\n  data %&gt;% select(all_of(cols))\n\nSee &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.\n\n\n\ncar_resale %&gt;%\n  ExpNumViz(target = NULL,\n            nlim = 10,\n            Page = c(2,2))\n\n$`0`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncar_resale %&gt;%\n  ExpNumViz(target = \"Price\",\n            nlim = 10,\n            Page = c(2,2),\n            col = \"#96C6D999\")\n\n$`0`\n\n\n\n\n\n\n\n\n\n\n#|fig-width: 15\n#|fig-height: 15\n\ncar_resale %&gt;%\n  ExpCatViz(target = NULL,\n            clim = 10,\n            col = \"#96C6D999\",\n            margin = 2,\n            Page = c(4,4),\n            sample = 16)\n\n$`0`"
  },
  {
    "objectID": "In-class ex/In-class ex05/In-class Ex05.html#model-1",
    "href": "In-class ex/In-class ex05/In-class Ex05.html#model-1",
    "title": "In-class_Ex05",
    "section": "Model 1",
    "text": "Model 1\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year +KM +\n              Weight + Guarantee_Period,data = car_resale)\n\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)"
  },
  {
    "objectID": "In-class ex/In-class ex05/In-class Ex05.html#model-1-1",
    "href": "In-class ex/In-class ex05/In-class Ex05.html#model-1-1",
    "title": "In-class_Ex05",
    "section": "Model 1:",
    "text": "Model 1:\n\nmodel1 &lt;- lm(Price ~ Age_08_04 +KM +\n              Weight + Guarantee_Period,data = car_resale)\n\n\ncheck_normality(model1)\n\nWarning: Non-normality of residuals detected (p &lt; .001).\n\n\n\np_model1 &lt;- parameters((model1))\n\n\nplot(parameters(model1))\n\n\n\n\n\n\n\n\n\ntbl_regression(model1,\n               intercept = TRUE) %&gt;%\n  add_glance_source_note(label = list(sigma~\"/U03C3\"),\n                         include = c(r.squared,adj.r.squared,\n                                     AIC,statistic,sigma)\n                         )\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n-2,186\n-4,093, -278\n0.025\n    Age_08_04\n-119\n-125, -114\n&lt;0.001\n    KM\n-0.02\n-0.03, -0.02\n&lt;0.001\n    Weight\n20\n18, 21\n&lt;0.001\n    Guarantee_Period\n27\n2.1, 52\n0.034\n  \n  \n    \n      R² = 0.849; Adjusted R² = 0.848; AIC = 24,915; Statistic = 2,005; /U03C3 = 1,413\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\nggcoefstats(model1,\n            output =\"plot\")"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 01/Hands-on ex 01.html",
    "href": "Hands-on Exercises/Hands-on Ex 01/Hands-on ex 01.html",
    "title": "Hands on exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched in to R.\n\npacman::p_load(tidyverse)\n\n\n\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 01/Hands-on ex 01.html#install-and-launching-r-packages",
    "href": "Hands-on Exercises/Hands-on Ex 01/Hands-on ex 01.html#install-and-launching-r-packages",
    "title": "Hands on exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched in to R.\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 01/Hands-on ex 01.html#importing-the-data",
    "href": "Hands-on Exercises/Hands-on Ex 01/Hands-on ex 01.html#importing-the-data",
    "title": "Hands on exercise 1",
    "section": "",
    "text": "exam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 03/Hands-on Ex 3.2.html",
    "href": "Hands-on Exercises/Hands-on Ex 03/Hands-on Ex 3.2.html",
    "title": "Hands-on Ex 3.2",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, you will learn how to create animated data visualisation by using gganimate and plotly r packages. At the same time, you will also learn how to (i) reshape data by using tidyr package, and (ii) process, wrangle and transform data by using dplyr package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\n\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\nTip:\nBefore you start making animated graphs, you should first ask yourself: Does it makes sense to go through the effort? If you are conducting an exploratory data analysis, a animated graphic may not be worth the time investment. However, if you are giving a presentation, a few well-placed animated graphics can help an audience connect with your topic remarkably better than static counterparts.\n\n\n\n\n\n\nFirst, write a code chunk to check, install and load the following R packages:\n\nplotly, R library for plotting interactive statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)\n\n\n\n\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\nWrite a code chunk to import Data worksheet from GlobalPopulation Excel workbook by using appropriate R package from tidyverse family.\n\ncol &lt;- c(\"Country\", \"Continent\")\n\nglobalPop &lt;- read_excel(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 03/data/data-2/GlobalPopulation.xls\",\n                        sheet = \"Data\") %&gt;%\n  mutate(across(all_of(col), as.factor)) %&gt;%  \n  mutate(Year = as.integer(Year)) \n\nThings to learn from the code chunk above\n\nread_xls() of readxl package is used to import the Excel worksheet.\nmutate_each_() of dplyr package is used to convert all character data type into factor.\nmutate of dplyr package is used to convert data values of Year field into integer.\n\nUnfortunately, mutate_each_() was deprecated in dplyr 0.7.0. and funs()was deprecated in dplyr 0.8.0. In view of this, we will re-write the code by using mutate_at() as shown in the code chunk below.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 03/data/data-2/GlobalPopulation.xls\",\n                        sheet = \"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\n\nInstead of using mutate_at(), across() can be used to derive the same outputs.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 03/data/data-2/GlobalPopulation.xls\",\n                        sheet = \"Data\") %&gt;%\n  mutate(across(col, as.factor)) %&gt;%\n  mutate(Year = as.integer(Year))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(col, as.factor)`.\nCaused by warning:\n! Using an external vector in selections was deprecated in tidyselect 1.1.0.\nℹ Please use `all_of()` or `any_of()` instead.\n  # Was:\n  data %&gt;% select(col)\n\n  # Now:\n  data %&gt;% select(all_of(col))\n\nSee &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.\n\n\n\n\n\n\ngganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\n\nIn the code chunk below, the basic ggplot2 functions are used to create a static bubble plot.\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear') \n\n\n\n\n\n\n\n\nThe animated bubble chart\n\n\n\n\nIn Plotly R package, both ggplotly() and plot_ly() support key frame animations through the frame argument/aesthetic. They also support an ids argument/aesthetic to ensure smooth transitions between objects with the same id (which helps facilitate object constancy).\n\n\nIn this sub-section, you will learn how to create an animated bubble plot by using ggplotly() method.\n\nlibrary(ggplot2)\nlibrary(gganimate)\nlibrary(plotly)\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(alpha = 0.7, show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) \nanimate(gg)  \n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\nAppropriate ggplot2 functions are used to create a static bubble plot. The output is then saved as an R object called gg.\nggplotly() is then used to convert the R graphic object into an animated svg object.\n\nNotice that although show.legend = FALSE argument was used, the legend still appears on the plot. To overcome this problem, theme(legend.position='none') should be used as shown in the plot and code chunk below.\n\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(gganimate)\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(alpha = 0.7) +  # 移除 frame = Year\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', y = '% Young') + \n  theme(legend.position='none') +\n  transition_time(Year)  \n\nggplotly(gg)\n\n\n\n\n\n\n\n\nIn this sub-section, you will learn how to create an animated bubble plot by using plot_ly() method.\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent,\n          sizes = c(2, 100),\n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\nbp  \n\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\n\n\n\n\n\n\n\n\n\n\nGetting Started Visit this link for a very interesting implementation of gganimate by your senior. Building an animation step-by-step with gganimate. Creating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 03/Hands-on Ex 3.2.html#overview",
    "href": "Hands-on Exercises/Hands-on Ex 03/Hands-on Ex 3.2.html#overview",
    "title": "Hands-on Ex 3.2",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, you will learn how to create animated data visualisation by using gganimate and plotly r packages. At the same time, you will also learn how to (i) reshape data by using tidyr package, and (ii) process, wrangle and transform data by using dplyr package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\n\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\nTip:\nBefore you start making animated graphs, you should first ask yourself: Does it makes sense to go through the effort? If you are conducting an exploratory data analysis, a animated graphic may not be worth the time investment. However, if you are giving a presentation, a few well-placed animated graphics can help an audience connect with your topic remarkably better than static counterparts."
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 03/Hands-on Ex 3.2.html#getting-started",
    "href": "Hands-on Exercises/Hands-on Ex 03/Hands-on Ex 3.2.html#getting-started",
    "title": "Hands-on Ex 3.2",
    "section": "",
    "text": "First, write a code chunk to check, install and load the following R packages:\n\nplotly, R library for plotting interactive statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)\n\n\n\n\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\nWrite a code chunk to import Data worksheet from GlobalPopulation Excel workbook by using appropriate R package from tidyverse family.\n\ncol &lt;- c(\"Country\", \"Continent\")\n\nglobalPop &lt;- read_excel(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 03/data/data-2/GlobalPopulation.xls\",\n                        sheet = \"Data\") %&gt;%\n  mutate(across(all_of(col), as.factor)) %&gt;%  \n  mutate(Year = as.integer(Year)) \n\nThings to learn from the code chunk above\n\nread_xls() of readxl package is used to import the Excel worksheet.\nmutate_each_() of dplyr package is used to convert all character data type into factor.\nmutate of dplyr package is used to convert data values of Year field into integer.\n\nUnfortunately, mutate_each_() was deprecated in dplyr 0.7.0. and funs()was deprecated in dplyr 0.8.0. In view of this, we will re-write the code by using mutate_at() as shown in the code chunk below.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 03/data/data-2/GlobalPopulation.xls\",\n                        sheet = \"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\n\nInstead of using mutate_at(), across() can be used to derive the same outputs.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 03/data/data-2/GlobalPopulation.xls\",\n                        sheet = \"Data\") %&gt;%\n  mutate(across(col, as.factor)) %&gt;%\n  mutate(Year = as.integer(Year))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(col, as.factor)`.\nCaused by warning:\n! Using an external vector in selections was deprecated in tidyselect 1.1.0.\nℹ Please use `all_of()` or `any_of()` instead.\n  # Was:\n  data %&gt;% select(col)\n\n  # Now:\n  data %&gt;% select(all_of(col))\n\nSee &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;."
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 03/Hands-on Ex 3.2.html#animated-data-visualisation-gganimate-methods",
    "href": "Hands-on Exercises/Hands-on Ex 03/Hands-on Ex 3.2.html#animated-data-visualisation-gganimate-methods",
    "title": "Hands-on Ex 3.2",
    "section": "",
    "text": "gganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\n\nIn the code chunk below, the basic ggplot2 functions are used to create a static bubble plot.\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear') \n\n\n\n\n\n\n\n\nThe animated bubble chart"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 03/Hands-on Ex 3.2.html#animated-data-visualisation-plotly",
    "href": "Hands-on Exercises/Hands-on Ex 03/Hands-on Ex 3.2.html#animated-data-visualisation-plotly",
    "title": "Hands-on Ex 3.2",
    "section": "",
    "text": "In Plotly R package, both ggplotly() and plot_ly() support key frame animations through the frame argument/aesthetic. They also support an ids argument/aesthetic to ensure smooth transitions between objects with the same id (which helps facilitate object constancy).\n\n\nIn this sub-section, you will learn how to create an animated bubble plot by using ggplotly() method.\n\nlibrary(ggplot2)\nlibrary(gganimate)\nlibrary(plotly)\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(alpha = 0.7, show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) \nanimate(gg)  \n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\nAppropriate ggplot2 functions are used to create a static bubble plot. The output is then saved as an R object called gg.\nggplotly() is then used to convert the R graphic object into an animated svg object.\n\nNotice that although show.legend = FALSE argument was used, the legend still appears on the plot. To overcome this problem, theme(legend.position='none') should be used as shown in the plot and code chunk below.\n\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(gganimate)\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(alpha = 0.7) +  # 移除 frame = Year\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', y = '% Young') + \n  theme(legend.position='none') +\n  transition_time(Year)  \n\nggplotly(gg)\n\n\n\n\n\n\n\n\nIn this sub-section, you will learn how to create an animated bubble plot by using plot_ly() method.\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent,\n          sizes = c(2, 100),\n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\nbp  \n\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values.\nWarning: `line.width` does not currently support multiple values."
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 03/Hands-on Ex 3.2.html#reference",
    "href": "Hands-on Exercises/Hands-on Ex 03/Hands-on Ex 3.2.html#reference",
    "title": "Hands-on Ex 3.2",
    "section": "",
    "text": "Getting Started Visit this link for a very interesting implementation of gganimate by your senior. Building an animation step-by-step with gganimate. Creating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-1.html",
    "href": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-1.html",
    "title": "Hands-on Exercise 4-1",
    "section": "",
    "text": "In Chapter 1, we introduced common methods for visualizing distributions, such as histograms, probability density curves (PDF), boxplots, notch plots, and violin plots using ggplot2. This chapter will cover two newer visualization techniques: ridgeline plots and raincloud plots, created with ggplot2 and its extensions.\n\n\n\n\n\nFor the purpose of this exercise, the following R packages will be used, they are:\n\nggridges, a ggplot2 extension specially designed for plotting ridgeline plots,\nggdist, a ggplot2 extension spacially desgin for visualising distribution and uncertainty,\ntidyverse, a family of R packages to meet the modern data science and visual communication needs,\nggthemes, a ggplot extension that provides the user additional themes, scales, and geoms for the ggplots package, and\ncolorspace, an R package provides a broad toolbox for selecting individual colors or color palettes, manipulating these colors, and employing them in various kinds of visualisations.\n\nThe code chunk below will be used load these R packages into RStudio environment.\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse)\n\n\n\n\nFor the purpose of this exercise, Exam_data.csv will be used.\nIn the code chunk below, read_csv() of readr package is used to import Exam_data.csv into R and saved it into a tibble data.frame.\n\nexam_data &lt;- read_csv(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 04/data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\nRidgeline plot (sometimes called Joyplot) is a data visualisation technique for revealing the distribution of a numeric value for several groups. Distribution can be represented using histograms or density plots, all aligned to the same horizontal scale and presented with a slight overlap.\nFigure below is a ridgelines plot showing the distribution of English score by class.\n\nNote\n\nRidgeline plots make sense when the number of group to represent is medium to high, and thus a classic window separation would take to much space. Indeed, the fact that groups overlap each other allows to use space more efficiently. If you have less than 5 groups, dealing with other distribution plots is probably better.\nIt works well when there is a clear pattern in the result, like if there is an obvious ranking in groups. Otherwise group will tend to overlap each other, leading to a messy plot not providing any insight.\n\n\n\nThere are several ways to plot ridgeline plot with R. In this section, you will learn how to plot ridgeline plot by using ggridges package.\nggridges package provides two main geom to plot gridgeline plots, they are: geom_ridgeline() and geom_density_ridges(). The former takes height values directly to draw the ridgelines, and the latter first estimates data densities and then draws those using ridgelines.\nThe ridgeline plot below is plotted by using geom_density_ridges().\n\nggplot(exam_data, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\nSometimes we would like to have the area under a ridgeline not filled with a single solid color but rather with colors that vary in some form along the x axis. This effect can be achieved by using either geom_ridgeline_gradient() or geom_density_ridges_gradient(). Both geoms work just like geom_ridgeline() and geom_density_ridges(), except that they allow for varying fill colors. However, they do not allow for alpha transparency in the fill. For technical reasons, we can have changing fill colors or transparency but not both.\n\nggplot(exam_data, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill=after_stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\nPicking joint bandwidth of 3.18\n\n\n\n\n\n\n\n\n\n\n\n\nBeside providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density()of ggplot2.\nFigure below is plotted by mapping the probabilities calculated by using stat(ecdf) which represent the empirical cumulative density function for the distribution of English score.\n\nggplot(exam_data,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()\n\nWarning: `stat(ecdf)` was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(ecdf)` instead.\n\n\nPicking joint bandwidth of 3.18\n\n\n\n\n\n\n\n\n\n⚠️ Important\nIt is important include the argument calc_ecdf = TRUE in stat_density_ridges().\n\n\n\nBy using geom_density_ridges_gradient(), we can colour the ridgeline plot by quantile, via the calculated stat(quantile)aesthetic as shown in the figure below.\n\nggplot(exam_data,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\nPicking joint bandwidth of 3.18\n\n\n\n\n\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nggplot(exam_data,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()\n\nPicking joint bandwidth of 3.18\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Raincloud Plot is a data visualization technique that shows a half-density distribution, resembling a “raincloud.” It enhances the traditional boxplot by highlighting multiple modalities, indicating potential groups. While boxplots don’t show where densities cluster, raincloud plots do. In this section, you will learn how to create a raincloud plot to visualize English scores by race using ggdist and ggplot2.\n\n\nFirst, we will plot a Half-Eye graph by using stat_halfeye() of ggdist package.\nThis produces a Half Eye visualization, which is contains a half-density and a slab-interval.\n\nggplot(exam_data, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n\n\n\n\n\n\n\n\nNext, we will add the second geometry layer using geom_boxplot() of ggplot2. This produces a narrow boxplot. We reduce the width and adjust the opacity.\n\nggplot(exam_data, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\n\n\n\n\n\nNext, we will add the third geometry layer using stat_dots() of ggdist package. This produces a half-dotplot, which is similar to a histogram that indicates the number of samples (number of dots) in each bin. We select side = “left” to indicate we want it on the left-hand side.\n\nggplot(exam_data, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n\n\n\n\n\nLastly, coord_flip() of ggplot2 package will be used to flip the raincloud chart horizontally to give it the raincloud appearance. At the same time, theme_economist() of ggthemes package is used to give the raincloud chart a professional publishing standard look.\n\nggplot(exam_data, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = NA,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()\n\n\n\n\n\n\n\n\nReference\n\nIntroducing Ridgeline Plots (formerly Joyplots)\nClaus O. Wilke Fundamentals of Data Visualization especially Chapter 6, 7, 8, 9 and 10.\nAllen M, Poggiali D, Whitaker K et al. “Raincloud plots: a multi-platform tool for robust data. visualization” [version 2; peer review: 2 approved]. Welcome Open Res 2021, pp. 4:63.\nDots + interval stats and geoms"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-1.html#learning-outcome",
    "href": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-1.html#learning-outcome",
    "title": "Hands-on Exercise 4-1",
    "section": "",
    "text": "In Chapter 1, we introduced common methods for visualizing distributions, such as histograms, probability density curves (PDF), boxplots, notch plots, and violin plots using ggplot2. This chapter will cover two newer visualization techniques: ridgeline plots and raincloud plots, created with ggplot2 and its extensions."
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-1.html#getting-started",
    "href": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-1.html#getting-started",
    "title": "Hands-on Exercise 4-1",
    "section": "",
    "text": "For the purpose of this exercise, the following R packages will be used, they are:\n\nggridges, a ggplot2 extension specially designed for plotting ridgeline plots,\nggdist, a ggplot2 extension spacially desgin for visualising distribution and uncertainty,\ntidyverse, a family of R packages to meet the modern data science and visual communication needs,\nggthemes, a ggplot extension that provides the user additional themes, scales, and geoms for the ggplots package, and\ncolorspace, an R package provides a broad toolbox for selecting individual colors or color palettes, manipulating these colors, and employing them in various kinds of visualisations.\n\nThe code chunk below will be used load these R packages into RStudio environment.\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse)\n\n\n\n\nFor the purpose of this exercise, Exam_data.csv will be used.\nIn the code chunk below, read_csv() of readr package is used to import Exam_data.csv into R and saved it into a tibble data.frame.\n\nexam_data &lt;- read_csv(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 04/data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-1.html#visualising-distribution-with-ridgeline-plot",
    "href": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-1.html#visualising-distribution-with-ridgeline-plot",
    "title": "Hands-on Exercise 4-1",
    "section": "",
    "text": "Ridgeline plot (sometimes called Joyplot) is a data visualisation technique for revealing the distribution of a numeric value for several groups. Distribution can be represented using histograms or density plots, all aligned to the same horizontal scale and presented with a slight overlap.\nFigure below is a ridgelines plot showing the distribution of English score by class.\n\nNote\n\nRidgeline plots make sense when the number of group to represent is medium to high, and thus a classic window separation would take to much space. Indeed, the fact that groups overlap each other allows to use space more efficiently. If you have less than 5 groups, dealing with other distribution plots is probably better.\nIt works well when there is a clear pattern in the result, like if there is an obvious ranking in groups. Otherwise group will tend to overlap each other, leading to a messy plot not providing any insight.\n\n\n\nThere are several ways to plot ridgeline plot with R. In this section, you will learn how to plot ridgeline plot by using ggridges package.\nggridges package provides two main geom to plot gridgeline plots, they are: geom_ridgeline() and geom_density_ridges(). The former takes height values directly to draw the ridgelines, and the latter first estimates data densities and then draws those using ridgelines.\nThe ridgeline plot below is plotted by using geom_density_ridges().\n\nggplot(exam_data, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\nSometimes we would like to have the area under a ridgeline not filled with a single solid color but rather with colors that vary in some form along the x axis. This effect can be achieved by using either geom_ridgeline_gradient() or geom_density_ridges_gradient(). Both geoms work just like geom_ridgeline() and geom_density_ridges(), except that they allow for varying fill colors. However, they do not allow for alpha transparency in the fill. For technical reasons, we can have changing fill colors or transparency but not both.\n\nggplot(exam_data, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill=after_stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\nPicking joint bandwidth of 3.18\n\n\n\n\n\n\n\n\n\n\n\n\nBeside providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density()of ggplot2.\nFigure below is plotted by mapping the probabilities calculated by using stat(ecdf) which represent the empirical cumulative density function for the distribution of English score.\n\nggplot(exam_data,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()\n\nWarning: `stat(ecdf)` was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(ecdf)` instead.\n\n\nPicking joint bandwidth of 3.18\n\n\n\n\n\n\n\n\n\n⚠️ Important\nIt is important include the argument calc_ecdf = TRUE in stat_density_ridges().\n\n\n\nBy using geom_density_ridges_gradient(), we can colour the ridgeline plot by quantile, via the calculated stat(quantile)aesthetic as shown in the figure below.\n\nggplot(exam_data,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\nPicking joint bandwidth of 3.18\n\n\n\n\n\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nggplot(exam_data,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()\n\nPicking joint bandwidth of 3.18"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-1.html#visualising-distribution-with-raincloud-plot",
    "href": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-1.html#visualising-distribution-with-raincloud-plot",
    "title": "Hands-on Exercise 4-1",
    "section": "",
    "text": "A Raincloud Plot is a data visualization technique that shows a half-density distribution, resembling a “raincloud.” It enhances the traditional boxplot by highlighting multiple modalities, indicating potential groups. While boxplots don’t show where densities cluster, raincloud plots do. In this section, you will learn how to create a raincloud plot to visualize English scores by race using ggdist and ggplot2.\n\n\nFirst, we will plot a Half-Eye graph by using stat_halfeye() of ggdist package.\nThis produces a Half Eye visualization, which is contains a half-density and a slab-interval.\n\nggplot(exam_data, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n\n\n\n\n\n\n\n\nNext, we will add the second geometry layer using geom_boxplot() of ggplot2. This produces a narrow boxplot. We reduce the width and adjust the opacity.\n\nggplot(exam_data, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\n\n\n\n\n\nNext, we will add the third geometry layer using stat_dots() of ggdist package. This produces a half-dotplot, which is similar to a histogram that indicates the number of samples (number of dots) in each bin. We select side = “left” to indicate we want it on the left-hand side.\n\nggplot(exam_data, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n\n\n\n\n\nLastly, coord_flip() of ggplot2 package will be used to flip the raincloud chart horizontally to give it the raincloud appearance. At the same time, theme_economist() of ggthemes package is used to give the raincloud chart a professional publishing standard look.\n\nggplot(exam_data, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = NA,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()\n\n\n\n\n\n\n\n\nReference\n\nIntroducing Ridgeline Plots (formerly Joyplots)\nClaus O. Wilke Fundamentals of Data Visualization especially Chapter 6, 7, 8, 9 and 10.\nAllen M, Poggiali D, Whitaker K et al. “Raincloud plots: a multi-platform tool for robust data. visualization” [version 2; peer review: 2 approved]. Welcome Open Res 2021, pp. 4:63.\nDots + interval stats and geoms"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-3.html",
    "href": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-3.html",
    "title": "Hands-on Exercise 4-3",
    "section": "",
    "text": "Visualising uncertainty is relatively new in statistical graphics. In this chapter, you will gain hands-on experience on creating statistical graphics for visualising uncertainty. By the end of this chapter you will be able:\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package.\n\n\n\n\n\n\nFor the purpose of this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering), and\nggdist for visualising distribution and uncertainty.\n\n\npacman::p_load(plotly, crosstalk, DT, \n               ggdist, ggridges, colorspace,\n               gganimate, tidyverse)\n\n\n\n\nFor the purpose of this exercise, Exam_data.csv will be used.\n\nexam_data &lt;- read_csv(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 04/data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\nA point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval.\nImportant: Don’t confuse the uncertainty of a point estimate with the variation in the sample\nIn this section, you will learn how to plot error bars of maths scores by race by using data provided in exam tibble data frame.\nFirstly, code chunk below will be used to derive the necessary summary statistics.\n\nmy_sum &lt;- exam_data %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\n💡 Things to learn from the code chunk above\n\ngroup_by() of dplyr package is used to group the observation by RACE,\nsummarise() is used to compute the count of observations, mean, standard deviation\nmutate() is used to derive standard error of Maths by RACE, and\nthe output is save as a tibble data table called my_sum.\n\nNext, the code chunk below will be used to display my_sum tibble data frame in an html table format.\n\nsuppressWarnings\n\nfunction (expr, classes = \"warning\") \n{\n    withCallingHandlers(expr, warning = function(w) if (inherits(w, \n        classes)) \n        tryInvokeRestart(\"muffleWarning\"))\n}\n&lt;bytecode: 0x141195a00&gt;\n&lt;environment: namespace:base&gt;\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n\nNow we are ready to plot the standard error bars of mean maths score by race as shown below.\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by rac\")\n\n\n\n\n\n\n\n\n💡 Things to learn from the code chunk above\n\nThe error bars are computed by using the formula mean+/-se.\nFor geom_point(), it is important to indicate stat=“identity”.\n\n\n\n\nInstead of plotting the standard error bar of point estimates, we can also plot the confidence intervals of mean maths score by race.\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\n\n💡 Things to learn from the code chunk above\n\nThe confidence intervals are computed by using the formula mean+/-1.96*se.\nThe error bars is sorted by using the average maths scores.\nlabs() argument of ggplot2 is used to change the x-axis label.\n\n\n\n\nIn this section, you will learn how to plot interactive error bars for the 99% confidence interval of mean maths score by race as shown in the figure below.\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning in geom_point(aes(x = RACE, y = mean, text = paste(\"Race:\", RACE, :\nIgnoring unknown aesthetics: text\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggdist is an R package offering flexible ggplot2 geoms and stats for visualizing distributions and uncertainty. It supports both frequentist and Bayesian models:\n\nFrequentist: Visualizes confidence or bootstrap distributions.\nBayesian: Visualizes probability distributions (via the tidybayes package).11.4.1 Visualizing the uncertainty of point estimates: ggdist methods\n\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam_data %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\nFor example, in the code chunk below the following arguments are used:\n\n.width = 0.95\n.point = median\n.interval = qi\n\n\nexam_data %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\nWarning in layer_slabinterval(data = data, mapping = mapping, stat =\nStatPointinterval, : Ignoring unknown parameters: `.point` and `.interval`\n\n\n\n\n\n\n\n\n\n\n\n\nexam_data %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE) +   \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\nGentle advice: This function comes with many arguments, students are advised to read the syntax reference for more detail.\n\n\n\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam_data %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\nUsing GitHub PAT from the git credential store.\n\n\nSkipping install of 'ungeviz' from a github remote, the SHA1 (d43afb69) has not changed since last install.\n  Use `force = TRUE` to force installation\n\n\nNote: You only need to perform this step once.\n\n\n\n\nlibrary(ungeviz)\n\n\n\n\nNext, the code chunk below will be used to build the HOPs.\n\nggplot(data = exam_data, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)\n\nWarning in geom_hpline(data = sampler(25, group = RACE), height = 0.6, color =\n\"#D55E00\"): Ignoring unknown parameters: `height`"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-3.html#learning-outcome",
    "href": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-3.html#learning-outcome",
    "title": "Hands-on Exercise 4-3",
    "section": "",
    "text": "Visualising uncertainty is relatively new in statistical graphics. In this chapter, you will gain hands-on experience on creating statistical graphics for visualising uncertainty. By the end of this chapter you will be able:\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package."
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-3.html#getting-started",
    "href": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-3.html#getting-started",
    "title": "Hands-on Exercise 4-3",
    "section": "",
    "text": "For the purpose of this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering), and\nggdist for visualising distribution and uncertainty.\n\n\npacman::p_load(plotly, crosstalk, DT, \n               ggdist, ggridges, colorspace,\n               gganimate, tidyverse)\n\n\n\n\nFor the purpose of this exercise, Exam_data.csv will be used.\n\nexam_data &lt;- read_csv(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 04/data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-3.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "href": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-3.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "title": "Hands-on Exercise 4-3",
    "section": "",
    "text": "A point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval.\nImportant: Don’t confuse the uncertainty of a point estimate with the variation in the sample\nIn this section, you will learn how to plot error bars of maths scores by race by using data provided in exam tibble data frame.\nFirstly, code chunk below will be used to derive the necessary summary statistics.\n\nmy_sum &lt;- exam_data %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\n💡 Things to learn from the code chunk above\n\ngroup_by() of dplyr package is used to group the observation by RACE,\nsummarise() is used to compute the count of observations, mean, standard deviation\nmutate() is used to derive standard error of Maths by RACE, and\nthe output is save as a tibble data table called my_sum.\n\nNext, the code chunk below will be used to display my_sum tibble data frame in an html table format.\n\nsuppressWarnings\n\nfunction (expr, classes = \"warning\") \n{\n    withCallingHandlers(expr, warning = function(w) if (inherits(w, \n        classes)) \n        tryInvokeRestart(\"muffleWarning\"))\n}\n&lt;bytecode: 0x141195a00&gt;\n&lt;environment: namespace:base&gt;\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n\nNow we are ready to plot the standard error bars of mean maths score by race as shown below.\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by rac\")\n\n\n\n\n\n\n\n\n💡 Things to learn from the code chunk above\n\nThe error bars are computed by using the formula mean+/-se.\nFor geom_point(), it is important to indicate stat=“identity”.\n\n\n\n\nInstead of plotting the standard error bar of point estimates, we can also plot the confidence intervals of mean maths score by race.\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\n\n💡 Things to learn from the code chunk above\n\nThe confidence intervals are computed by using the formula mean+/-1.96*se.\nThe error bars is sorted by using the average maths scores.\nlabs() argument of ggplot2 is used to change the x-axis label.\n\n\n\n\nIn this section, you will learn how to plot interactive error bars for the 99% confidence interval of mean maths score by race as shown in the figure below.\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning in geom_point(aes(x = RACE, y = mean, text = paste(\"Race:\", RACE, :\nIgnoring unknown aesthetics: text"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-3.html#visualising-uncertainty-ggdistpackage",
    "href": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-3.html#visualising-uncertainty-ggdistpackage",
    "title": "Hands-on Exercise 4-3",
    "section": "",
    "text": "ggdist is an R package offering flexible ggplot2 geoms and stats for visualizing distributions and uncertainty. It supports both frequentist and Bayesian models:\n\nFrequentist: Visualizes confidence or bootstrap distributions.\nBayesian: Visualizes probability distributions (via the tidybayes package).11.4.1 Visualizing the uncertainty of point estimates: ggdist methods\n\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam_data %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\nFor example, in the code chunk below the following arguments are used:\n\n.width = 0.95\n.point = median\n.interval = qi\n\n\nexam_data %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\nWarning in layer_slabinterval(data = data, mapping = mapping, stat =\nStatPointinterval, : Ignoring unknown parameters: `.point` and `.interval`\n\n\n\n\n\n\n\n\n\n\n\n\nexam_data %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE) +   \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\nGentle advice: This function comes with many arguments, students are advised to read the syntax reference for more detail.\n\n\n\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam_data %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-3.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "href": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-3.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "title": "Hands-on Exercise 4-3",
    "section": "",
    "text": "devtools::install_github(\"wilkelab/ungeviz\")\n\nUsing GitHub PAT from the git credential store.\n\n\nSkipping install of 'ungeviz' from a github remote, the SHA1 (d43afb69) has not changed since last install.\n  Use `force = TRUE` to force installation\n\n\nNote: You only need to perform this step once.\n\n\n\n\nlibrary(ungeviz)\n\n\n\n\nNext, the code chunk below will be used to build the HOPs.\n\nggplot(data = exam_data, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)\n\nWarning in geom_hpline(data = sampler(25, group = RACE), height = 0.6, color =\n\"#D55E00\"): Ignoring unknown parameters: `height`"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-2.html",
    "href": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-2.html",
    "title": "Hands-on Exercise 5-2",
    "section": "",
    "text": "Heatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in rowa and colouring the cells within the table. Heatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.\nIn this hands-on exercise, you will gain hands-on experience on using R to plot static and interactive heatmap for visualising and analysing multivariate data.\n\n\n\nBefore you get started, you are required to open a new Quarto document. Keep the default html as the authoring format.\nNext, you will use the code chunk below to install and launch seriation, heatmaply, dendextend and tidyverse in RStudio.\n\npacman::p_load(seriation, dendextend, heatmaply, tidyverse)\n\n\n\n\nIn this hands-on exercise, the data of World Happines 2018 report will be used. The data set is downloaded from here. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\n\n\nIn the code chunk below, read_csv() of readr is used to import WHData-2018.csv into R and parsed it into tibble R data frame format.\n\nwh &lt;- read_csv(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 05/data/WHData-2018.csv\")\n\nRows: 156 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): Country, Region\ndbl (10): Happiness score, Whisker-high, Whisker-low, Dystopia, GDP per capi...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe output tibbled data frame is called wh.\n\n\n\nNext, we need to change the rows by country name instead of row number by using the code chunk below\n\nwh &lt;- as.data.frame(wh)\nrow.names(wh) &lt;- wh$Country\n\nNotice that the row number has been replaced into the country name.\n\n\n\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform wh data frame into a data matrix.\n\nwh1 &lt;- dplyr::select(wh, c(3, 7:12)) \nwh_matrix &lt;- data.matrix(wh)\n\nNotice that wh_matrix is in R matrix format.\n\n\n\n\nThere are many R packages and functions can be used to drawing static heatmaps, they are:\n\nheatmap()of R stats package. It draws a simple heatmap.\nheatmap.2() of gplots R package. It draws an enhanced heatmap compared to the R base function.\npheatmap() of pheatmap R package. pheatmap package also known as Pretty Heatmap. The package provides functions to draws pretty heatmaps and provides more control to change the appearance of heatmaps.\nComplexHeatmap package of R/Bioconductor package. The package draws, annotates and arranges complex heatmaps (very useful for genomic data analysis). The full reference guide of the package is available here.\nsuperheat package: A Graphical Tool for Exploring Complex Datasets Using Heatmaps. A system for generating extendable and customizable heatmaps for exploring complex datasets, including big data and data with multiple data types. The full reference guide of the package is available here.\n\nIn this section, you will learn how to plot static heatmaps by using heatmap() of R Stats package.\n\n\nIn this sub-section, we will plot a heatmap by using heatmap() of Base Stats. The code chunk is given below.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\n\n\n\n\nNote:\n\nBy default, heatmap() plots a cluster heatmap. The arguments Rowv=NAand Colv=NA are used to switch off the option of plotting the row and column dendrograms.\n\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below.\n\nwh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\n\n\n\n\nNote:\n\nThe order of both rows and columns is different compare to the native wh_matrix. This is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\n\nHere, red cells denotes small values, and red small ones. This heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\nThe code chunk below normalises the matrix column-wise.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\n\n\n\n\nNotice that the values are scaled now. Also note that margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively.\n\n\n\n\nheatmaply is an R package for building interactive cluster heatmap that can be shared online as a stand-alone HTML file. It is designed and maintained by Tal Galili.\nBefore we get started, you should review the Introduction to Heatmaply to have an overall understanding of the features and functions of Heatmaply package. You are also required to have the user manualof the package handy with you for reference purposes.\nIn this section, you will gain hands-on experience on using heatmaply to design an interactive cluster heatmap. We will still use the wh_matrix as the input data.\n\n\n\nheatmaply(mtcars)\n\nWarning in doTryCatch(return(expr), name, parentenv, handler): unable to load shared object '/Library/Frameworks/R.framework/Resources/modules//R_X11.so':\n  dlopen(/Library/Frameworks/R.framework/Resources/modules//R_X11.so, 0x0006): Library not loaded: /opt/X11/lib/libSM.6.dylib\n  Referenced from: &lt;34C5A480-1AC4-30DF-83C9-30A913FC042E&gt; /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/modules/R_X11.so\n  Reason: tried: '/opt/X11/lib/libSM.6.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/X11/lib/libSM.6.dylib' (no such file), '/opt/X11/lib/libSM.6.dylib' (no such file), '/Library/Frameworks/R.framework/Resources/lib/libSM.6.dylib' (no such file), '/Library/Java/JavaVirtualMachines/jdk-11.0.18+10/Contents/Home/lib/server/libSM.6.dylib' (no such file)\n\n\n\n\n\n\nThe code chunk below shows the basic syntax needed to create n interactive heatmap by using heatmaply package.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\nNote that:\n\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the left hand side of the heatmap.\nThe text label of each raw, on the other hand, is placed on the right hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north.\n\n\n\n\nWhen analysing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables’ values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(), namely: scale, normalise and percentilse.\n\n\n\nWhen all variables are came from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\nIn such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling.\n\nThe code chunk below is used to scale variable values columewise.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\n\n\nWhen variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\n\nDifferent from Scaling, the normalise method is performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nSimilar to Normalize method, the Percentize method is also performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options “pearson”, “spearman” and “kendall” can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\nhclustfun: function used to compute the hierarchical clustering when Rowvor Colv are not dendrograms. Defaults to hclust.\ndist_method default is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist”” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\nhclust_method default is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\nIn general, a clustering model can be calibrated either manually or statistically.\n\n\n\nIn the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\n\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that “average” method should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster.\n\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n\n\n\nOne of the problems with hierarchical clustering is that it doesn’t actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can’t end up between A and B, but it doesn’t tell you which way to flip the A+B cluster. It doesn’t tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\nRegistered S3 method overwritten by 'gclus':\n  method         from     \n  reorder.hclust seriation\n\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")\n\n\n\n\n\n\n\n\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nIn the code chunk below, the Blues colour palette of rColorBrewer is used\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)\n\n\n\n\n\n\n\n\nBeside providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-2.html#overview",
    "href": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-2.html#overview",
    "title": "Hands-on Exercise 5-2",
    "section": "",
    "text": "Heatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in rowa and colouring the cells within the table. Heatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.\nIn this hands-on exercise, you will gain hands-on experience on using R to plot static and interactive heatmap for visualising and analysing multivariate data."
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-2.html#installing-and-launching-r-packages",
    "href": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-2.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 5-2",
    "section": "",
    "text": "Before you get started, you are required to open a new Quarto document. Keep the default html as the authoring format.\nNext, you will use the code chunk below to install and launch seriation, heatmaply, dendextend and tidyverse in RStudio.\n\npacman::p_load(seriation, dendextend, heatmaply, tidyverse)"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-2.html#importing-and-preparing-the-data-set",
    "href": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-2.html#importing-and-preparing-the-data-set",
    "title": "Hands-on Exercise 5-2",
    "section": "",
    "text": "In this hands-on exercise, the data of World Happines 2018 report will be used. The data set is downloaded from here. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\n\n\nIn the code chunk below, read_csv() of readr is used to import WHData-2018.csv into R and parsed it into tibble R data frame format.\n\nwh &lt;- read_csv(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 05/data/WHData-2018.csv\")\n\nRows: 156 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): Country, Region\ndbl (10): Happiness score, Whisker-high, Whisker-low, Dystopia, GDP per capi...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe output tibbled data frame is called wh.\n\n\n\nNext, we need to change the rows by country name instead of row number by using the code chunk below\n\nwh &lt;- as.data.frame(wh)\nrow.names(wh) &lt;- wh$Country\n\nNotice that the row number has been replaced into the country name.\n\n\n\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform wh data frame into a data matrix.\n\nwh1 &lt;- dplyr::select(wh, c(3, 7:12)) \nwh_matrix &lt;- data.matrix(wh)\n\nNotice that wh_matrix is in R matrix format."
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-2.html#static-heatmap",
    "href": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-2.html#static-heatmap",
    "title": "Hands-on Exercise 5-2",
    "section": "",
    "text": "There are many R packages and functions can be used to drawing static heatmaps, they are:\n\nheatmap()of R stats package. It draws a simple heatmap.\nheatmap.2() of gplots R package. It draws an enhanced heatmap compared to the R base function.\npheatmap() of pheatmap R package. pheatmap package also known as Pretty Heatmap. The package provides functions to draws pretty heatmaps and provides more control to change the appearance of heatmaps.\nComplexHeatmap package of R/Bioconductor package. The package draws, annotates and arranges complex heatmaps (very useful for genomic data analysis). The full reference guide of the package is available here.\nsuperheat package: A Graphical Tool for Exploring Complex Datasets Using Heatmaps. A system for generating extendable and customizable heatmaps for exploring complex datasets, including big data and data with multiple data types. The full reference guide of the package is available here.\n\nIn this section, you will learn how to plot static heatmaps by using heatmap() of R Stats package.\n\n\nIn this sub-section, we will plot a heatmap by using heatmap() of Base Stats. The code chunk is given below.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\n\n\n\n\nNote:\n\nBy default, heatmap() plots a cluster heatmap. The arguments Rowv=NAand Colv=NA are used to switch off the option of plotting the row and column dendrograms.\n\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below.\n\nwh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\n\n\n\n\nNote:\n\nThe order of both rows and columns is different compare to the native wh_matrix. This is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\n\nHere, red cells denotes small values, and red small ones. This heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\nThe code chunk below normalises the matrix column-wise.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\n\n\n\n\nNotice that the values are scaled now. Also note that margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively."
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-2.html#creating-interactive-heatmap",
    "href": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-2.html#creating-interactive-heatmap",
    "title": "Hands-on Exercise 5-2",
    "section": "",
    "text": "heatmaply is an R package for building interactive cluster heatmap that can be shared online as a stand-alone HTML file. It is designed and maintained by Tal Galili.\nBefore we get started, you should review the Introduction to Heatmaply to have an overall understanding of the features and functions of Heatmaply package. You are also required to have the user manualof the package handy with you for reference purposes.\nIn this section, you will gain hands-on experience on using heatmaply to design an interactive cluster heatmap. We will still use the wh_matrix as the input data.\n\n\n\nheatmaply(mtcars)\n\nWarning in doTryCatch(return(expr), name, parentenv, handler): unable to load shared object '/Library/Frameworks/R.framework/Resources/modules//R_X11.so':\n  dlopen(/Library/Frameworks/R.framework/Resources/modules//R_X11.so, 0x0006): Library not loaded: /opt/X11/lib/libSM.6.dylib\n  Referenced from: &lt;34C5A480-1AC4-30DF-83C9-30A913FC042E&gt; /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/modules/R_X11.so\n  Reason: tried: '/opt/X11/lib/libSM.6.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/X11/lib/libSM.6.dylib' (no such file), '/opt/X11/lib/libSM.6.dylib' (no such file), '/Library/Frameworks/R.framework/Resources/lib/libSM.6.dylib' (no such file), '/Library/Java/JavaVirtualMachines/jdk-11.0.18+10/Contents/Home/lib/server/libSM.6.dylib' (no such file)\n\n\n\n\n\n\nThe code chunk below shows the basic syntax needed to create n interactive heatmap by using heatmaply package.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\nNote that:\n\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the left hand side of the heatmap.\nThe text label of each raw, on the other hand, is placed on the right hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north.\n\n\n\n\nWhen analysing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables’ values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(), namely: scale, normalise and percentilse.\n\n\n\nWhen all variables are came from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\nIn such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling.\n\nThe code chunk below is used to scale variable values columewise.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\n\n\nWhen variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\n\nDifferent from Scaling, the normalise method is performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nSimilar to Normalize method, the Percentize method is also performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options “pearson”, “spearman” and “kendall” can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\nhclustfun: function used to compute the hierarchical clustering when Rowvor Colv are not dendrograms. Defaults to hclust.\ndist_method default is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist”” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\nhclust_method default is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\nIn general, a clustering model can be calibrated either manually or statistically.\n\n\n\nIn the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\n\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that “average” method should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster.\n\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n\n\n\nOne of the problems with hierarchical clustering is that it doesn’t actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can’t end up between A and B, but it doesn’t tell you which way to flip the A+B cluster. It doesn’t tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\nRegistered S3 method overwritten by 'gclus':\n  method         from     \n  reorder.hclust seriation\n\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")\n\n\n\n\n\n\n\n\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nIn the code chunk below, the Blues colour palette of rColorBrewer is used\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)\n\n\n\n\n\n\n\n\nBeside providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-1.html",
    "href": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-1.html",
    "title": "Hands-on Exercises 5-1",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\nIn this hands-on, you will learn how to build ternary plot programmatically using R for visualising and analysing population structure of Singapore.\nThe hands-on exercise consists of four steps:\n\nInstall and launch tidyverse and ggtern packages.\nDerive three new measures using mutate() function of dplyr package.\nBuild a static ternary plot using ggtern() function of ggtern package.\nBuild an interactive ternary plot using plot-ly() function of Plotly R package.\n\n\n\n\nFor this exercise, two main R packages will be used in this hands-on exercise, they are:\n\nggtern, a ggplot extension specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\nPlotly R, an R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js . The plotly R libary contains the ggplotly function, which will convert ggplot2 figures into a Plotly object.\n\nWe will also need to ensure that selected tidyverse family packages namely: readr, dplyr and tidyr are also installed and loaded.\nIn this exercise, version 3.2.1 of ggplot2 will be installed instead of the latest version of ggplot2. This is because the current version of ggtern package is not compatible to the latest version of ggplot2.\nThe code chunks below will accomplish the task.\n\npacman::p_load(plotly, ggtern, tidyverse)\n\n\n\n\n\n\nFor the purpose of this hands-on exercise, the Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018 data will be used. The data set has been downloaded and included in the data sub-folder of the hands-on exercise folder. It is called respopagsex2000to2018_tidy.csv and is in csv file format.\n\n\n\nTo important respopagsex2000to2018_tidy.csv into R, read_csv() function of readr package will be used.\n\n#Reading the data into R environment\npop_data &lt;- read_csv(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 05/data/respopagsex2000to2018_tidy.csv\") \n\nRows: 108126 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): PA, SZ, AG\ndbl (2): Year, Population\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nNext, use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\n#Deriving the young, economy active and old measures\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)\n\n\n\n\n\n\n\nUse ggtern() function of ggtern package to create a simple ternary plot.\n\n#Building the static ternary plot\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n#Building the static ternary plot \nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) + geom_point() + labs(title=\"Population structure, 2015\") + theme_rgbw()\n\n\n\n\n\n\n\n\n\n\n\nThe code below create an interactive ternary plot using plot_ly() function of Plotly R.\n\n# reusable function for creating annotation object\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )\n\nNo scatterternary mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -&gt; https://plotly.com/r/reference/#scatter-mode"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-1.html#overview",
    "href": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-1.html#overview",
    "title": "Hands-on Exercises 5-1",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\nIn this hands-on, you will learn how to build ternary plot programmatically using R for visualising and analysing population structure of Singapore.\nThe hands-on exercise consists of four steps:\n\nInstall and launch tidyverse and ggtern packages.\nDerive three new measures using mutate() function of dplyr package.\nBuild a static ternary plot using ggtern() function of ggtern package.\nBuild an interactive ternary plot using plot-ly() function of Plotly R package."
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-1.html#installing-and-launching-r-packages",
    "href": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-1.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercises 5-1",
    "section": "",
    "text": "For this exercise, two main R packages will be used in this hands-on exercise, they are:\n\nggtern, a ggplot extension specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\nPlotly R, an R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js . The plotly R libary contains the ggplotly function, which will convert ggplot2 figures into a Plotly object.\n\nWe will also need to ensure that selected tidyverse family packages namely: readr, dplyr and tidyr are also installed and loaded.\nIn this exercise, version 3.2.1 of ggplot2 will be installed instead of the latest version of ggplot2. This is because the current version of ggtern package is not compatible to the latest version of ggplot2.\nThe code chunks below will accomplish the task.\n\npacman::p_load(plotly, ggtern, tidyverse)"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-1.html#data-preparation",
    "href": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-1.html#data-preparation",
    "title": "Hands-on Exercises 5-1",
    "section": "",
    "text": "For the purpose of this hands-on exercise, the Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018 data will be used. The data set has been downloaded and included in the data sub-folder of the hands-on exercise folder. It is called respopagsex2000to2018_tidy.csv and is in csv file format.\n\n\n\nTo important respopagsex2000to2018_tidy.csv into R, read_csv() function of readr package will be used.\n\n#Reading the data into R environment\npop_data &lt;- read_csv(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 05/data/respopagsex2000to2018_tidy.csv\") \n\nRows: 108126 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): PA, SZ, AG\ndbl (2): Year, Population\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nNext, use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\n#Deriving the young, economy active and old measures\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-1.html#plotting-ternary-diagram-with-r",
    "href": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-1.html#plotting-ternary-diagram-with-r",
    "title": "Hands-on Exercises 5-1",
    "section": "",
    "text": "Use ggtern() function of ggtern package to create a simple ternary plot.\n\n#Building the static ternary plot\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n#Building the static ternary plot \nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) + geom_point() + labs(title=\"Population structure, 2015\") + theme_rgbw()\n\n\n\n\n\n\n\n\n\n\n\nThe code below create an interactive ternary plot using plot_ly() function of Plotly R.\n\n# reusable function for creating annotation object\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )\n\nNo scatterternary mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -&gt; https://plotly.com/r/reference/#scatter-mode"
  },
  {
    "objectID": "Hands-on Exercises/00.html",
    "href": "Hands-on Exercises/00.html",
    "title": "Hans-on Exercise 00:Working with tidyverse",
    "section": "",
    "text": "Getting started!\n\nLoading tidyverse onto r environment by using the code chunk below.\n\n\npacman::p_load(tidyverse)\n\n\nImporting data\nGetting started!\n\nLoading tidyverse onto r environment by using the code chunk below.\n\n\npacman::p_load(tidyverse)\n\n\nImporting data\n\n\nrealis_2019 &lt;- read.csv(\"data/REALIS2019.csv\")\n\n\n\npopdata_fat &lt;- read_csv(\"data/PopData2019_fat.csv\")\n\n3.pivoting data\n\n popdata_long &lt;- popdata_fat %&gt;%\n   pivot_longer(c(3:21),\n                 names_to =\"Age Group\", \n                 values_to =\"population\") \n\n4.export r data file(rds)\n\nwrite_rds(popdata_long,\"rds/popdata_long.rds\")"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 02/Hands-on Ex 02.html",
    "href": "Hands-on Exercises/Hands-on Ex 02/Hands-on Ex 02.html",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "In this chapter, we will learn:\n\ncontrol the placement of annotation on a graph by using functions provided in ggrepel package,\ncreate professional publication quality figure by using functions provided in ggthemes and hrbrthemes packages,\nplot composite figure by combining ggplot2 graphs by using patchwork package.\n\n\n\n\n\n\n\n\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse) \n\n\n\n\n\nexam_data &lt;- read_csv(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 02/data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: ggrepel: 317 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  theme_gray() +\n  ggtitle(\"Distribution of Maths scores\") \n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 18,\n              base_size = 15,\n              grid = \"Y\")\n\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\n\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\n\np3 &lt;- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\np1 + p2\n\n\n\n\n\n\n\n\n\n\n\n\n(p1 / p2) | p3\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\npatchwork &lt;- (p1 / p2) | p3\npatchwork & theme_economist()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\nPatchwork R package goes nerd viral\nggrepel\nggthemes\nhrbrthemes\nggplot tips: Arranging plots\nggplot2 Theme Elements Demonstration\nggplot2 Theme Elements Reference Sheet"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 02/Hands-on Ex 02.html#reference",
    "href": "Hands-on Exercises/Hands-on Ex 02/Hands-on Ex 02.html#reference",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "Patchwork R package goes nerd viral\nggrepel\nggthemes\nhrbrthemes\nggplot tips: Arranging plots\nggplot2 Theme Elements Demonstration\nggplot2 Theme Elements Reference Sheet"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-3.html",
    "href": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-3.html",
    "title": "Hands-on Exercise 5-3",
    "section": "",
    "text": "Parallel coordinates plot is a data visualisation specially designed for visualising and analysing multivariate, numerical data. It is ideal for comparing multiple variables together and seeing the relationships between them. For example, the variables contribute to Happiness Index. Parallel coordinates was invented by Alfred Inselberg in the 1970s as a way to visualize high-dimensional data. This data visualisation technique is more often found in academic and scientific communities than in business and consumer data visualizations. As pointed out by Stephen Few(2006), “This certainly isn’t a chart that you would present to the board of directors or place on your Web site for the general public. In fact, the strength of parallel coordinates isn’t in their ability to communicate some truth in the data to others, but rather in their ability to bring meaningful multivariate patterns and comparisons to light when used interactively for analysis.” For example, parallel coordinates plot can be used to characterise clusters detected during customer segmentation.\nBy the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting statistic parallel coordinates plots by using ggparcoord() of GGally package,\nplotting interactive parallel coordinates plots by using parcoordspackage, and\nplotting interactive parallel coordinates plots by using parallelPlotpackage.\n\n\n\n\nFor this exercise, the GGally, parcoords, parallelPlot and tidyversepackages will be used.\nThe code chunks below are used to install and load the packages in R.\n\npacman::p_load(GGally, parallelPlot, tidyverse)\n\n\n\n\nIn this hands-on exercise, the World Happinees 2018 (http://worldhappiness.report/ed/2018/) data will be used. The data set is download at https://s3.amazonaws.com/happiness-report/2018/WHR2018Chapter2OnlineData.xls. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\nIn the code chunk below, read_csv() of readr package is used to import WHData-2018.csv into R and save it into a tibble data frame object called wh.\n\nwh &lt;- read_csv(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 05/data/WHData-2018.csv\")\n\nRows: 156 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): Country, Region\ndbl (10): Happiness score, Whisker-high, Whisker-low, Dystopia, GDP per capi...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nIn this section, you will learn how to plot static parallel coordinates plot by using ggparcoord() of GGally package. Before getting started, it is a good practice to read the function description in detail.\n\n\nCode chunk below shows a typical syntax used to plot a basic static parallel coordinates plot by using ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\n\n\n\n\nNotice that only two argument namely data and columns is used. Dataargument is used to map the data object (i.e. wh) and columns is used to select the columns for preparing the parallel coordinates plot.\n\n\n\nThe basic parallel coordinates failed to reveal any meaning understanding of the World Happiness measures. In this section, you will learn how to makeover the plot by using a collection of arguments provided by ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\nWarning: The following aesthetics were dropped during statistical transformation:\ncolour.\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above.\ngroupColumn argument is used to group the observations (i.e. parallel lines) by using a single variable (i.e. Region) and colour the parallel coordinates lines by region name. scale argument is used to scale the variables in the parallel coordinate plot by using uniminmax method. The method univariately scale each variable so the minimum of the variable is zero and the maximum is one. alphaLines argument is used to reduce the intensity of the line colour to 0.2. The permissible value range is between 0 to 1. boxplot argument is used to turn on the boxplot by using logical TRUE. The default is FALSE. title argument is used to provide the parallel coordinates plot a title.\n\n\n\nSince ggparcoord() is developed by extending ggplot2 package, we can combination use some of the ggplot2 function when plotting a parallel coordinates plot.\nIn the code chunk below, facet_wrap() of ggplot2 is used to plot 10 small multiple parallel coordinates plots. Each plot represent one geographical region such as East Asia.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region)\n\n\n\n\n\n\n\n\nOne of the aesthetic defect of the current design is that some of the variable names overlap on x-axis.\n\n\n\nTo make the x-axis text label easy to read, let us rotate the labels by 30 degrees. We can rotate axis text labels using theme() function in ggplot2 as shown in the code chunk below\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nTo rotate x-axis text labels, we use axis.text.x as argument to theme() function. And we specify element_text(angle = 30) to rotate the x-axis text by an angle 30 degree.\n\n\n\n\nRotating x-axis text labels to 30 degrees makes the label overlap with the plot and we can avoid this by adjusting the text location using hjustargument to theme’s text element with element_text(). We use axis.text.x as we want to change the look of x-axis text.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30, hjust=1))\n\n\n\n\n\n\n\n\n\n\n\n\nparallelPlot is an R package specially designed to plot a parallel coordinates plot by using ‘htmlwidgets’ package and d3.js. In this section, you will learn how to use functions provided in parallelPlot package to build interactive parallel coordinates plot.\n\n\nThe code chunk below plot an interactive parallel coordinates plot by using parallelPlot().\n\nwh &lt;- wh %&gt;%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)\n\n\n\n\n\nNotice that some of the axis labels are too long. You will learn how to overcome this problem in the next step.\n\n\n\nIn the code chunk below, rotateTitle argument is used to avoid overlapping axis labels.\n\nparallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\nOne of the useful interactive feature of parallelPlot is we can click on a variable of interest, for example Happiness score, the monotonous blue colour (default) will change a blues with different intensity colour scheme will be used.\n\n\n\nWe can change the default blue colour scheme by using continousCSargument as shown in the code chunl below.\n\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)\n\n\n\n\n\n\n\n\nIn the code chunk below, histoVisibility argument is used to plot histogram along the axis of each variables.\n\nhistoVisibility &lt;- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)\n\n\n\n\n\n\n\n\n\n\nggparcoord() of GGally package\nparcoords user guide\nparallelPlot"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-3.html#overview",
    "href": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-3.html#overview",
    "title": "Hands-on Exercise 5-3",
    "section": "",
    "text": "Parallel coordinates plot is a data visualisation specially designed for visualising and analysing multivariate, numerical data. It is ideal for comparing multiple variables together and seeing the relationships between them. For example, the variables contribute to Happiness Index. Parallel coordinates was invented by Alfred Inselberg in the 1970s as a way to visualize high-dimensional data. This data visualisation technique is more often found in academic and scientific communities than in business and consumer data visualizations. As pointed out by Stephen Few(2006), “This certainly isn’t a chart that you would present to the board of directors or place on your Web site for the general public. In fact, the strength of parallel coordinates isn’t in their ability to communicate some truth in the data to others, but rather in their ability to bring meaningful multivariate patterns and comparisons to light when used interactively for analysis.” For example, parallel coordinates plot can be used to characterise clusters detected during customer segmentation.\nBy the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting statistic parallel coordinates plots by using ggparcoord() of GGally package,\nplotting interactive parallel coordinates plots by using parcoordspackage, and\nplotting interactive parallel coordinates plots by using parallelPlotpackage."
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-3.html#installing-and-launching-r-packages",
    "href": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-3.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 5-3",
    "section": "",
    "text": "For this exercise, the GGally, parcoords, parallelPlot and tidyversepackages will be used.\nThe code chunks below are used to install and load the packages in R.\n\npacman::p_load(GGally, parallelPlot, tidyverse)"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-3.html#data-preparation",
    "href": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-3.html#data-preparation",
    "title": "Hands-on Exercise 5-3",
    "section": "",
    "text": "In this hands-on exercise, the World Happinees 2018 (http://worldhappiness.report/ed/2018/) data will be used. The data set is download at https://s3.amazonaws.com/happiness-report/2018/WHR2018Chapter2OnlineData.xls. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\nIn the code chunk below, read_csv() of readr package is used to import WHData-2018.csv into R and save it into a tibble data frame object called wh.\n\nwh &lt;- read_csv(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 05/data/WHData-2018.csv\")\n\nRows: 156 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): Country, Region\ndbl (10): Happiness score, Whisker-high, Whisker-low, Dystopia, GDP per capi...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-3.html#plotting-static-parallel-coordinates-plot",
    "href": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-3.html#plotting-static-parallel-coordinates-plot",
    "title": "Hands-on Exercise 5-3",
    "section": "",
    "text": "In this section, you will learn how to plot static parallel coordinates plot by using ggparcoord() of GGally package. Before getting started, it is a good practice to read the function description in detail.\n\n\nCode chunk below shows a typical syntax used to plot a basic static parallel coordinates plot by using ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\n\n\n\n\nNotice that only two argument namely data and columns is used. Dataargument is used to map the data object (i.e. wh) and columns is used to select the columns for preparing the parallel coordinates plot.\n\n\n\nThe basic parallel coordinates failed to reveal any meaning understanding of the World Happiness measures. In this section, you will learn how to makeover the plot by using a collection of arguments provided by ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\nWarning: The following aesthetics were dropped during statistical transformation:\ncolour.\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above.\ngroupColumn argument is used to group the observations (i.e. parallel lines) by using a single variable (i.e. Region) and colour the parallel coordinates lines by region name. scale argument is used to scale the variables in the parallel coordinate plot by using uniminmax method. The method univariately scale each variable so the minimum of the variable is zero and the maximum is one. alphaLines argument is used to reduce the intensity of the line colour to 0.2. The permissible value range is between 0 to 1. boxplot argument is used to turn on the boxplot by using logical TRUE. The default is FALSE. title argument is used to provide the parallel coordinates plot a title.\n\n\n\nSince ggparcoord() is developed by extending ggplot2 package, we can combination use some of the ggplot2 function when plotting a parallel coordinates plot.\nIn the code chunk below, facet_wrap() of ggplot2 is used to plot 10 small multiple parallel coordinates plots. Each plot represent one geographical region such as East Asia.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region)\n\n\n\n\n\n\n\n\nOne of the aesthetic defect of the current design is that some of the variable names overlap on x-axis.\n\n\n\nTo make the x-axis text label easy to read, let us rotate the labels by 30 degrees. We can rotate axis text labels using theme() function in ggplot2 as shown in the code chunk below\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nTo rotate x-axis text labels, we use axis.text.x as argument to theme() function. And we specify element_text(angle = 30) to rotate the x-axis text by an angle 30 degree.\n\n\n\n\nRotating x-axis text labels to 30 degrees makes the label overlap with the plot and we can avoid this by adjusting the text location using hjustargument to theme’s text element with element_text(). We use axis.text.x as we want to change the look of x-axis text.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30, hjust=1))"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-3.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "href": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-3.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "title": "Hands-on Exercise 5-3",
    "section": "",
    "text": "parallelPlot is an R package specially designed to plot a parallel coordinates plot by using ‘htmlwidgets’ package and d3.js. In this section, you will learn how to use functions provided in parallelPlot package to build interactive parallel coordinates plot.\n\n\nThe code chunk below plot an interactive parallel coordinates plot by using parallelPlot().\n\nwh &lt;- wh %&gt;%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)\n\n\n\n\n\nNotice that some of the axis labels are too long. You will learn how to overcome this problem in the next step.\n\n\n\nIn the code chunk below, rotateTitle argument is used to avoid overlapping axis labels.\n\nparallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\nOne of the useful interactive feature of parallelPlot is we can click on a variable of interest, for example Happiness score, the monotonous blue colour (default) will change a blues with different intensity colour scheme will be used.\n\n\n\nWe can change the default blue colour scheme by using continousCSargument as shown in the code chunl below.\n\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)\n\n\n\n\n\n\n\n\nIn the code chunk below, histoVisibility argument is used to plot histogram along the axis of each variables.\n\nhistoVisibility &lt;- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-3.html#references",
    "href": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-3.html#references",
    "title": "Hands-on Exercise 5-3",
    "section": "",
    "text": "ggparcoord() of GGally package\nparcoords user guide\nparallelPlot"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-4.html",
    "href": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-4.html",
    "title": "Hands-on Ex 5-4",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experiences on designing treemap using appropriate R packages. The hands-on exercise consists of three main section. First, you will learn how to manipulate transaction data into a treemap strcuture by using selected functions provided in dplyrpackage. Then, you will learn how to plot static treemap by using treemappackage. In the third section, you will learn how to design interactive treemap by using d3treeR package.\n\n\n\nBefore we get started, you are required to check if treemap and tidyversepacakges have been installed in you R.\n\npacman::p_load(treemap, treemapify, tidyverse) \n\n\n\n\nIn this exercise, REALIS2018.csv data will be used. This dataset provides information of private property transaction records in 2018. The dataset is extracted from REALIS portal (https://spring.ura.gov.sg/lad/ore/login/index.cfm) of Urban Redevelopment Authority (URA).\n\n\nIn the code chunk below, read_csv() of readr is used to import realis2018.csv into R and parsed it into tibble R data.frame format.\n\nrealis2018 &lt;- read_csv(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 05/data/realis2018.csv\")\n\nRows: 23205 Columns: 20\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (12): Project Name, Address, Type of Area, Nett Price($), Sale Date, Pro...\ndbl  (8): No. of Units, Area (sqm), Transacted Price ($), Unit Price ($ psm)...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe output tibble data.frame is called realis2018.\n\n\n\nThe data.frame realis2018 is in trasaction record form, which is highly disaggregated and not appropriate to be used to plot a treemap. In this section, we will perform the following steps to manipulate and prepare a data.frtame that is appropriate for treemap visualisation:\n\ngroup transaction records by Project Name, Planning Region, Planning Area, Property Type and Type of Sale, and\ncompute Total Unit Sold, Total Area, Median Unit Price and Median Transacted Price by applying appropriate summary statistics on No. of Units, Area (sqm), Unit Price ($ psm) and Transacted Price ($)respectively.\n\nTwo key verbs of dplyr package, namely: group_by() and summarize() will be used to perform these steps.\ngroup_by() breaks down a data.frame into specified groups of rows. When you then apply the verbs above on the resulting object they’ll be automatically applied “by group”.\nGrouping affects the verbs as follows:\n\ngrouped select() is the same as ungrouped select(), except that grouping variables are always retained.\ngrouped arrange() is the same as ungrouped; unless you set .by_group = TRUE, in which case it orders first by the grouping variables.\nmutate() and filter() are most useful in conjunction with window functions (like rank(), or min(x) == x). They are described in detail in vignette(“window-functions”).\nsample_n() and sample_frac() sample the specified number/fraction of rows in each group.\nsummarise() computes the summary for each group.\n\nIn our case, group_by() will used together with summarise() to derive the summarised data.frame.\n📣 Students who are new to dplyr methods should consult Introduction to dplyrbefore moving on to the next section.\n\n\n\nThe code chank below shows a typical two lines code approach to perform the steps.\n\nrealis2018_grouped &lt;- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`, \n                               `Property Type`, `Type of Sale`)\nrealis2018_summarised &lt;- summarise(realis2018_grouped, \n                          `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                          `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                          `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE), \n                          `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n`summarise()` has grouped output by 'Project Name', 'Planning Region',\n'Planning Area', 'Property Type'. You can override using the `.groups`\nargument.\n\n\n📒 Note\n\nAggregation functions such as sum() and meadian() obey the usual rule of missing values: if there’s any missing value in the input, the output will be a missing value. The argument na.rm = TRUE removes the missing values prior to computation.\n\nThe code chunk above is not very efficient because we have to give each intermediate data.frame a name, even though we don’t have to care about it.\n\n\n\nThe code chunk below shows a more efficient way to tackle the same processes by using the pipe, %&gt;%:\n🔔 Recommendation\nTo learn more about pipe, visit this excellent article: Pipes in R Tutorial For Beginners.\n\nrealis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n`summarise()` has grouped output by 'Project Name', 'Planning Region',\n'Planning Area', 'Property Type'. You can override using the `.groups`\nargument.\n\n\n\n\n\n\ntreemap package is a R package specially designed to offer great flexibility in drawing treemaps. The core function, namely: treemap() offers at least 43 arguments. In this section, we will only explore the major arguments for designing elegent and yet truthful treemaps.\n\n\nIn this section, treemap() of Treemap package is used to plot a treemap showing the distribution of median unit prices and total unit sold of resale condominium by geographic hierarchy in 2017.\nFirst, we will select records belongs to resale condominium property type from realis2018_selected data frame.\n\nrealis2018_selected &lt;- realis2018_summarised %&gt;%\n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")\n\n\n\n\nThe code chunk below designed a treemap by using three core arguments of treemap(), namely: index, vSize and vColor.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThings to learn from the three arguments used:\n\nindex\n\nThe index vector must consist of at least two column names or else no hierarchy treemap will be plotted.\nIf multiple column names are provided, such as the code chunk above, the first name is the highest aggregation level, the second name the second highest aggregation level, and so on.\n\nvSize\n\nThe column must not contain negative values. This is because it’s vaues will be used to map the sizes of the rectangles of the treemaps.\n\n\nWarning:\nThe treemap above was wrongly coloured. For a correctly designed treemap, the colours of the rectagles should be in different intensity showing, in our case, median unit prices.\nFor treemap(), vColor is used in combination with the argument type to determines the colours of the rectangles. Without defining type, like the code chunk above, treemap() assumes type = index, in our case, the hierarchy of planning areas.\n\n\n\nIn the code chunk below, type argument is define as value.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThinking to learn from the conde chunk above.\n\nThe rectangles are coloured with different intensity of green, reflecting their respective median unit prices.\nThe legend reveals that the values are binned into ten bins, i.e. 0-5000, 5000-10000, etc. with an equal interval of 5000.\n\n\n\n\nThere are two arguments that determine the mapping to color palettes: mapping and palette. The only difference between “value” and “manual” is the default value for mapping. The “value” treemap considers palette to be a diverging color palette (say ColorBrewer’s “RdYlBu”), and maps it in such a way that 0 corresponds to the middle color (typically white or yellow), -max(abs(values)) to the left-end color, and max(abs(values)), to the right-end color. The “manual” treemap simply maps min(values) to the left-end color, max(values) to the right-end color, and mean(range(values)) to the middle color.\n\n\n\nThe code chunk below shows a value type treemap.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nalthough the colour palette used is RdYlBu but there are no red rectangles in the treemap above. This is because all the median unit prices are positive.\nThe reason why we see only 5000 to 45000 in the legend is because the range argument is by default c(min(values, max(values)) with some pretty rounding.\n\n\n\n\nThe “manual” type does not interpret the values as the “value” type does. Instead, the value range is mapped linearly to the colour palette.\nThe code chunk below shows a manual type treemap.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nThe colour scheme used is very copnfusing. This is because mapping = (min(values), mean(range(values)), max(values)). It is not wise to use diverging colour palette such as RdYlBu if the values are all positive or negative\n\nTo overcome this problem, a single colour palette such as Blues should be used.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\ntreemap() supports two popular treemap layouts, namely: “squarified” and “pivotSize”. The default is “pivotSize”.\nThe squarified treemap algorithm (Bruls et al., 2000) produces good aspect ratios, but ignores the sorting order of the rectangles (sortID). The ordered treemap, pivot-by-size, algorithm (Bederson et al., 2002) takes the sorting order (sortID) into account while aspect ratios are still acceptable.\n\n\n\nThe code chunk below plots a squarified treemap by changing the algorithm argument.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"squarified\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nWhen “pivotSize” algorithm is used, sortID argument can be used to dertemine the order in which the rectangles are placed from top left to bottom right.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\n\ntreemapify is a R package specially developed to draw treemaps in ggplot2. In this section, you will learn how to designing treemps closely resemble treemaps designing in previous section by using treemapify. Before you getting started, you should read Introduction to “treemapify” its user guide.\n\n\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") + \n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\")\n\n\n\n\n\n\n\n\n\n\n\nGroup by Planning Region\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") + \n  geom_treemap()\n\n\n\n\n\n\n\n\nGroup by Planning Area\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap()\n\n\n\n\n\n\n\n\nAdding boundary line\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap() +\n  geom_treemap_subgroup2_border(colour = \"gray40\",\n                                size = 2) +\n  geom_treemap_subgroup_border(colour = \"gray20\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis slide shows you how to install a R package which is not available in cran.\n\nIf this is the first time you install a package from github, you should install devtools package by using the code below or else you can skip this step.\n\n\ndevtools::install_github(\"timelyportfolio/d3treeR\", force = TRUE)\n\nUsing GitHub PAT from the git credential store.\n\n\nDownloading GitHub repo timelyportfolio/d3treeR@HEAD\n\n\njsonlite   (1.8.9  -&gt; 1.9.0 ) [CRAN]\nxfun       (0.50   -&gt; 0.51  ) [CRAN]\ntinytex    (0.54   -&gt; 0.55  ) [CRAN]\ndata.table (1.16.4 -&gt; 1.17.0) [CRAN]\n\n\nInstalling 4 packages: jsonlite, xfun, tinytex, data.table\n\n\n\nThe downloaded binary packages are in\n    /var/folders/v7/kn7_1jkd60l80zw7rs_11qk00000gn/T//RtmpSSU3wK/downloaded_packages\n── R CMD build ─────────────────────────────────────────────────────────────────\n* checking for file ‘/private/var/folders/v7/kn7_1jkd60l80zw7rs_11qk00000gn/T/RtmpSSU3wK/remotes159df58221bf8/d3treeR-d3treeR-ebb833d/DESCRIPTION’ ... OK\n* preparing ‘d3treeR’:\n* checking DESCRIPTION meta-information ... OK\n* checking for LF line-endings in source and make files and shell scripts\n* checking for empty or unneeded directories\nOmitted ‘LazyData’ from DESCRIPTION\n* building ‘d3treeR_0.1.tar.gz’\n\n\n\nNext, you will load the devtools library and install the package found in github by using the codes below.\n\n\nlibrary(devtools)\n\nLoading required package: usethis\n\ninstall_github(\"timelyportfolio/d3treeR\")\n\nUsing GitHub PAT from the git credential store.\n\n\nSkipping install of 'd3treeR' from a github remote, the SHA1 (ebb833db) has not changed since last install.\n  Use `force = TRUE` to force installation\n\n\n\nNow you are ready to launch d3treeR package\n\nlibrary(d3treeR)\n\n\n\n\n\nThe codes below perform two processes.\n\ntreemap() is used to build a treemap by using selected variables in condominium data.frame. The treemap created is save as object called tm.\n\n\nif (!requireNamespace(\"treemap\", quietly = TRUE)) {\n  install.packages(\"treemap\", dependencies = TRUE)\n}\n\n\nlibrary(treemap)\ntm &lt;- treemap(realis2018_summarised,\n        index=c(\"Planning Region\", \"Planning Area\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        title=\"Private Residential Property Sold, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\nThen d3tree() is used to build an interactive treemap.\n\nd3tree(tm,rootname = \"Singapore\" )"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-4.html#overview",
    "href": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-4.html#overview",
    "title": "Hands-on Ex 5-4",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experiences on designing treemap using appropriate R packages. The hands-on exercise consists of three main section. First, you will learn how to manipulate transaction data into a treemap strcuture by using selected functions provided in dplyrpackage. Then, you will learn how to plot static treemap by using treemappackage. In the third section, you will learn how to design interactive treemap by using d3treeR package."
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-4.html#installing-and-launching-r-packages",
    "href": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-4.html#installing-and-launching-r-packages",
    "title": "Hands-on Ex 5-4",
    "section": "",
    "text": "Before we get started, you are required to check if treemap and tidyversepacakges have been installed in you R.\n\npacman::p_load(treemap, treemapify, tidyverse)"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-4.html#data-wrangling",
    "href": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-4.html#data-wrangling",
    "title": "Hands-on Ex 5-4",
    "section": "",
    "text": "In this exercise, REALIS2018.csv data will be used. This dataset provides information of private property transaction records in 2018. The dataset is extracted from REALIS portal (https://spring.ura.gov.sg/lad/ore/login/index.cfm) of Urban Redevelopment Authority (URA).\n\n\nIn the code chunk below, read_csv() of readr is used to import realis2018.csv into R and parsed it into tibble R data.frame format.\n\nrealis2018 &lt;- read_csv(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 05/data/realis2018.csv\")\n\nRows: 23205 Columns: 20\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (12): Project Name, Address, Type of Area, Nett Price($), Sale Date, Pro...\ndbl  (8): No. of Units, Area (sqm), Transacted Price ($), Unit Price ($ psm)...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe output tibble data.frame is called realis2018.\n\n\n\nThe data.frame realis2018 is in trasaction record form, which is highly disaggregated and not appropriate to be used to plot a treemap. In this section, we will perform the following steps to manipulate and prepare a data.frtame that is appropriate for treemap visualisation:\n\ngroup transaction records by Project Name, Planning Region, Planning Area, Property Type and Type of Sale, and\ncompute Total Unit Sold, Total Area, Median Unit Price and Median Transacted Price by applying appropriate summary statistics on No. of Units, Area (sqm), Unit Price ($ psm) and Transacted Price ($)respectively.\n\nTwo key verbs of dplyr package, namely: group_by() and summarize() will be used to perform these steps.\ngroup_by() breaks down a data.frame into specified groups of rows. When you then apply the verbs above on the resulting object they’ll be automatically applied “by group”.\nGrouping affects the verbs as follows:\n\ngrouped select() is the same as ungrouped select(), except that grouping variables are always retained.\ngrouped arrange() is the same as ungrouped; unless you set .by_group = TRUE, in which case it orders first by the grouping variables.\nmutate() and filter() are most useful in conjunction with window functions (like rank(), or min(x) == x). They are described in detail in vignette(“window-functions”).\nsample_n() and sample_frac() sample the specified number/fraction of rows in each group.\nsummarise() computes the summary for each group.\n\nIn our case, group_by() will used together with summarise() to derive the summarised data.frame.\n📣 Students who are new to dplyr methods should consult Introduction to dplyrbefore moving on to the next section.\n\n\n\nThe code chank below shows a typical two lines code approach to perform the steps.\n\nrealis2018_grouped &lt;- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`, \n                               `Property Type`, `Type of Sale`)\nrealis2018_summarised &lt;- summarise(realis2018_grouped, \n                          `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                          `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                          `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE), \n                          `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n`summarise()` has grouped output by 'Project Name', 'Planning Region',\n'Planning Area', 'Property Type'. You can override using the `.groups`\nargument.\n\n\n📒 Note\n\nAggregation functions such as sum() and meadian() obey the usual rule of missing values: if there’s any missing value in the input, the output will be a missing value. The argument na.rm = TRUE removes the missing values prior to computation.\n\nThe code chunk above is not very efficient because we have to give each intermediate data.frame a name, even though we don’t have to care about it.\n\n\n\nThe code chunk below shows a more efficient way to tackle the same processes by using the pipe, %&gt;%:\n🔔 Recommendation\nTo learn more about pipe, visit this excellent article: Pipes in R Tutorial For Beginners.\n\nrealis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n`summarise()` has grouped output by 'Project Name', 'Planning Region',\n'Planning Area', 'Property Type'. You can override using the `.groups`\nargument."
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-4.html#designing-treemap-with-treemap-package",
    "href": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-4.html#designing-treemap-with-treemap-package",
    "title": "Hands-on Ex 5-4",
    "section": "",
    "text": "treemap package is a R package specially designed to offer great flexibility in drawing treemaps. The core function, namely: treemap() offers at least 43 arguments. In this section, we will only explore the major arguments for designing elegent and yet truthful treemaps.\n\n\nIn this section, treemap() of Treemap package is used to plot a treemap showing the distribution of median unit prices and total unit sold of resale condominium by geographic hierarchy in 2017.\nFirst, we will select records belongs to resale condominium property type from realis2018_selected data frame.\n\nrealis2018_selected &lt;- realis2018_summarised %&gt;%\n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")\n\n\n\n\nThe code chunk below designed a treemap by using three core arguments of treemap(), namely: index, vSize and vColor.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThings to learn from the three arguments used:\n\nindex\n\nThe index vector must consist of at least two column names or else no hierarchy treemap will be plotted.\nIf multiple column names are provided, such as the code chunk above, the first name is the highest aggregation level, the second name the second highest aggregation level, and so on.\n\nvSize\n\nThe column must not contain negative values. This is because it’s vaues will be used to map the sizes of the rectangles of the treemaps.\n\n\nWarning:\nThe treemap above was wrongly coloured. For a correctly designed treemap, the colours of the rectagles should be in different intensity showing, in our case, median unit prices.\nFor treemap(), vColor is used in combination with the argument type to determines the colours of the rectangles. Without defining type, like the code chunk above, treemap() assumes type = index, in our case, the hierarchy of planning areas.\n\n\n\nIn the code chunk below, type argument is define as value.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThinking to learn from the conde chunk above.\n\nThe rectangles are coloured with different intensity of green, reflecting their respective median unit prices.\nThe legend reveals that the values are binned into ten bins, i.e. 0-5000, 5000-10000, etc. with an equal interval of 5000.\n\n\n\n\nThere are two arguments that determine the mapping to color palettes: mapping and palette. The only difference between “value” and “manual” is the default value for mapping. The “value” treemap considers palette to be a diverging color palette (say ColorBrewer’s “RdYlBu”), and maps it in such a way that 0 corresponds to the middle color (typically white or yellow), -max(abs(values)) to the left-end color, and max(abs(values)), to the right-end color. The “manual” treemap simply maps min(values) to the left-end color, max(values) to the right-end color, and mean(range(values)) to the middle color.\n\n\n\nThe code chunk below shows a value type treemap.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nalthough the colour palette used is RdYlBu but there are no red rectangles in the treemap above. This is because all the median unit prices are positive.\nThe reason why we see only 5000 to 45000 in the legend is because the range argument is by default c(min(values, max(values)) with some pretty rounding.\n\n\n\n\nThe “manual” type does not interpret the values as the “value” type does. Instead, the value range is mapped linearly to the colour palette.\nThe code chunk below shows a manual type treemap.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nThe colour scheme used is very copnfusing. This is because mapping = (min(values), mean(range(values)), max(values)). It is not wise to use diverging colour palette such as RdYlBu if the values are all positive or negative\n\nTo overcome this problem, a single colour palette such as Blues should be used.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\ntreemap() supports two popular treemap layouts, namely: “squarified” and “pivotSize”. The default is “pivotSize”.\nThe squarified treemap algorithm (Bruls et al., 2000) produces good aspect ratios, but ignores the sorting order of the rectangles (sortID). The ordered treemap, pivot-by-size, algorithm (Bederson et al., 2002) takes the sorting order (sortID) into account while aspect ratios are still acceptable.\n\n\n\nThe code chunk below plots a squarified treemap by changing the algorithm argument.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"squarified\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nWhen “pivotSize” algorithm is used, sortID argument can be used to dertemine the order in which the rectangles are placed from top left to bottom right.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-4.html#designing-treemap-using-treemapifypackage",
    "href": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-4.html#designing-treemap-using-treemapifypackage",
    "title": "Hands-on Ex 5-4",
    "section": "",
    "text": "treemapify is a R package specially developed to draw treemaps in ggplot2. In this section, you will learn how to designing treemps closely resemble treemaps designing in previous section by using treemapify. Before you getting started, you should read Introduction to “treemapify” its user guide.\n\n\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") + \n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\")\n\n\n\n\n\n\n\n\n\n\n\nGroup by Planning Region\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") + \n  geom_treemap()\n\n\n\n\n\n\n\n\nGroup by Planning Area\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap()\n\n\n\n\n\n\n\n\nAdding boundary line\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap() +\n  geom_treemap_subgroup2_border(colour = \"gray40\",\n                                size = 2) +\n  geom_treemap_subgroup_border(colour = \"gray20\")"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-4.html#designing-interactive-treemap-using-d3treer",
    "href": "Hands-on Exercises/Hands-on Ex 05/Hands-on Ex 5-4.html#designing-interactive-treemap-using-d3treer",
    "title": "Hands-on Ex 5-4",
    "section": "",
    "text": "This slide shows you how to install a R package which is not available in cran.\n\nIf this is the first time you install a package from github, you should install devtools package by using the code below or else you can skip this step.\n\n\ndevtools::install_github(\"timelyportfolio/d3treeR\", force = TRUE)\n\nUsing GitHub PAT from the git credential store.\n\n\nDownloading GitHub repo timelyportfolio/d3treeR@HEAD\n\n\njsonlite   (1.8.9  -&gt; 1.9.0 ) [CRAN]\nxfun       (0.50   -&gt; 0.51  ) [CRAN]\ntinytex    (0.54   -&gt; 0.55  ) [CRAN]\ndata.table (1.16.4 -&gt; 1.17.0) [CRAN]\n\n\nInstalling 4 packages: jsonlite, xfun, tinytex, data.table\n\n\n\nThe downloaded binary packages are in\n    /var/folders/v7/kn7_1jkd60l80zw7rs_11qk00000gn/T//RtmpSSU3wK/downloaded_packages\n── R CMD build ─────────────────────────────────────────────────────────────────\n* checking for file ‘/private/var/folders/v7/kn7_1jkd60l80zw7rs_11qk00000gn/T/RtmpSSU3wK/remotes159df58221bf8/d3treeR-d3treeR-ebb833d/DESCRIPTION’ ... OK\n* preparing ‘d3treeR’:\n* checking DESCRIPTION meta-information ... OK\n* checking for LF line-endings in source and make files and shell scripts\n* checking for empty or unneeded directories\nOmitted ‘LazyData’ from DESCRIPTION\n* building ‘d3treeR_0.1.tar.gz’\n\n\n\nNext, you will load the devtools library and install the package found in github by using the codes below.\n\n\nlibrary(devtools)\n\nLoading required package: usethis\n\ninstall_github(\"timelyportfolio/d3treeR\")\n\nUsing GitHub PAT from the git credential store.\n\n\nSkipping install of 'd3treeR' from a github remote, the SHA1 (ebb833db) has not changed since last install.\n  Use `force = TRUE` to force installation\n\n\n\nNow you are ready to launch d3treeR package\n\nlibrary(d3treeR)\n\n\n\n\n\nThe codes below perform two processes.\n\ntreemap() is used to build a treemap by using selected variables in condominium data.frame. The treemap created is save as object called tm.\n\n\nif (!requireNamespace(\"treemap\", quietly = TRUE)) {\n  install.packages(\"treemap\", dependencies = TRUE)\n}\n\n\nlibrary(treemap)\ntm &lt;- treemap(realis2018_summarised,\n        index=c(\"Planning Region\", \"Planning Area\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        title=\"Private Residential Property Sold, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\nThen d3tree() is used to build an interactive treemap.\n\nd3tree(tm,rootname = \"Singapore\" )"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-2.html",
    "href": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-2.html",
    "title": "Hands-on Exercise 4-2",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters\n\n\n\n\nggstatsplot  is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\n\n\n\n\nIn this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\n\nexam_data &lt;- read_csv(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 04/data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam_data,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\nA Bayes factor is the ratio of the likelihood of one hypothesis to another, measuring the strength of evidence for one theory over another. It helps evaluate data in favor of the null hypothesis and incorporates external information. When comparing hypotheses H1 (alternative) and H0 (null), it’s often denoted as B10. The Schwarz criterion offers a simple way to approximate the Bayes Factor.\n\n\n\nA Bayes Factor can be any positive number.\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam_data,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats( data = exam_data, x = RACE, y = ENGLISH, type = \"p\", mean.ci = TRUE, pairwise.comparisons = TRUE, pairwise.display = \"s\", p.adjust.method = \"fdr\", messages = FALSE )\n\n\n\n\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\nIn this section, various statistical tests were conducted using ggbetweenstats, covering one-sample tests, two-sample mean tests, and one-way ANOVA. Different tests are applied based on the data context:\n\nOne-sample Test: Utilized gghistostats() to compare English scores against a specific value (e.g., 60) and calculate the Bayes Factor to assess the strength of evidence for hypotheses.\nTwo-sample Mean Test: Applied ggbetweenstats() to compare Math scores between genders, using a non-parametric test (Mann–Whitney U) to handle non-normal data.\nOne-way ANOVA: Examined differences in English scores across different races using parametric ANOVA with multiple comparison adjustments (FDR method) to identify significant group differences.\n\nThese methods provide comprehensive statistical insights, including p-values, effect sizes, and Bayes Factors, to support thorough data interpretation.\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam_data,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam_data %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, you will learn how to visualise model diagnostic and model parameters by using parameters package.\n\nToyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables.\n\n\n\n\n\n\n\n\npacman::p_load(readxl, performance, parameters, see)\n\n\n\nIn the code chunk below, read_xls() of readxl package is used to import the data worksheet of ToyotaCorolla.xls workbook into R.\n\ncar_resale &lt;- read_xls(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 04/data/ToyotaCorolla.xls\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\nNotice that the output object car_resale is a tibble data frame.\n\n\n\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\n\nIn the code chunk, check_collinearity() of performance package.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\nlibrary(ggplot2)\nlibrary(performance)\ncheck_c &lt;- check_collinearity(model)\n\n\nvif_plot &lt;- ggplot(check_c, aes(x = reorder(Term, VIF), y = VIF)) +\n  geom_point(aes(color = ifelse(VIF &gt;= 10, \"High (≥ 10)\", \"Low (&lt; 5)\")), size = 4) +\n  scale_color_manual(values = c(\"High (≥ 10)\" = \"red\", \"Low (&lt; 5)\" = \"green\")) +\n  geom_hline(yintercept = 10, linetype = \"dashed\", color = \"red\") +  \n  geom_hline(yintercept = 5, linetype = \"dashed\", color = \"blue\") +  \n  coord_flip() +\n  labs(title = \"Variance Inflation Factor (VIF)\",\n       subtitle = \"High VIF indicates potential multicollinearity issues\",\n       y = \"VIF Value\",\n       x = \"Predictor Variables\",\n       color = \"VIF Level\") +\n  theme_minimal()\n\nprint(vif_plot)\n\n\n\n\n\n\n\n\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\ncheck_n &lt;- check_normality(model1)\n\nplot(check_n)\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk, check_heteroscedasticity() of performancepackage.\n\ncheck_h &lt;- check_heteroscedasticity(model1)\nplot(check_h)\n\n\n\n\n\n\n\n\n\n\n\nWe can also perform the complete by using check_model().\n\ncheck_model(model1)\n\n\n\n\n\n\n\n\n\n\n\nIn the code below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.\n\nplot(parameters(model1))\n\n\n\n\n\n\n\n\n\n\n\nIn the code below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-2.html#learning-outcome",
    "href": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-2.html#learning-outcome",
    "title": "Hands-on Exercise 4-2",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-2.html#visual-statistical-analysis-with-ggstatsplot",
    "href": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-2.html#visual-statistical-analysis-with-ggstatsplot",
    "title": "Hands-on Exercise 4-2",
    "section": "",
    "text": "ggstatsplot  is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves."
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-2.html#getting-started",
    "href": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-2.html#getting-started",
    "title": "Hands-on Exercise 4-2",
    "section": "",
    "text": "In this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\n\nexam_data &lt;- read_csv(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 04/data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam_data,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\nA Bayes factor is the ratio of the likelihood of one hypothesis to another, measuring the strength of evidence for one theory over another. It helps evaluate data in favor of the null hypothesis and incorporates external information. When comparing hypotheses H1 (alternative) and H0 (null), it’s often denoted as B10. The Schwarz criterion offers a simple way to approximate the Bayes Factor.\n\n\n\nA Bayes Factor can be any positive number.\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam_data,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats( data = exam_data, x = RACE, y = ENGLISH, type = \"p\", mean.ci = TRUE, pairwise.comparisons = TRUE, pairwise.display = \"s\", p.adjust.method = \"fdr\", messages = FALSE )\n\n\n\n\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\nIn this section, various statistical tests were conducted using ggbetweenstats, covering one-sample tests, two-sample mean tests, and one-way ANOVA. Different tests are applied based on the data context:\n\nOne-sample Test: Utilized gghistostats() to compare English scores against a specific value (e.g., 60) and calculate the Bayes Factor to assess the strength of evidence for hypotheses.\nTwo-sample Mean Test: Applied ggbetweenstats() to compare Math scores between genders, using a non-parametric test (Mann–Whitney U) to handle non-normal data.\nOne-way ANOVA: Examined differences in English scores across different races using parametric ANOVA with multiple comparison adjustments (FDR method) to identify significant group differences.\n\nThese methods provide comprehensive statistical insights, including p-values, effect sizes, and Bayes Factors, to support thorough data interpretation.\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam_data,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam_data %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-2.html#visualising-models",
    "href": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-2.html#visualising-models",
    "title": "Hands-on Exercise 4-2",
    "section": "",
    "text": "In this section, you will learn how to visualise model diagnostic and model parameters by using parameters package.\n\nToyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables."
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-2.html#installing-and-loading-the-required-libraries",
    "href": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-2.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 4-2",
    "section": "",
    "text": "pacman::p_load(readxl, performance, parameters, see)\n\n\n\nIn the code chunk below, read_xls() of readxl package is used to import the data worksheet of ToyotaCorolla.xls workbook into R.\n\ncar_resale &lt;- read_xls(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 04/data/ToyotaCorolla.xls\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\nNotice that the output object car_resale is a tibble data frame.\n\n\n\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\n\nIn the code chunk, check_collinearity() of performance package.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\nlibrary(ggplot2)\nlibrary(performance)\ncheck_c &lt;- check_collinearity(model)\n\n\nvif_plot &lt;- ggplot(check_c, aes(x = reorder(Term, VIF), y = VIF)) +\n  geom_point(aes(color = ifelse(VIF &gt;= 10, \"High (≥ 10)\", \"Low (&lt; 5)\")), size = 4) +\n  scale_color_manual(values = c(\"High (≥ 10)\" = \"red\", \"Low (&lt; 5)\" = \"green\")) +\n  geom_hline(yintercept = 10, linetype = \"dashed\", color = \"red\") +  \n  geom_hline(yintercept = 5, linetype = \"dashed\", color = \"blue\") +  \n  coord_flip() +\n  labs(title = \"Variance Inflation Factor (VIF)\",\n       subtitle = \"High VIF indicates potential multicollinearity issues\",\n       y = \"VIF Value\",\n       x = \"Predictor Variables\",\n       color = \"VIF Level\") +\n  theme_minimal()\n\nprint(vif_plot)\n\n\n\n\n\n\n\n\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\ncheck_n &lt;- check_normality(model1)\n\nplot(check_n)\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk, check_heteroscedasticity() of performancepackage.\n\ncheck_h &lt;- check_heteroscedasticity(model1)\nplot(check_h)\n\n\n\n\n\n\n\n\n\n\n\nWe can also perform the complete by using check_model().\n\ncheck_model(model1)\n\n\n\n\n\n\n\n\n\n\n\nIn the code below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.\n\nplot(parameters(model1))\n\n\n\n\n\n\n\n\n\n\n\nIn the code below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-4.html",
    "href": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-4.html",
    "title": "Hands-on Exercise 4-4",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages.\n\n\n\n\nIn this exercise, four R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)\n\n\n\n\nIn this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 &lt;- read_csv(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 04/data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)\n\nRows: 267 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): City, District, Sub-district\ndbl (4): Sub-district ID, Positive, Recovered, Death\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator(population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\n\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Positive,\n  denominator = Death,\n  group = `Sub-district`\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \nThings to learn from the code chunk above.\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\n\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",     #&lt;&lt;\n  xrange = c(0, 6500),  #&lt;&lt;\n  yrange = c(0, 0.05)   #&lt;&lt;\n)\n\nWarning: The `xrange` argument deprecated; please use the `x_range` argument\ninstead.  For more options, see the help: `?funnel_plot`\n\n\nWarning: The `yrange` argument deprecated; please use the `y_range` argument\ninstead.  For more options, see the help: `?funnel_plot`\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \nThings to learn from the code chunk above. + data_type argument is used to change from default “SR” to “PR” (i.e. proportions). + xrange and yrange are used to set the range of x-axis and y-axis\n\n\n\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)\n\nWarning: The `xrange` argument deprecated; please use the `x_range` argument\ninstead.  For more options, see the help: `?funnel_plot`\n\n\nWarning: The `yrange` argument deprecated; please use the `y_range` argument\ninstead.  For more options, see the help: `?funnel_plot`\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \nThings to learn from the code chunk above.\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles.\n\n\n\n\n\nIn this section, you will gain hands-on experience on building funnel plots step-by-step by using ggplot2. It aims to enhance you working experience of ggplot2 to customise speciallised data visualisation like funnel plot.\n\n\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\n\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\n\nWarning in geom_point(aes(label = `Sub-district`), alpha = 0.4): Ignoring\nunknown aesthetics: label\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2\n3.5.0.\nℹ Please use the `legend.position.inside` argument of `theme()` instead.\n\np\n\n\n\n\n\n\n\n\n\n\n\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly\n\n\n\n\n\n\n\n\n\n\nfunnelPlotR package.\nFunnel Plots for Indirectly-standardised ratios.\nChanging funnel plot options\nggplot2 package."
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-4.html#overview",
    "href": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-4.html#overview",
    "title": "Hands-on Exercise 4-4",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages."
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-4.html#installing-and-launching-r-packages",
    "href": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-4.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 4-4",
    "section": "",
    "text": "In this exercise, four R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-4.html#importing-data",
    "href": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-4.html#importing-data",
    "title": "Hands-on Exercise 4-4",
    "section": "",
    "text": "In this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 &lt;- read_csv(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 04/data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)\n\nRows: 267 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): City, District, Sub-district\ndbl (4): Sub-district ID, Positive, Recovered, Death\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-4.html#funnelplotr-methods",
    "href": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-4.html#funnelplotr-methods",
    "title": "Hands-on Exercise 4-4",
    "section": "",
    "text": "FunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator(population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\n\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Positive,\n  denominator = Death,\n  group = `Sub-district`\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \nThings to learn from the code chunk above.\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\n\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",     #&lt;&lt;\n  xrange = c(0, 6500),  #&lt;&lt;\n  yrange = c(0, 0.05)   #&lt;&lt;\n)\n\nWarning: The `xrange` argument deprecated; please use the `x_range` argument\ninstead.  For more options, see the help: `?funnel_plot`\n\n\nWarning: The `yrange` argument deprecated; please use the `y_range` argument\ninstead.  For more options, see the help: `?funnel_plot`\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \nThings to learn from the code chunk above. + data_type argument is used to change from default “SR” to “PR” (i.e. proportions). + xrange and yrange are used to set the range of x-axis and y-axis\n\n\n\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)\n\nWarning: The `xrange` argument deprecated; please use the `x_range` argument\ninstead.  For more options, see the help: `?funnel_plot`\n\n\nWarning: The `yrange` argument deprecated; please use the `y_range` argument\ninstead.  For more options, see the help: `?funnel_plot`\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \nThings to learn from the code chunk above.\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles."
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-4.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "href": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-4.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "title": "Hands-on Exercise 4-4",
    "section": "",
    "text": "In this section, you will gain hands-on experience on building funnel plots step-by-step by using ggplot2. It aims to enhance you working experience of ggplot2 to customise speciallised data visualisation like funnel plot.\n\n\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\n\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\n\nWarning in geom_point(aes(label = `Sub-district`), alpha = 0.4): Ignoring\nunknown aesthetics: label\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2\n3.5.0.\nℹ Please use the `legend.position.inside` argument of `theme()` instead.\n\np\n\n\n\n\n\n\n\n\n\n\n\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-4.html#references",
    "href": "Hands-on Exercises/Hands-on Ex 04/Hands-on Ex 4-4.html#references",
    "title": "Hands-on Exercise 4-4",
    "section": "",
    "text": "funnelPlotR package.\nFunnel Plots for Indirectly-standardised ratios.\nChanging funnel plot options\nggplot2 package."
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 03/Hands-on Ex 03.html",
    "href": "Hands-on Exercises/Hands-on Ex 03/Hands-on Ex 03.html",
    "title": "Hands-on Exercise 03",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to create interactive data visualisation by using functions provided by ggiraph and plotlyr packages.\n\n\n\nFirst, write a code chunk to check, install and launch the following R packages:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\nThe code chunk below will be used to accomplish the task.\n\npacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse) \n\n\n\n\nIn this section, Exam_data.csv provided will be used. Using read_csv() of readr package, import Exam_data.csv into R.\nThe code chunk below read_csv() of readr package is used to import Exam_data.csv data file into R and save it as an tibble data frame called exam_data.\n\nexam_data &lt;- read_csv(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 03/data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nggiraph  is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf it used within a shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides. Refer to this article for more detail explanation.\n\n\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\n\n\n\n\nYou can hovering the mouse pointer on an data point of interest, the student’s ID will be displayed.\n\n\n\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7.\n\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\n\n\n\n\n\n\n\nYou can hovering the mouse pointer on an data point of interest, the student’s ID will be displayed.\n\n\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\nNotice that the background colour of the tooltip is black and the font colour is white and bold.\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)                                        \n\n\n\n\n\n\nRefer to Customizing girafe objects to learn more about how to customise ggiraph objects.\n\n\n\n\nCode chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\n\nCode chunk below shows the second interactive feature of ggiraph, namely data_id.\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\n\n\n\n\nNote that the default value of the hover css is hover_css = “fill:orange;”.\n\n\n\nIn the code chunk below, css codes are used to change the highlighting effect.\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\nNote: Different from previous example, in this example the ccs customisation request are encoded directly.\n\n\n\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\n\n\n\nonclick argument of ggiraph provides hotlink interactivity on the web.\nThe code chunk below shown an example of onclick.\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\n\n\n\n\nWarning:\nNote that click actions must be a string column in the dataset containing valid javascript instructions.\n\n\n\nCoordinated multiple views methods has been implemented in the data visualisation below.\nNotice that when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views as shown in the example above, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\n\n\n\n\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point.\n\n\n\n\nPlotly’s R graphing library create interactive web graphics from ggplot2 graphs and/or a custom interface to the (MIT-licensed) JavaScript library plotly.js inspired by the grammar of graphics. Different from other plotly platform, plot.R is free and open source.\nThere are two ways to create interactive graph by using plotly, they are:\nby using plot_ly(), and by using ggplotly()\n\n\nThe tabset below shows an example a basic interactive plot created by using plot_ly().\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -&gt; https://plotly.com/r/reference/#scatter\n\n\nNo scatter mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -&gt; https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\n\n\n\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE)\n\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -&gt; https://plotly.com/r/reference/#scatter\n\n\nNo scatter mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -&gt; https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\n\n\n\nThe code chunk below plots an interactive scatter plot by using ggplotly().\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\n\n\n\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\ntwo scatterplots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\n\nThing to learn from the code chunk:\n\nhighlight_key() simply creates an object of class crosstalk::SharedData.\nVisit this link to learn more about crosstalk\n\n\n\n\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\n\n\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)        \n\nSetting the `off` event (i.e., 'plotly_deselect') to match the `on` event (i.e., 'plotly_selected'). You can change this default via the `highlight()` function.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis link provides online version of the reference guide and several useful articles. Use this link to download the pdf version of the reference guide.\n\nHow to Plot With Ggiraph\nInteractive map of France with ggiraph\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to interactive graphs for Swiss Olympians - the solo specialists.\n\n\n\n\n\nGetting Started with Plotly in R\nA collection of plotly R graphs are available via this link.\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this link\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly’s R API.\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 03/Hands-on Ex 03.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-on Exercises/Hands-on Ex 03/Hands-on Ex 03.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-on Exercise 03",
    "section": "",
    "text": "ggiraph  is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf it used within a shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides. Refer to this article for more detail explanation.\n\n\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 03/Hands-on Ex 03.html#interactivity",
    "href": "Hands-on Exercises/Hands-on Ex 03/Hands-on Ex 03.html#interactivity",
    "title": "Hands-on Exercise 03",
    "section": "",
    "text": "You can hovering the mouse pointer on an data point of interest, the student’s ID will be displayed."
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 03/Hands-on Ex 03.html#displaying-multiple-information-on-tooltip",
    "href": "Hands-on Exercises/Hands-on Ex 03/Hands-on Ex 03.html#displaying-multiple-information-on-tooltip",
    "title": "Hands-on Exercise 03",
    "section": "",
    "text": "The content of the tooltip can be customised by including a list object as shown in the code chunk below.\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7.\n\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 03/Hands-on Ex 03.html#interactivity-1",
    "href": "Hands-on Exercises/Hands-on Ex 03/Hands-on Ex 03.html#interactivity-1",
    "title": "Hands-on Exercise 03",
    "section": "",
    "text": "You can hovering the mouse pointer on an data point of interest, the student’s ID will be displayed.\n\n\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\nNotice that the background colour of the tooltip is black and the font colour is white and bold.\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)                                        \n\n\n\n\n\n\nRefer to Customizing girafe objects to learn more about how to customise ggiraph objects.\n\n\n\n\nCode chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\n\nCode chunk below shows the second interactive feature of ggiraph, namely data_id.\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\n\n\n\n\nNote that the default value of the hover css is hover_css = “fill:orange;”.\n\n\n\nIn the code chunk below, css codes are used to change the highlighting effect.\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\nNote: Different from previous example, in this example the ccs customisation request are encoded directly.\n\n\n\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\n\n\n\nonclick argument of ggiraph provides hotlink interactivity on the web.\nThe code chunk below shown an example of onclick.\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\n\n\n\n\nWarning:\nNote that click actions must be a string column in the dataset containing valid javascript instructions.\n\n\n\nCoordinated multiple views methods has been implemented in the data visualisation below.\nNotice that when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views as shown in the example above, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\n\n\n\n\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point."
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 03/Hands-on Ex 03.html#interactive-data-visualisation---plotly-methods",
    "href": "Hands-on Exercises/Hands-on Ex 03/Hands-on Ex 03.html#interactive-data-visualisation---plotly-methods",
    "title": "Hands-on Exercise 03",
    "section": "",
    "text": "Plotly’s R graphing library create interactive web graphics from ggplot2 graphs and/or a custom interface to the (MIT-licensed) JavaScript library plotly.js inspired by the grammar of graphics. Different from other plotly platform, plot.R is free and open source.\nThere are two ways to create interactive graph by using plotly, they are:\nby using plot_ly(), and by using ggplotly()\n\n\nThe tabset below shows an example a basic interactive plot created by using plot_ly().\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -&gt; https://plotly.com/r/reference/#scatter\n\n\nNo scatter mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -&gt; https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\n\n\n\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE)\n\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -&gt; https://plotly.com/r/reference/#scatter\n\n\nNo scatter mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -&gt; https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\n\n\n\nThe code chunk below plots an interactive scatter plot by using ggplotly().\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\n\n\n\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\ntwo scatterplots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\n\nThing to learn from the code chunk:\n\nhighlight_key() simply creates an object of class crosstalk::SharedData.\nVisit this link to learn more about crosstalk\n\n\n\n\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\n\n\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)        \n\nSetting the `off` event (i.e., 'plotly_deselect') to match the `on` event (i.e., 'plotly_selected'). You can change this default via the `highlight()` function."
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 03/Hands-on Ex 03.html#reference",
    "href": "Hands-on Exercises/Hands-on Ex 03/Hands-on Ex 03.html#reference",
    "title": "Hands-on Exercise 03",
    "section": "",
    "text": "This link provides online version of the reference guide and several useful articles. Use this link to download the pdf version of the reference guide.\n\nHow to Plot With Ggiraph\nInteractive map of France with ggiraph\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to interactive graphs for Swiss Olympians - the solo specialists.\n\n\n\n\n\nGetting Started with Plotly in R\nA collection of plotly R graphs are available via this link.\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this link\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly’s R API.\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 07/Hands-on Ex 07.html",
    "href": "Hands-on Exercises/Hands-on Ex 07/Hands-on Ex 07.html",
    "title": "Hands-on Ex07",
    "section": "",
    "text": "By the end of this hands-on exercise you will be able create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart\n\n\n\n\n\n\n\nWrite a code chunk to check, install and launch the following R packages: scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse.\n\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table, CGPfunctions, ggHoriPlot, tidyverse)\n\n\n\n\nIn this section, you will learn how to plot a calender heatmap programmatically by using ggplot2 package.\nBy the end of this section, you will be able to:\n\nplot a calender heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\n\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\n\nFirst, you will use the code chunk below to import eventlog.csv file into R environment and called the data frame as attacks.\n\nattacks &lt;- read_csv(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 07/data/Hands-on_Ex07/eventlog.csv\")\n\nRows: 199999 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): source_country, tz\ndttm (1): timestamp\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores time zone of the source IP address.\n\n\n\n\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\n\n\n\n📒 Note\n\n\n\n\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\n\n\n\n\n\n📒 Note\n\n\n\n\nBeside extracting the necessary data into attacks data frame, mutate() of dplyrpackage is used to convert wkday and hour fields into factor so they’ll be ordered when plotting\n\n\n\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\n\n\n💡 Things to learn from the code chunk\n\n\n\n\n\na tibble data table called grouped is derived by aggregating the attack by wkdayand hour fields.\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\n\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\n\n\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\n\n\n\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, you will learn how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair &lt;- read_excel(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 07/data/Hands-on_Ex07/arrivals_by_air.xlsx\")\n\n\n\n\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\n\n\n\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\n\n\n\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n\nThe code chunk below is used to plot the cycle plot as shown in Slide 12/23.\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section you will learn how to plot a slopegraph by using R.\nBefore getting start, make sure that CGPfunctions has been installed and loaded onto R environment. Then, refer to Using newggslopegraph to learn more about the function. Lastly, read more about newggslopegraph() and its arguments by referring to this link.\n\n\nImport the rice data set into R environment by using the code chunk below.\n\nrice &lt;- read_csv(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 07/data/Hands-on_Ex07/rice.csv\")\n\nRows: 550 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Country\ndbl (3): Year, Yield, Production\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nNext, code chunk below will be used to plot a basic slopegraph as shown below.\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Dr. Kam Tin Seong\")\n\n\nConverting 'Year' to an ordered factor\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n💡 Thing to learn from the code chunk above\n\n\n\n\nFor effective data visualisation design, factor() is used convert the value type of Yearfield from numeric to factor."
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 07/Hands-on Ex 07.html#learning-outcome",
    "href": "Hands-on Exercises/Hands-on Ex 07/Hands-on Ex 07.html#learning-outcome",
    "title": "Hands-on Ex07",
    "section": "",
    "text": "By the end of this hands-on exercise you will be able create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 07/Hands-on Ex 07.html#do-it-yourself",
    "href": "Hands-on Exercises/Hands-on Ex 07/Hands-on Ex 07.html#do-it-yourself",
    "title": "Hands-on Ex07",
    "section": "",
    "text": "Write a code chunk to check, install and launch the following R packages: scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse.\n\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table, CGPfunctions, ggHoriPlot, tidyverse)"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 07/Hands-on Ex 07.html#plotting-calendar-heatmap",
    "href": "Hands-on Exercises/Hands-on Ex 07/Hands-on Ex 07.html#plotting-calendar-heatmap",
    "title": "Hands-on Ex07",
    "section": "",
    "text": "In this section, you will learn how to plot a calender heatmap programmatically by using ggplot2 package.\nBy the end of this section, you will be able to:\n\nplot a calender heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\n\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\n\nFirst, you will use the code chunk below to import eventlog.csv file into R environment and called the data frame as attacks.\n\nattacks &lt;- read_csv(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 07/data/Hands-on_Ex07/eventlog.csv\")\n\nRows: 199999 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): source_country, tz\ndttm (1): timestamp\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores time zone of the source IP address.\n\n\n\n\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\n\n\n\n📒 Note\n\n\n\n\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\n\n\n\n\n\n📒 Note\n\n\n\n\nBeside extracting the necessary data into attacks data frame, mutate() of dplyrpackage is used to convert wkday and hour fields into factor so they’ll be ordered when plotting\n\n\n\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\n\n\n💡 Things to learn from the code chunk\n\n\n\n\n\na tibble data table called grouped is derived by aggregating the attack by wkdayand hour fields.\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\n\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\n\n\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\n\n\n\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 07/Hands-on Ex 07.html#plotting-cycle-plot",
    "href": "Hands-on Exercises/Hands-on Ex 07/Hands-on Ex 07.html#plotting-cycle-plot",
    "title": "Hands-on Ex07",
    "section": "",
    "text": "In this section, you will learn how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair &lt;- read_excel(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 07/data/Hands-on_Ex07/arrivals_by_air.xlsx\")\n\n\n\n\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\n\n\n\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\n\n\n\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n\nThe code chunk below is used to plot the cycle plot as shown in Slide 12/23.\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")"
  },
  {
    "objectID": "Hands-on Exercises/Hands-on Ex 07/Hands-on Ex 07.html#plotting-slopegraph",
    "href": "Hands-on Exercises/Hands-on Ex 07/Hands-on Ex 07.html#plotting-slopegraph",
    "title": "Hands-on Ex07",
    "section": "",
    "text": "In this section you will learn how to plot a slopegraph by using R.\nBefore getting start, make sure that CGPfunctions has been installed and loaded onto R environment. Then, refer to Using newggslopegraph to learn more about the function. Lastly, read more about newggslopegraph() and its arguments by referring to this link.\n\n\nImport the rice data set into R environment by using the code chunk below.\n\nrice &lt;- read_csv(\"/Users/geloliu/Gelo-608/ISSS608/Hands-on Exercises/Hands-on Ex 07/data/Hands-on_Ex07/rice.csv\")\n\nRows: 550 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Country\ndbl (3): Year, Yield, Production\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nNext, code chunk below will be used to plot a basic slopegraph as shown below.\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Dr. Kam Tin Seong\")\n\n\nConverting 'Year' to an ordered factor\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n💡 Thing to learn from the code chunk above\n\n\n\n\nFor effective data visualisation design, factor() is used convert the value type of Yearfield from numeric to factor."
  },
  {
    "objectID": "In-class ex/In-class ex04/In-class ex04.html",
    "href": "In-class ex/In-class ex04/In-class ex04.html",
    "title": "In-class Ex04",
    "section": "",
    "text": "pacman:: p_load(haven,\n               SmartEDA,\n               tidymodels, \n               tidyverse)\n\n\nexam_data &lt;- read_csv(\"/Users/geloliu/Gelo-608/ISSS608/In-class ex/In-class ex04/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nggplot(data = exam_data,\n       aes(x = ENGLISH,\n           y = CLASS)) +\ngeom_boxplot()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am Gelo.This is the course page of ISSS608 whereby I share my hands-on Exercises,In class Exercises."
  },
  {
    "objectID": "In-class ex/In-class ex 07/In-class ex 07.html",
    "href": "In-class ex/In-class ex 07/In-class ex 07.html",
    "title": "In-class ex 07",
    "section": "",
    "text": "By the end of this session, you will be able to:\n\nimport and wrangling time-series data by using appropriate tidyverse methods,\nvisualise and analyse time-series data,\ncalibrate time-series forecasting models by using exponential smoothing and ARIMA techniques, and\ncompare and evaluate the performance of forecasting models.\n\n\n\n\nFor the purpose of this hands-on exercise, the following R packages will be used.\n\npacman::p_load(tidyverse, tsibble, feasts, fable, seasonal)\n\n\nlubridate provides a collection to functions to parse and wrangle time and date data.\ntsibble, feasts, fable and fable.prophet are belong to tidyverts, a family of tidy tools for time series data handling, analysis and forecasting.\n\ntsibble provides a data infrastructure for tidy temporal data with wrangling tools. Adapting the tidy data principles, tsibble is a data- and model-oriented object.\nfeasts provides a collection of tools for the analysis of time series data. The package name is an acronym comprising of its key features: Feature Extraction And Statistics for Time Series.\n\n\n\n\nFirst, read_csv() of readr package is used to import visitor_arrivals_by_air.csv file into R environment. The imported file is saved an tibble object called ts_data.\n\nts_data &lt;- read_csv(\n  \"/Users/geloliu/Gelo-608/ISSS608/In-class ex/In-class ex 07/visitor_arrivals_by_air.csv\")\n\nRows: 144 Columns: 34\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): Month-Year\ndbl (33): Republic of South Africa, Canada, USA, Bangladesh, Brunei, China, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nIn the code chunk below, dmy() of lubridate package is used to convert data type of Month-Year field from Character to Date.\n\nts_data$`Month-Year` &lt;- dmy(\n  ts_data$`Month-Year`)\n\n\n\n\ntibble object\n\nts_data\n\n# A tibble: 144 × 34\n   `Month-Year` `Republic of South Africa` Canada   USA Bangladesh Brunei China\n   &lt;date&gt;                            &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 2008-01-01                         3680   6972 31155       6786   3729 79599\n 2 2008-02-01                         1662   6056 27738       6314   3070 82074\n 3 2008-03-01                         3394   6220 31349       7502   4805 72546\n 4 2008-04-01                         3337   4764 26376       7333   3096 76112\n 5 2008-05-01                         2089   4460 26788       7988   3586 64808\n 6 2008-06-01                         2515   3888 29725       8301   5284 55238\n 7 2008-07-01                         2919   5313 33183       9004   4070 80747\n 8 2008-08-01                         2471   4519 27427       7913   4183 66625\n 9 2008-09-01                         2492   3421 21588       7549   3160 52649\n10 2008-10-01                         3023   4756 25112       7527   2983 54423\n# ℹ 134 more rows\n# ℹ 27 more variables: `Hong Kong SAR (China)` &lt;dbl&gt;, India &lt;dbl&gt;,\n#   Indonesia &lt;dbl&gt;, Japan &lt;dbl&gt;, `South Korea` &lt;dbl&gt;, Kuwait &lt;dbl&gt;,\n#   Malaysia &lt;dbl&gt;, Myanmar &lt;dbl&gt;, Pakistan &lt;dbl&gt;, Philippines &lt;dbl&gt;,\n#   `Saudi Arabia` &lt;dbl&gt;, `Sri Lanka` &lt;dbl&gt;, Taiwan &lt;dbl&gt;, Thailand &lt;dbl&gt;,\n#   `United Arab Emirates` &lt;dbl&gt;, Vietnam &lt;dbl&gt;, `Belgium & Luxembourg` &lt;dbl&gt;,\n#   Finland &lt;dbl&gt;, France &lt;dbl&gt;, Germany &lt;dbl&gt;, Italy &lt;dbl&gt;, …\n\n\n\n\n\nts object\n\nts_data_ts &lt;- ts(ts_data)       \nhead(ts_data_ts)\n\n     Month-Year Republic of South Africa Canada   USA Bangladesh Brunei China\n[1,]      13879                     3680   6972 31155       6786   3729 79599\n[2,]      13910                     1662   6056 27738       6314   3070 82074\n[3,]      13939                     3394   6220 31349       7502   4805 72546\n[4,]      13970                     3337   4764 26376       7333   3096 76112\n[5,]      14000                     2089   4460 26788       7988   3586 64808\n[6,]      14031                     2515   3888 29725       8301   5284 55238\n     Hong Kong SAR (China) India Indonesia Japan South Korea Kuwait Malaysia\n[1,]                 17103 41639     62683 37673       27937    284    31352\n[2,]                 21089 37170     47834 35297       22633    241    35030\n[3,]                 23230 44815     64688 42575       22876    206    37629\n[4,]                 17688 49527     58074 26839       20634    193    37521\n[5,]                 19340 67754     57089 30814       22785    140    38044\n[6,]                 19152 57380     70118 31001       22575    354    40419\n     Myanmar Pakistan Philippines Saudi Arabia Sri Lanka Taiwan Thailand\n[1,]    5269     1395       18622          406      5289  13757    18370\n[2,]    4643     1027       21609          591      4767  13921    16400\n[3,]    6218     1635       28464          626      4988  11181    23387\n[4,]    7324     1232       30131          644      7639  11665    24469\n[5,]    5395     1306       30193          470      5125  11436    21935\n[6,]    5542     1996       25800          772      4791  10689    19900\n     United Arab Emirates Vietnam Belgium & Luxembourg Finland France Germany\n[1,]                 2652   10315                 1341    1179   6918   11982\n[2,]                 2230   13415                 1449    1207   7876   13256\n[3,]                 3353   14320                 1674    1071   8066   15185\n[4,]                 3245   15413                 1426     768   8312   11604\n[5,]                 2856   14424                 1243     690   7066    9853\n[6,]                 4292   21368                 1255     624   5926    9347\n     Italy Netherlands Spain Switzerland United Kingdom Australia New Zealand\n[1,]  2953        4938  1668        4450          41934     71260        7806\n[2,]  2704        4885  1568        4381          44029     45595        4729\n[3,]  2822        5015  2254        5015          49489     53191        6106\n[4,]  3018        4902  1503        5434          35771     56514        7560\n[5,]  2165        4397  1365        4427          24464     57808        9090\n[6,]  2022        4166  1446        3359          22473     63350        9681\n\n\n\n\n\nThe code chunk below converting ts_data from tibble object into tsibble object by using as_tsibble() of tsibble R package.\n\nts_tsibble &lt;- ts_data %&gt;%\n  mutate(Month = yearmonth(`Month-Year`)) %&gt;%\n  as_tsibble(index = `Month`)\n\nWhat can we learn from the code chunk above? + mutate() of dplyrpackage is used to derive a new field by transforming the data values in Month-Year field into month-year format. The transformation is performed by using yearmonth() of tsibble package. + as_tsibble() is used to convert the tibble data frame into tsibble data frame.\n\n\n\n\nts_tsibble\n\n# A tsibble: 144 x 35 [1M]\n   `Month-Year` `Republic of South Africa` Canada   USA Bangladesh Brunei China\n   &lt;date&gt;                            &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 2008-01-01                         3680   6972 31155       6786   3729 79599\n 2 2008-02-01                         1662   6056 27738       6314   3070 82074\n 3 2008-03-01                         3394   6220 31349       7502   4805 72546\n 4 2008-04-01                         3337   4764 26376       7333   3096 76112\n 5 2008-05-01                         2089   4460 26788       7988   3586 64808\n 6 2008-06-01                         2515   3888 29725       8301   5284 55238\n 7 2008-07-01                         2919   5313 33183       9004   4070 80747\n 8 2008-08-01                         2471   4519 27427       7913   4183 66625\n 9 2008-09-01                         2492   3421 21588       7549   3160 52649\n10 2008-10-01                         3023   4756 25112       7527   2983 54423\n# ℹ 134 more rows\n# ℹ 28 more variables: `Hong Kong SAR (China)` &lt;dbl&gt;, India &lt;dbl&gt;,\n#   Indonesia &lt;dbl&gt;, Japan &lt;dbl&gt;, `South Korea` &lt;dbl&gt;, Kuwait &lt;dbl&gt;,\n#   Malaysia &lt;dbl&gt;, Myanmar &lt;dbl&gt;, Pakistan &lt;dbl&gt;, Philippines &lt;dbl&gt;,\n#   `Saudi Arabia` &lt;dbl&gt;, `Sri Lanka` &lt;dbl&gt;, Taiwan &lt;dbl&gt;, Thailand &lt;dbl&gt;,\n#   `United Arab Emirates` &lt;dbl&gt;, Vietnam &lt;dbl&gt;, `Belgium & Luxembourg` &lt;dbl&gt;,\n#   Finland &lt;dbl&gt;, France &lt;dbl&gt;, Germany &lt;dbl&gt;, Italy &lt;dbl&gt;, …\n\n\n\n\n\n\nIn order to visualise the time-series data effectively, we need to organise the data frame from wide to long format by using pivot_longer() of tidyr package as shown below.\n\nts_longer &lt;- ts_data %&gt;%\n  pivot_longer(cols = c(2:34),\n               names_to = \"Country\",\n               values_to = \"Arrivals\")\n\n\n\n\nts_longer %&gt;%\n  filter(Country == \"Vietnam\") %&gt;%\n  ggplot(aes(x = `Month-Year`, \n             y = Arrivals))+\n  geom_line(linewidth = 0.5)\n\n\n\n\n\n\n\n\n\nfilter() of dplyr package is used to select records belong to Vietnam.\ngeom_line() of ggplot2 package is used to plot the time-series line graph. ]\n\n\n\n\n\nggplot(data = ts_longer, \n       aes(x = `Month-Year`, \n           y = Arrivals,\n           color = Country))+\n  geom_line(linewidth = 0.5) +\n  theme(legend.position = \"bottom\", \n        legend.box.spacing = unit(0.5, \"cm\"))\n\n\n\n\n\n\n\n\nIn order to provide effective comparison, facet_wrap() of ggplot2package is used to create small multiple line graph also known as trellis plot.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntsibble_longer &lt;- ts_tsibble %&gt;%\n  pivot_longer(cols = c(2:34),\n               names_to = \"Country\",\n               values_to = \"Arrivals\")\n\n\n\n\ntsibble_longer %&gt;%\n  filter(Country == \"Italy\" |\n         Country == \"Vietnam\" |\n         Country == \"United Kingdom\" |\n         Country == \"Germany\") %&gt;% \n  gg_season(Arrivals)\n\n\n\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(Country == \"Vietnam\" |\n         Country == \"Italy\") %&gt;% \n  autoplot(Arrivals) + \n  facet_grid(Country ~ ., scales = \"free_y\")\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(Country == \"Vietnam\" |\n         Country == \"Italy\") %&gt;% \n  gg_subseries(Arrivals)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, ACF() of feasts package is used to plot the ACF curve of visitor arrival from Vietnam.\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\") %&gt;%\n  ACF(Arrivals) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\") %&gt;%\n  PACF(Arrivals) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\" |\n         `Country` == \"Italy\" |\n         `Country` == \"United Kingdom\" |\n         `Country` == \"China\") %&gt;%\n  ACF(Arrivals) %&gt;%\n  autoplot()\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\" |\n         `Country` == \"Italy\" |\n         `Country` == \"United Kingdom\" |\n         `Country` == \"China\") %&gt;%\n  PACF(Arrivals) %&gt;%\n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\") %&gt;%\n  gg_tsdisplay(Arrivals)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\") %&gt;%\n  model(stl = STL(Arrivals)) %&gt;%\n  components() %&gt;%\n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\") %&gt;%\n  model(\n    classical_decomposition(\n      Arrivals, type = \"additive\")) %&gt;%\n  components() %&gt;%\n  autoplot()\n\nWarning: Removed 6 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvietnam_ts &lt;- tsibble_longer %&gt;%\n  filter(Country == \"Vietnam\") %&gt;% \n  mutate(Type = if_else(\n    `Month-Year` &gt;= \"2019-01-01\", \n    \"Hold-out\", \"Training\"))\n\n\nvietnam_train &lt;- vietnam_ts %&gt;%\n  filter(`Month-Year` &lt; \"2019-01-01\")\n\n\n\n\n\nvietnam_train %&gt;%\n  model(stl = STL(Arrivals)) %&gt;%\n  components() %&gt;%\n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nETS(y ~ error(c(\"A\", \"M\")) +\n      trend(c(\"N\", \"A\", \"Ad\")) +\n      season(c(\"N\", \"A\", \"M\")))\n\n&lt;ETS model definition&gt;\n\n\n\n\n\n\nfit_ses &lt;- vietnam_train %&gt;%\n  model(ETS(Arrivals ~ error(\"A\") \n            + trend(\"N\") \n            + season(\"N\")))\nfit_ses\n\n# A mable: 1 x 2\n# Key:     Country [1]\n  Country `ETS(Arrivals ~ error(\"A\") + trend(\"N\") + season(\"N\"))`\n  &lt;chr&gt;                                                   &lt;model&gt;\n1 Vietnam                                            &lt;ETS(A,N,N)&gt;\n\n\n\n\n\n\ngg_tsresiduals(fit_ses)\n\n\n\n\n\n\n\n\n\n\n\n\nfit_ses %&gt;%\n  report()\n\nSeries: Arrivals \nModel: ETS(A,N,N) \n  Smoothing parameters:\n    alpha = 0.9998995 \n\n  Initial states:\n     l[0]\n 10312.99\n\n  sigma^2:  27939164\n\n     AIC     AICc      BIC \n2911.726 2911.913 2920.374 \n\n\n\n\n\n\n\n\n\nvietnam_H &lt;- vietnam_train %&gt;%\n  model(`Holt's method` = \n          ETS(Arrivals ~ error(\"A\") +\n                trend(\"A\") + \n                season(\"N\")))\nvietnam_H %&gt;% report()\n\nSeries: Arrivals \nModel: ETS(A,A,N) \n  Smoothing parameters:\n    alpha = 0.9998995 \n    beta  = 0.0001004625 \n\n  Initial states:\n     l[0]     b[0]\n 13673.29 525.8859\n\n  sigma^2:  28584805\n\n     AIC     AICc      BIC \n2916.695 2917.171 2931.109 \n\n\n\n\n\n\nvietnam_HAd &lt;- vietnam_train %&gt;%\n  model(`Holt's method` = \n          ETS(Arrivals ~ error(\"A\") +\n                trend(\"Ad\") + \n                season(\"N\")))\nvietnam_HAd %&gt;% report()\n\nSeries: Arrivals \nModel: ETS(A,Ad,N) \n  Smoothing parameters:\n    alpha = 0.9998999 \n    beta  = 0.0001098602 \n    phi   = 0.9784562 \n\n  Initial states:\n     l[0]   b[0]\n 13257.28 523.54\n\n  sigma^2:  28641536\n\n     AIC     AICc      BIC \n2917.921 2918.593 2935.218 \n\n\n\n\n\n\ngg_tsresiduals(vietnam_H)\n\n\n\n\n\n\n\n\n\ngg_tsresiduals(vietnam_HAd)\n\n\n\n\n\n\n\n\n\n\n\n\n\nVietnam_WH &lt;- vietnam_train %&gt;%\n  model(\n    Additive = ETS(Arrivals ~ error(\"A\") \n                   + trend(\"A\") \n                   + season(\"A\")),\n    Multiplicative = ETS(Arrivals ~ error(\"M\") \n                         + trend(\"A\") \n                         + season(\"M\"))\n    )\n\nVietnam_WH %&gt;% report()\n\nWarning in report.mdl_df(.): Model reporting is only supported for individual\nmodels, so a glance will be shown. To see the report for a specific model, use\n`select()` and `filter()` to identify a single model.\n\n\n# A tibble: 2 × 10\n  Country .model          sigma2 log_lik   AIC  AICc   BIC    MSE   AMSE     MAE\n  &lt;chr&gt;   &lt;chr&gt;            &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 Vietnam Additive       5.33e+6  -1336. 2706. 2711. 2755. 4.68e6 8.56e6 1.72e+3\n2 Vietnam Multiplicative 4.55e-3  -1300. 2635. 2640. 2684. 3.05e6 3.42e6 5.20e-2\n\n\n\n\n\n\nfit_ETS &lt;- vietnam_train %&gt;%\n  model(`SES` = ETS(Arrivals ~ error(\"A\") + \n                      trend(\"N\") + \n                      season(\"N\")),\n        `Holt`= ETS(Arrivals ~ error(\"A\") +\n                      trend(\"A\") +\n                      season(\"N\")),\n        `damped Holt` = \n          ETS(Arrivals ~ error(\"A\") +\n                trend(\"Ad\") + \n                season(\"N\")),\n        `WH_A` = ETS(\n          Arrivals ~ error(\"A\") + \n            trend(\"A\") + \n            season(\"A\")),\n        `WH_M` = ETS(Arrivals ~ error(\"M\") \n                         + trend(\"A\") \n                         + season(\"M\"))\n  )\n\n\n\n\n\nfit_ETS %&gt;%\n  tidy()\n\n# A tibble: 45 × 4\n   Country .model      term      estimate\n   &lt;chr&gt;   &lt;chr&gt;       &lt;chr&gt;        &lt;dbl&gt;\n 1 Vietnam SES         alpha     1.00    \n 2 Vietnam SES         l[0]  10313.      \n 3 Vietnam Holt        alpha     1.00    \n 4 Vietnam Holt        beta      0.000100\n 5 Vietnam Holt        l[0]  13673.      \n 6 Vietnam Holt        b[0]    526.      \n 7 Vietnam damped Holt alpha     1.00    \n 8 Vietnam damped Holt beta      0.000110\n 9 Vietnam damped Holt phi       0.978   \n10 Vietnam damped Holt l[0]  13257.      \n# ℹ 35 more rows\n\n\n\n\n\n\nfit_ETS %&gt;% \n  report()\n\nWarning in report.mdl_df(.): Model reporting is only supported for individual\nmodels, so a glance will be shown. To see the report for a specific model, use\n`select()` and `filter()` to identify a single model.\n\n\n# A tibble: 5 × 10\n  Country .model       sigma2 log_lik   AIC  AICc   BIC       MSE   AMSE     MAE\n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 Vietnam SES         2.79e+7  -1453. 2912. 2912. 2920. 27515844. 5.99e7 3.91e+3\n2 Vietnam Holt        2.86e+7  -1453. 2917. 2917. 2931. 27718599. 6.03e7 3.92e+3\n3 Vietnam damped Holt 2.86e+7  -1453. 2918. 2919. 2935. 27556629. 5.97e7 3.92e+3\n4 Vietnam WH_A        5.33e+6  -1336. 2706. 2711. 2755.  4684271. 8.56e6 1.72e+3\n5 Vietnam WH_M        4.55e-3  -1300. 2635. 2640. 2684.  3046059. 3.42e6 5.20e-2\n\n\n\n\n\n\nfit_ETS %&gt;%\n  forecast(h = \"12 months\") %&gt;%\n  autoplot(vietnam_ts, \n           level = NULL)\n\n\n\n\n\n\n\n\n\n\n\n\nfit_autoETS &lt;- vietnam_train %&gt;%\n  model(ETS(Arrivals))\nfit_autoETS %&gt;% report()\n\nSeries: Arrivals \nModel: ETS(M,A,M) \n  Smoothing parameters:\n    alpha = 0.1613503 \n    beta  = 0.0001021811 \n    gamma = 0.0001030996 \n\n  Initial states:\n     l[0]     b[0]      s[0]     s[-1]     s[-2]     s[-3]    s[-4]    s[-5]\n 15001.12 212.3552 0.9167302 0.8311728 0.8739287 0.8690543 1.104668 1.485584\n    s[-6]     s[-7]    s[-8]     s[-9]    s[-10]    s[-11]\n 1.311207 0.9917759 1.014187 0.8973028 0.8816768 0.8227129\n\n  sigma^2:  0.0046\n\n     AIC     AICc      BIC \n2634.751 2640.119 2683.759 \n\n\n\n\n\n\ngg_tsresiduals(fit_autoETS)\n\n\n\n\n\n\n\n\n\n\n\n\nfit_autoETS %&gt;%\n  forecast(h = \"12 months\") %&gt;%\n  autoplot(vietnam_train)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfc_autoETS &lt;- fit_autoETS %&gt;%\n  forecast(h = \"12 months\")\n\nvietnam_ts %&gt;%\n  ggplot(aes(x=`Month`, \n             y=Arrivals)) +\n  autolayer(fc_autoETS, \n            alpha = 0.6) +\n  geom_line(aes(\n    color = Type), \n    alpha = 0.8) + \n  geom_line(aes(\n    y = .mean, \n    colour = \"Forecast\"), \n    data = fc_autoETS) +\n  geom_line(aes(\n    y = .fitted, \n    colour = \"Fitted\"), \n    data = augment(fit_autoETS))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvietnam_train %&gt;%\n  gg_tsdisplay(plot_type='partial')\n\nPlot variable not specified, automatically selected `y = Arrivals`\n\n\n\n\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\") %&gt;%\n  ACF(Arrivals) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"United Kingdom\") %&gt;%\n  ACF(Arrivals) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"United Kingdom\") %&gt;%\n  ACF(Arrivals) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(Country == \"Vietnam\") %&gt;%\n  gg_tsdisplay(difference(\n    Arrivals,\n    lag = 1), \n    plot_type='partial')\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(Country == \"Vietnam\") %&gt;%\n  gg_tsdisplay(difference(\n    Arrivals,\n    difference = 12), \n    plot_type='partial')\n\nWarning: Removed 12 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 12 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfit_arima &lt;- vietnam_train %&gt;%\n  model(\n    arima200 = ARIMA(Arrivals ~ pdq(2,0,0)),\n    sarima210 = ARIMA(Arrivals ~ pdq(2,0,0) + \n                        PDQ(2,1,0))\n    )\nreport(fit_arima)\n\nWarning in report.mdl_df(fit_arima): Model reporting is only supported for\nindividual models, so a glance will be shown. To see the report for a specific\nmodel, use `select()` and `filter()` to identify a single model.\n\n\n# A tibble: 2 × 9\n  Country .model      sigma2 log_lik   AIC  AICc   BIC ar_roots   ma_roots \n  &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;list&gt;     &lt;list&gt;   \n1 Vietnam arima200  4173906.  -1085. 2181. 2182. 2198. &lt;cpl [26]&gt; &lt;cpl [0]&gt;\n2 Vietnam sarima210 4173906.  -1085. 2181. 2182. 2198. &lt;cpl [26]&gt; &lt;cpl [0]&gt;\n\n\n\n\n\n\nfit_autoARIMA &lt;- vietnam_train %&gt;%\n  model(ARIMA(Arrivals))\n\nWarning: 1 error encountered for ARIMA(Arrivals)\n[1] The `urca` package must be installed to use this functionality. It can be installed with install.packages(\"urca\")\n\nreport(fit_autoARIMA)\n\nSeries: Arrivals \nModel: NULL model \nNULL model\n\n\n\n\n\n\nbind_rows(\n    fit_autoARIMA %&gt;% accuracy(),\n    fit_autoETS %&gt;% accuracy(),\n    fit_autoARIMA %&gt;% \n      forecast(h = 12) %&gt;% \n      accuracy(vietnam_ts),\n    fit_autoETS %&gt;% \n      forecast(h = 12) %&gt;% \n      accuracy(vietnam_ts)) %&gt;%\n  select(-ME, -MPE, -ACF1)\n\n# A tibble: 4 × 8\n  Country .model          .type     RMSE   MAE   MAPE    MASE   RMSSE\n  &lt;chr&gt;   &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 Vietnam ARIMA(Arrivals) Training  NaN   NaN  NaN    NaN     NaN    \n2 Vietnam ETS(Arrivals)   Training 1745. 1386.   5.29   0.467   0.473\n3 Vietnam ARIMA(Arrivals) Test      NaN   NaN  NaN    NaN     NaN    \n4 Vietnam ETS(Arrivals)   Test     3163. 2636.   6.64   0.889   0.857\n\n\n\n\n\n\nASEAN &lt;- tsibble_longer %&gt;%\n  filter(Country == \"Vietnam\" |\n         Country == \"Malaysia\" |\n         Country == \"Indonesia\" |\n         Country == \"Thailand\" |\n         Country == \"Philippines\")\n\n\nASEAN_train &lt;- ASEAN %&gt;%\n  mutate(Type = if_else(\n    `Month-Year` &gt;= \"2019-01-01\", \n    \"Hold-out\", \"Training\")) %&gt;%\n  filter(Type == \"Training\")\n\n\n\n\n\nASEAN_fit &lt;- ASEAN_train %&gt;%\n  model(\n    ets = ETS(Arrivals),\n    arima = ARIMA(Arrivals)\n  )\n\nWarning: 5 errors (1 unique) encountered for arima\n[5] The `urca` package must be installed to use this functionality. It can be installed with install.packages(\"urca\")\n\n\n\n\n\n\nASEAN_fit %&gt;%\n  glance()\n\n# A tibble: 5 × 10\n  Country     .model  sigma2 log_lik   AIC  AICc   BIC        MSE    AMSE    MAE\n  &lt;chr&gt;       &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 Indonesia   ets    0.0102   -1561. 3156. 3161. 3205. 173901516.  1.80e8 0.0732\n2 Malaysia    ets    0.00467  -1430. 2894. 2899. 2943.  20381756.  2.00e7 0.0506\n3 Philippines ets    0.00356  -1343. 2722. 2728. 2774.   5282584.  7.58e6 0.0461\n4 Thailand    ets    0.00663  -1343. 2722. 2728. 2774.   5396141.  6.33e6 0.0584\n5 Vietnam     ets    0.00455  -1300. 2635. 2640. 2684.   3046059.  3.42e6 0.0520\n\n\n\n\n\n\nASEAN_fit %&gt;%\n  augment()\n\n# A tsibble: 1,320 x 7 [1M]\n# Key:       Country, .model [10]\n   Country   .model    Month Arrivals .fitted  .resid  .innov\n   &lt;chr&gt;     &lt;chr&gt;     &lt;mth&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 Indonesia ets    2008 Jan    62683  56534.   6149.  0.109 \n 2 Indonesia ets    2008 Feb    47834  46417.   1417.  0.0305\n 3 Indonesia ets    2008 Mar    64688  62660.   2028.  0.0324\n 4 Indonesia ets    2008 Apr    58074  61045.  -2971. -0.0487\n 5 Indonesia ets    2008 May    57089  62280.  -5191. -0.0833\n 6 Indonesia ets    2008 Jun    70118  75791.  -5673. -0.0749\n 7 Indonesia ets    2008 Jul    73805  78691.  -4886. -0.0621\n 8 Indonesia ets    2008 Aug    58015  61910.  -3895. -0.0629\n 9 Indonesia ets    2008 Sep    63730  74518. -10788. -0.145 \n10 Indonesia ets    2008 Oct    71206  67869.   3337.  0.0492\n# ℹ 1,310 more rows\n\n\n\n\n\n\nASEAN_fit %&gt;%\n  accuracy() %&gt;%\n  arrange(Country)\n\n# A tibble: 10 × 11\n   Country     .model .type       ME   RMSE   MAE     MPE   MAPE    MASE   RMSSE\n   &lt;chr&gt;       &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 Indonesia   ets    Trai… -1813.   13187. 9665.  -1.83    7.57   0.556   0.619\n 2 Indonesia   arima  Trai…   NaN      NaN   NaN  NaN     NaN    NaN     NaN    \n 3 Malaysia    ets    Trai…  -678.    4515. 3538.  -1.25    5.15   0.529   0.527\n 4 Malaysia    arima  Trai…   NaN      NaN   NaN  NaN     NaN    NaN     NaN    \n 5 Philippines ets    Trai…    -2.35  2298. 1897.  -0.334   4.64   0.464   0.408\n 6 Philippines arima  Trai…   NaN      NaN   NaN  NaN     NaN    NaN     NaN    \n 7 Thailand    ets    Trai…    19.7   2323. 1773.  -0.511   5.89   0.489   0.485\n 8 Thailand    arima  Trai…   NaN      NaN   NaN  NaN     NaN    NaN     NaN    \n 9 Vietnam     ets    Trai…   -35.2   1745. 1386.  -0.728   5.29   0.467   0.473\n10 Vietnam     arima  Trai…   NaN      NaN   NaN  NaN     NaN    NaN     NaN    \n# ℹ 1 more variable: ACF1 &lt;dbl&gt;\n\n\n\n\n\n\nASEAN_fc &lt;- ASEAN_fit %&gt;%\n  forecast(h = \"12 months\")\n\n\n\n\n\nASEAN_fc %&gt;%\n  autoplot(ASEAN)\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\n\nWarning: Removed 60 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\nRob J Hyndman and George Athanasopoulos (2022) Forecasting: Principles and Practice (3rd ed), online version."
  },
  {
    "objectID": "In-class ex/In-class ex 07/In-class ex 07.html#learning-outcome",
    "href": "In-class ex/In-class ex 07/In-class ex 07.html#learning-outcome",
    "title": "In-class ex 07",
    "section": "",
    "text": "By the end of this session, you will be able to:\n\nimport and wrangling time-series data by using appropriate tidyverse methods,\nvisualise and analyse time-series data,\ncalibrate time-series forecasting models by using exponential smoothing and ARIMA techniques, and\ncompare and evaluate the performance of forecasting models."
  },
  {
    "objectID": "In-class ex/In-class ex 07/In-class ex 07.html#getting-started",
    "href": "In-class ex/In-class ex 07/In-class ex 07.html#getting-started",
    "title": "In-class ex 07",
    "section": "",
    "text": "For the purpose of this hands-on exercise, the following R packages will be used.\n\npacman::p_load(tidyverse, tsibble, feasts, fable, seasonal)\n\n\nlubridate provides a collection to functions to parse and wrangle time and date data.\ntsibble, feasts, fable and fable.prophet are belong to tidyverts, a family of tidy tools for time series data handling, analysis and forecasting.\n\ntsibble provides a data infrastructure for tidy temporal data with wrangling tools. Adapting the tidy data principles, tsibble is a data- and model-oriented object.\nfeasts provides a collection of tools for the analysis of time series data. The package name is an acronym comprising of its key features: Feature Extraction And Statistics for Time Series.\n\n\n\n\nFirst, read_csv() of readr package is used to import visitor_arrivals_by_air.csv file into R environment. The imported file is saved an tibble object called ts_data.\n\nts_data &lt;- read_csv(\n  \"/Users/geloliu/Gelo-608/ISSS608/In-class ex/In-class ex 07/visitor_arrivals_by_air.csv\")\n\nRows: 144 Columns: 34\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): Month-Year\ndbl (33): Republic of South Africa, Canada, USA, Bangladesh, Brunei, China, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nIn the code chunk below, dmy() of lubridate package is used to convert data type of Month-Year field from Character to Date.\n\nts_data$`Month-Year` &lt;- dmy(\n  ts_data$`Month-Year`)\n\n\n\n\ntibble object\n\nts_data\n\n# A tibble: 144 × 34\n   `Month-Year` `Republic of South Africa` Canada   USA Bangladesh Brunei China\n   &lt;date&gt;                            &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 2008-01-01                         3680   6972 31155       6786   3729 79599\n 2 2008-02-01                         1662   6056 27738       6314   3070 82074\n 3 2008-03-01                         3394   6220 31349       7502   4805 72546\n 4 2008-04-01                         3337   4764 26376       7333   3096 76112\n 5 2008-05-01                         2089   4460 26788       7988   3586 64808\n 6 2008-06-01                         2515   3888 29725       8301   5284 55238\n 7 2008-07-01                         2919   5313 33183       9004   4070 80747\n 8 2008-08-01                         2471   4519 27427       7913   4183 66625\n 9 2008-09-01                         2492   3421 21588       7549   3160 52649\n10 2008-10-01                         3023   4756 25112       7527   2983 54423\n# ℹ 134 more rows\n# ℹ 27 more variables: `Hong Kong SAR (China)` &lt;dbl&gt;, India &lt;dbl&gt;,\n#   Indonesia &lt;dbl&gt;, Japan &lt;dbl&gt;, `South Korea` &lt;dbl&gt;, Kuwait &lt;dbl&gt;,\n#   Malaysia &lt;dbl&gt;, Myanmar &lt;dbl&gt;, Pakistan &lt;dbl&gt;, Philippines &lt;dbl&gt;,\n#   `Saudi Arabia` &lt;dbl&gt;, `Sri Lanka` &lt;dbl&gt;, Taiwan &lt;dbl&gt;, Thailand &lt;dbl&gt;,\n#   `United Arab Emirates` &lt;dbl&gt;, Vietnam &lt;dbl&gt;, `Belgium & Luxembourg` &lt;dbl&gt;,\n#   Finland &lt;dbl&gt;, France &lt;dbl&gt;, Germany &lt;dbl&gt;, Italy &lt;dbl&gt;, …\n\n\n\n\n\nts object\n\nts_data_ts &lt;- ts(ts_data)       \nhead(ts_data_ts)\n\n     Month-Year Republic of South Africa Canada   USA Bangladesh Brunei China\n[1,]      13879                     3680   6972 31155       6786   3729 79599\n[2,]      13910                     1662   6056 27738       6314   3070 82074\n[3,]      13939                     3394   6220 31349       7502   4805 72546\n[4,]      13970                     3337   4764 26376       7333   3096 76112\n[5,]      14000                     2089   4460 26788       7988   3586 64808\n[6,]      14031                     2515   3888 29725       8301   5284 55238\n     Hong Kong SAR (China) India Indonesia Japan South Korea Kuwait Malaysia\n[1,]                 17103 41639     62683 37673       27937    284    31352\n[2,]                 21089 37170     47834 35297       22633    241    35030\n[3,]                 23230 44815     64688 42575       22876    206    37629\n[4,]                 17688 49527     58074 26839       20634    193    37521\n[5,]                 19340 67754     57089 30814       22785    140    38044\n[6,]                 19152 57380     70118 31001       22575    354    40419\n     Myanmar Pakistan Philippines Saudi Arabia Sri Lanka Taiwan Thailand\n[1,]    5269     1395       18622          406      5289  13757    18370\n[2,]    4643     1027       21609          591      4767  13921    16400\n[3,]    6218     1635       28464          626      4988  11181    23387\n[4,]    7324     1232       30131          644      7639  11665    24469\n[5,]    5395     1306       30193          470      5125  11436    21935\n[6,]    5542     1996       25800          772      4791  10689    19900\n     United Arab Emirates Vietnam Belgium & Luxembourg Finland France Germany\n[1,]                 2652   10315                 1341    1179   6918   11982\n[2,]                 2230   13415                 1449    1207   7876   13256\n[3,]                 3353   14320                 1674    1071   8066   15185\n[4,]                 3245   15413                 1426     768   8312   11604\n[5,]                 2856   14424                 1243     690   7066    9853\n[6,]                 4292   21368                 1255     624   5926    9347\n     Italy Netherlands Spain Switzerland United Kingdom Australia New Zealand\n[1,]  2953        4938  1668        4450          41934     71260        7806\n[2,]  2704        4885  1568        4381          44029     45595        4729\n[3,]  2822        5015  2254        5015          49489     53191        6106\n[4,]  3018        4902  1503        5434          35771     56514        7560\n[5,]  2165        4397  1365        4427          24464     57808        9090\n[6,]  2022        4166  1446        3359          22473     63350        9681\n\n\n\n\n\nThe code chunk below converting ts_data from tibble object into tsibble object by using as_tsibble() of tsibble R package.\n\nts_tsibble &lt;- ts_data %&gt;%\n  mutate(Month = yearmonth(`Month-Year`)) %&gt;%\n  as_tsibble(index = `Month`)\n\nWhat can we learn from the code chunk above? + mutate() of dplyrpackage is used to derive a new field by transforming the data values in Month-Year field into month-year format. The transformation is performed by using yearmonth() of tsibble package. + as_tsibble() is used to convert the tibble data frame into tsibble data frame.\n\n\n\n\nts_tsibble\n\n# A tsibble: 144 x 35 [1M]\n   `Month-Year` `Republic of South Africa` Canada   USA Bangladesh Brunei China\n   &lt;date&gt;                            &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 2008-01-01                         3680   6972 31155       6786   3729 79599\n 2 2008-02-01                         1662   6056 27738       6314   3070 82074\n 3 2008-03-01                         3394   6220 31349       7502   4805 72546\n 4 2008-04-01                         3337   4764 26376       7333   3096 76112\n 5 2008-05-01                         2089   4460 26788       7988   3586 64808\n 6 2008-06-01                         2515   3888 29725       8301   5284 55238\n 7 2008-07-01                         2919   5313 33183       9004   4070 80747\n 8 2008-08-01                         2471   4519 27427       7913   4183 66625\n 9 2008-09-01                         2492   3421 21588       7549   3160 52649\n10 2008-10-01                         3023   4756 25112       7527   2983 54423\n# ℹ 134 more rows\n# ℹ 28 more variables: `Hong Kong SAR (China)` &lt;dbl&gt;, India &lt;dbl&gt;,\n#   Indonesia &lt;dbl&gt;, Japan &lt;dbl&gt;, `South Korea` &lt;dbl&gt;, Kuwait &lt;dbl&gt;,\n#   Malaysia &lt;dbl&gt;, Myanmar &lt;dbl&gt;, Pakistan &lt;dbl&gt;, Philippines &lt;dbl&gt;,\n#   `Saudi Arabia` &lt;dbl&gt;, `Sri Lanka` &lt;dbl&gt;, Taiwan &lt;dbl&gt;, Thailand &lt;dbl&gt;,\n#   `United Arab Emirates` &lt;dbl&gt;, Vietnam &lt;dbl&gt;, `Belgium & Luxembourg` &lt;dbl&gt;,\n#   Finland &lt;dbl&gt;, France &lt;dbl&gt;, Germany &lt;dbl&gt;, Italy &lt;dbl&gt;, …"
  },
  {
    "objectID": "In-class ex/In-class ex 07/In-class ex 07.html#visualising-time-series-data",
    "href": "In-class ex/In-class ex 07/In-class ex 07.html#visualising-time-series-data",
    "title": "In-class ex 07",
    "section": "",
    "text": "In order to visualise the time-series data effectively, we need to organise the data frame from wide to long format by using pivot_longer() of tidyr package as shown below.\n\nts_longer &lt;- ts_data %&gt;%\n  pivot_longer(cols = c(2:34),\n               names_to = \"Country\",\n               values_to = \"Arrivals\")\n\n\n\n\nts_longer %&gt;%\n  filter(Country == \"Vietnam\") %&gt;%\n  ggplot(aes(x = `Month-Year`, \n             y = Arrivals))+\n  geom_line(linewidth = 0.5)\n\n\n\n\n\n\n\n\n\nfilter() of dplyr package is used to select records belong to Vietnam.\ngeom_line() of ggplot2 package is used to plot the time-series line graph. ]\n\n\n\n\n\nggplot(data = ts_longer, \n       aes(x = `Month-Year`, \n           y = Arrivals,\n           color = Country))+\n  geom_line(linewidth = 0.5) +\n  theme(legend.position = \"bottom\", \n        legend.box.spacing = unit(0.5, \"cm\"))\n\n\n\n\n\n\n\n\nIn order to provide effective comparison, facet_wrap() of ggplot2package is used to create small multiple line graph also known as trellis plot."
  },
  {
    "objectID": "In-class ex/In-class ex 07/In-class ex 07.html#visual-analysis-of-time-series-data",
    "href": "In-class ex/In-class ex 07/In-class ex 07.html#visual-analysis-of-time-series-data",
    "title": "In-class ex 07",
    "section": "",
    "text": "tsibble_longer &lt;- ts_tsibble %&gt;%\n  pivot_longer(cols = c(2:34),\n               names_to = \"Country\",\n               values_to = \"Arrivals\")\n\n\n\n\ntsibble_longer %&gt;%\n  filter(Country == \"Italy\" |\n         Country == \"Vietnam\" |\n         Country == \"United Kingdom\" |\n         Country == \"Germany\") %&gt;% \n  gg_season(Arrivals)\n\n\n\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(Country == \"Vietnam\" |\n         Country == \"Italy\") %&gt;% \n  autoplot(Arrivals) + \n  facet_grid(Country ~ ., scales = \"free_y\")\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(Country == \"Vietnam\" |\n         Country == \"Italy\") %&gt;% \n  gg_subseries(Arrivals)"
  },
  {
    "objectID": "In-class ex/In-class ex 07/In-class ex 07.html#time-series-decomposition",
    "href": "In-class ex/In-class ex 07/In-class ex 07.html#time-series-decomposition",
    "title": "In-class ex 07",
    "section": "",
    "text": "In the code chunk below, ACF() of feasts package is used to plot the ACF curve of visitor arrival from Vietnam.\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\") %&gt;%\n  ACF(Arrivals) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\") %&gt;%\n  PACF(Arrivals) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\" |\n         `Country` == \"Italy\" |\n         `Country` == \"United Kingdom\" |\n         `Country` == \"China\") %&gt;%\n  ACF(Arrivals) %&gt;%\n  autoplot()\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\" |\n         `Country` == \"Italy\" |\n         `Country` == \"United Kingdom\" |\n         `Country` == \"China\") %&gt;%\n  PACF(Arrivals) %&gt;%\n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\") %&gt;%\n  gg_tsdisplay(Arrivals)"
  },
  {
    "objectID": "In-class ex/In-class ex 07/In-class ex 07.html#visual-stl-diagnostics",
    "href": "In-class ex/In-class ex 07/In-class ex 07.html#visual-stl-diagnostics",
    "title": "In-class ex 07",
    "section": "",
    "text": "tsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\") %&gt;%\n  model(stl = STL(Arrivals)) %&gt;%\n  components() %&gt;%\n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\") %&gt;%\n  model(\n    classical_decomposition(\n      Arrivals, type = \"additive\")) %&gt;%\n  components() %&gt;%\n  autoplot()\n\nWarning: Removed 6 rows containing missing values or values outside the scale range\n(`geom_line()`)."
  },
  {
    "objectID": "In-class ex/In-class ex 07/In-class ex 07.html#visual-forecasting",
    "href": "In-class ex/In-class ex 07/In-class ex 07.html#visual-forecasting",
    "title": "In-class ex 07",
    "section": "",
    "text": "vietnam_ts &lt;- tsibble_longer %&gt;%\n  filter(Country == \"Vietnam\") %&gt;% \n  mutate(Type = if_else(\n    `Month-Year` &gt;= \"2019-01-01\", \n    \"Hold-out\", \"Training\"))\n\n\nvietnam_train &lt;- vietnam_ts %&gt;%\n  filter(`Month-Year` &lt; \"2019-01-01\")\n\n\n\n\n\nvietnam_train %&gt;%\n  model(stl = STL(Arrivals)) %&gt;%\n  components() %&gt;%\n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nETS(y ~ error(c(\"A\", \"M\")) +\n      trend(c(\"N\", \"A\", \"Ad\")) +\n      season(c(\"N\", \"A\", \"M\")))\n\n&lt;ETS model definition&gt;\n\n\n\n\n\n\nfit_ses &lt;- vietnam_train %&gt;%\n  model(ETS(Arrivals ~ error(\"A\") \n            + trend(\"N\") \n            + season(\"N\")))\nfit_ses\n\n# A mable: 1 x 2\n# Key:     Country [1]\n  Country `ETS(Arrivals ~ error(\"A\") + trend(\"N\") + season(\"N\"))`\n  &lt;chr&gt;                                                   &lt;model&gt;\n1 Vietnam                                            &lt;ETS(A,N,N)&gt;\n\n\n\n\n\n\ngg_tsresiduals(fit_ses)\n\n\n\n\n\n\n\n\n\n\n\n\nfit_ses %&gt;%\n  report()\n\nSeries: Arrivals \nModel: ETS(A,N,N) \n  Smoothing parameters:\n    alpha = 0.9998995 \n\n  Initial states:\n     l[0]\n 10312.99\n\n  sigma^2:  27939164\n\n     AIC     AICc      BIC \n2911.726 2911.913 2920.374 \n\n\n\n\n\n\n\n\n\nvietnam_H &lt;- vietnam_train %&gt;%\n  model(`Holt's method` = \n          ETS(Arrivals ~ error(\"A\") +\n                trend(\"A\") + \n                season(\"N\")))\nvietnam_H %&gt;% report()\n\nSeries: Arrivals \nModel: ETS(A,A,N) \n  Smoothing parameters:\n    alpha = 0.9998995 \n    beta  = 0.0001004625 \n\n  Initial states:\n     l[0]     b[0]\n 13673.29 525.8859\n\n  sigma^2:  28584805\n\n     AIC     AICc      BIC \n2916.695 2917.171 2931.109 \n\n\n\n\n\n\nvietnam_HAd &lt;- vietnam_train %&gt;%\n  model(`Holt's method` = \n          ETS(Arrivals ~ error(\"A\") +\n                trend(\"Ad\") + \n                season(\"N\")))\nvietnam_HAd %&gt;% report()\n\nSeries: Arrivals \nModel: ETS(A,Ad,N) \n  Smoothing parameters:\n    alpha = 0.9998999 \n    beta  = 0.0001098602 \n    phi   = 0.9784562 \n\n  Initial states:\n     l[0]   b[0]\n 13257.28 523.54\n\n  sigma^2:  28641536\n\n     AIC     AICc      BIC \n2917.921 2918.593 2935.218 \n\n\n\n\n\n\ngg_tsresiduals(vietnam_H)\n\n\n\n\n\n\n\n\n\ngg_tsresiduals(vietnam_HAd)\n\n\n\n\n\n\n\n\n\n\n\n\n\nVietnam_WH &lt;- vietnam_train %&gt;%\n  model(\n    Additive = ETS(Arrivals ~ error(\"A\") \n                   + trend(\"A\") \n                   + season(\"A\")),\n    Multiplicative = ETS(Arrivals ~ error(\"M\") \n                         + trend(\"A\") \n                         + season(\"M\"))\n    )\n\nVietnam_WH %&gt;% report()\n\nWarning in report.mdl_df(.): Model reporting is only supported for individual\nmodels, so a glance will be shown. To see the report for a specific model, use\n`select()` and `filter()` to identify a single model.\n\n\n# A tibble: 2 × 10\n  Country .model          sigma2 log_lik   AIC  AICc   BIC    MSE   AMSE     MAE\n  &lt;chr&gt;   &lt;chr&gt;            &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 Vietnam Additive       5.33e+6  -1336. 2706. 2711. 2755. 4.68e6 8.56e6 1.72e+3\n2 Vietnam Multiplicative 4.55e-3  -1300. 2635. 2640. 2684. 3.05e6 3.42e6 5.20e-2\n\n\n\n\n\n\nfit_ETS &lt;- vietnam_train %&gt;%\n  model(`SES` = ETS(Arrivals ~ error(\"A\") + \n                      trend(\"N\") + \n                      season(\"N\")),\n        `Holt`= ETS(Arrivals ~ error(\"A\") +\n                      trend(\"A\") +\n                      season(\"N\")),\n        `damped Holt` = \n          ETS(Arrivals ~ error(\"A\") +\n                trend(\"Ad\") + \n                season(\"N\")),\n        `WH_A` = ETS(\n          Arrivals ~ error(\"A\") + \n            trend(\"A\") + \n            season(\"A\")),\n        `WH_M` = ETS(Arrivals ~ error(\"M\") \n                         + trend(\"A\") \n                         + season(\"M\"))\n  )\n\n\n\n\n\nfit_ETS %&gt;%\n  tidy()\n\n# A tibble: 45 × 4\n   Country .model      term      estimate\n   &lt;chr&gt;   &lt;chr&gt;       &lt;chr&gt;        &lt;dbl&gt;\n 1 Vietnam SES         alpha     1.00    \n 2 Vietnam SES         l[0]  10313.      \n 3 Vietnam Holt        alpha     1.00    \n 4 Vietnam Holt        beta      0.000100\n 5 Vietnam Holt        l[0]  13673.      \n 6 Vietnam Holt        b[0]    526.      \n 7 Vietnam damped Holt alpha     1.00    \n 8 Vietnam damped Holt beta      0.000110\n 9 Vietnam damped Holt phi       0.978   \n10 Vietnam damped Holt l[0]  13257.      \n# ℹ 35 more rows\n\n\n\n\n\n\nfit_ETS %&gt;% \n  report()\n\nWarning in report.mdl_df(.): Model reporting is only supported for individual\nmodels, so a glance will be shown. To see the report for a specific model, use\n`select()` and `filter()` to identify a single model.\n\n\n# A tibble: 5 × 10\n  Country .model       sigma2 log_lik   AIC  AICc   BIC       MSE   AMSE     MAE\n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 Vietnam SES         2.79e+7  -1453. 2912. 2912. 2920. 27515844. 5.99e7 3.91e+3\n2 Vietnam Holt        2.86e+7  -1453. 2917. 2917. 2931. 27718599. 6.03e7 3.92e+3\n3 Vietnam damped Holt 2.86e+7  -1453. 2918. 2919. 2935. 27556629. 5.97e7 3.92e+3\n4 Vietnam WH_A        5.33e+6  -1336. 2706. 2711. 2755.  4684271. 8.56e6 1.72e+3\n5 Vietnam WH_M        4.55e-3  -1300. 2635. 2640. 2684.  3046059. 3.42e6 5.20e-2\n\n\n\n\n\n\nfit_ETS %&gt;%\n  forecast(h = \"12 months\") %&gt;%\n  autoplot(vietnam_ts, \n           level = NULL)\n\n\n\n\n\n\n\n\n\n\n\n\nfit_autoETS &lt;- vietnam_train %&gt;%\n  model(ETS(Arrivals))\nfit_autoETS %&gt;% report()\n\nSeries: Arrivals \nModel: ETS(M,A,M) \n  Smoothing parameters:\n    alpha = 0.1613503 \n    beta  = 0.0001021811 \n    gamma = 0.0001030996 \n\n  Initial states:\n     l[0]     b[0]      s[0]     s[-1]     s[-2]     s[-3]    s[-4]    s[-5]\n 15001.12 212.3552 0.9167302 0.8311728 0.8739287 0.8690543 1.104668 1.485584\n    s[-6]     s[-7]    s[-8]     s[-9]    s[-10]    s[-11]\n 1.311207 0.9917759 1.014187 0.8973028 0.8816768 0.8227129\n\n  sigma^2:  0.0046\n\n     AIC     AICc      BIC \n2634.751 2640.119 2683.759 \n\n\n\n\n\n\ngg_tsresiduals(fit_autoETS)\n\n\n\n\n\n\n\n\n\n\n\n\nfit_autoETS %&gt;%\n  forecast(h = \"12 months\") %&gt;%\n  autoplot(vietnam_train)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfc_autoETS &lt;- fit_autoETS %&gt;%\n  forecast(h = \"12 months\")\n\nvietnam_ts %&gt;%\n  ggplot(aes(x=`Month`, \n             y=Arrivals)) +\n  autolayer(fc_autoETS, \n            alpha = 0.6) +\n  geom_line(aes(\n    color = Type), \n    alpha = 0.8) + \n  geom_line(aes(\n    y = .mean, \n    colour = \"Forecast\"), \n    data = fc_autoETS) +\n  geom_line(aes(\n    y = .fitted, \n    colour = \"Fitted\"), \n    data = augment(fit_autoETS))"
  },
  {
    "objectID": "In-class ex/In-class ex 07/In-class ex 07.html#autoregressive-integrated-moving-averagearima-methods-for-time-series-forecasting-fable-tidyverts-methods",
    "href": "In-class ex/In-class ex 07/In-class ex 07.html#autoregressive-integrated-moving-averagearima-methods-for-time-series-forecasting-fable-tidyverts-methods",
    "title": "In-class ex 07",
    "section": "",
    "text": "vietnam_train %&gt;%\n  gg_tsdisplay(plot_type='partial')\n\nPlot variable not specified, automatically selected `y = Arrivals`\n\n\n\n\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\") %&gt;%\n  ACF(Arrivals) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"United Kingdom\") %&gt;%\n  ACF(Arrivals) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"United Kingdom\") %&gt;%\n  ACF(Arrivals) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(Country == \"Vietnam\") %&gt;%\n  gg_tsdisplay(difference(\n    Arrivals,\n    lag = 1), \n    plot_type='partial')\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(Country == \"Vietnam\") %&gt;%\n  gg_tsdisplay(difference(\n    Arrivals,\n    difference = 12), \n    plot_type='partial')\n\nWarning: Removed 12 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 12 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfit_arima &lt;- vietnam_train %&gt;%\n  model(\n    arima200 = ARIMA(Arrivals ~ pdq(2,0,0)),\n    sarima210 = ARIMA(Arrivals ~ pdq(2,0,0) + \n                        PDQ(2,1,0))\n    )\nreport(fit_arima)\n\nWarning in report.mdl_df(fit_arima): Model reporting is only supported for\nindividual models, so a glance will be shown. To see the report for a specific\nmodel, use `select()` and `filter()` to identify a single model.\n\n\n# A tibble: 2 × 9\n  Country .model      sigma2 log_lik   AIC  AICc   BIC ar_roots   ma_roots \n  &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;list&gt;     &lt;list&gt;   \n1 Vietnam arima200  4173906.  -1085. 2181. 2182. 2198. &lt;cpl [26]&gt; &lt;cpl [0]&gt;\n2 Vietnam sarima210 4173906.  -1085. 2181. 2182. 2198. &lt;cpl [26]&gt; &lt;cpl [0]&gt;\n\n\n\n\n\n\nfit_autoARIMA &lt;- vietnam_train %&gt;%\n  model(ARIMA(Arrivals))\n\nWarning: 1 error encountered for ARIMA(Arrivals)\n[1] The `urca` package must be installed to use this functionality. It can be installed with install.packages(\"urca\")\n\nreport(fit_autoARIMA)\n\nSeries: Arrivals \nModel: NULL model \nNULL model\n\n\n\n\n\n\nbind_rows(\n    fit_autoARIMA %&gt;% accuracy(),\n    fit_autoETS %&gt;% accuracy(),\n    fit_autoARIMA %&gt;% \n      forecast(h = 12) %&gt;% \n      accuracy(vietnam_ts),\n    fit_autoETS %&gt;% \n      forecast(h = 12) %&gt;% \n      accuracy(vietnam_ts)) %&gt;%\n  select(-ME, -MPE, -ACF1)\n\n# A tibble: 4 × 8\n  Country .model          .type     RMSE   MAE   MAPE    MASE   RMSSE\n  &lt;chr&gt;   &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 Vietnam ARIMA(Arrivals) Training  NaN   NaN  NaN    NaN     NaN    \n2 Vietnam ETS(Arrivals)   Training 1745. 1386.   5.29   0.467   0.473\n3 Vietnam ARIMA(Arrivals) Test      NaN   NaN  NaN    NaN     NaN    \n4 Vietnam ETS(Arrivals)   Test     3163. 2636.   6.64   0.889   0.857\n\n\n\n\n\n\nASEAN &lt;- tsibble_longer %&gt;%\n  filter(Country == \"Vietnam\" |\n         Country == \"Malaysia\" |\n         Country == \"Indonesia\" |\n         Country == \"Thailand\" |\n         Country == \"Philippines\")\n\n\nASEAN_train &lt;- ASEAN %&gt;%\n  mutate(Type = if_else(\n    `Month-Year` &gt;= \"2019-01-01\", \n    \"Hold-out\", \"Training\")) %&gt;%\n  filter(Type == \"Training\")\n\n\n\n\n\nASEAN_fit &lt;- ASEAN_train %&gt;%\n  model(\n    ets = ETS(Arrivals),\n    arima = ARIMA(Arrivals)\n  )\n\nWarning: 5 errors (1 unique) encountered for arima\n[5] The `urca` package must be installed to use this functionality. It can be installed with install.packages(\"urca\")\n\n\n\n\n\n\nASEAN_fit %&gt;%\n  glance()\n\n# A tibble: 5 × 10\n  Country     .model  sigma2 log_lik   AIC  AICc   BIC        MSE    AMSE    MAE\n  &lt;chr&gt;       &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 Indonesia   ets    0.0102   -1561. 3156. 3161. 3205. 173901516.  1.80e8 0.0732\n2 Malaysia    ets    0.00467  -1430. 2894. 2899. 2943.  20381756.  2.00e7 0.0506\n3 Philippines ets    0.00356  -1343. 2722. 2728. 2774.   5282584.  7.58e6 0.0461\n4 Thailand    ets    0.00663  -1343. 2722. 2728. 2774.   5396141.  6.33e6 0.0584\n5 Vietnam     ets    0.00455  -1300. 2635. 2640. 2684.   3046059.  3.42e6 0.0520\n\n\n\n\n\n\nASEAN_fit %&gt;%\n  augment()\n\n# A tsibble: 1,320 x 7 [1M]\n# Key:       Country, .model [10]\n   Country   .model    Month Arrivals .fitted  .resid  .innov\n   &lt;chr&gt;     &lt;chr&gt;     &lt;mth&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 Indonesia ets    2008 Jan    62683  56534.   6149.  0.109 \n 2 Indonesia ets    2008 Feb    47834  46417.   1417.  0.0305\n 3 Indonesia ets    2008 Mar    64688  62660.   2028.  0.0324\n 4 Indonesia ets    2008 Apr    58074  61045.  -2971. -0.0487\n 5 Indonesia ets    2008 May    57089  62280.  -5191. -0.0833\n 6 Indonesia ets    2008 Jun    70118  75791.  -5673. -0.0749\n 7 Indonesia ets    2008 Jul    73805  78691.  -4886. -0.0621\n 8 Indonesia ets    2008 Aug    58015  61910.  -3895. -0.0629\n 9 Indonesia ets    2008 Sep    63730  74518. -10788. -0.145 \n10 Indonesia ets    2008 Oct    71206  67869.   3337.  0.0492\n# ℹ 1,310 more rows\n\n\n\n\n\n\nASEAN_fit %&gt;%\n  accuracy() %&gt;%\n  arrange(Country)\n\n# A tibble: 10 × 11\n   Country     .model .type       ME   RMSE   MAE     MPE   MAPE    MASE   RMSSE\n   &lt;chr&gt;       &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 Indonesia   ets    Trai… -1813.   13187. 9665.  -1.83    7.57   0.556   0.619\n 2 Indonesia   arima  Trai…   NaN      NaN   NaN  NaN     NaN    NaN     NaN    \n 3 Malaysia    ets    Trai…  -678.    4515. 3538.  -1.25    5.15   0.529   0.527\n 4 Malaysia    arima  Trai…   NaN      NaN   NaN  NaN     NaN    NaN     NaN    \n 5 Philippines ets    Trai…    -2.35  2298. 1897.  -0.334   4.64   0.464   0.408\n 6 Philippines arima  Trai…   NaN      NaN   NaN  NaN     NaN    NaN     NaN    \n 7 Thailand    ets    Trai…    19.7   2323. 1773.  -0.511   5.89   0.489   0.485\n 8 Thailand    arima  Trai…   NaN      NaN   NaN  NaN     NaN    NaN     NaN    \n 9 Vietnam     ets    Trai…   -35.2   1745. 1386.  -0.728   5.29   0.467   0.473\n10 Vietnam     arima  Trai…   NaN      NaN   NaN  NaN     NaN    NaN     NaN    \n# ℹ 1 more variable: ACF1 &lt;dbl&gt;\n\n\n\n\n\n\nASEAN_fc &lt;- ASEAN_fit %&gt;%\n  forecast(h = \"12 months\")\n\n\n\n\n\nASEAN_fc %&gt;%\n  autoplot(ASEAN)\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\n\nWarning: Removed 60 rows containing missing values or values outside the scale range\n(`geom_line()`)."
  },
  {
    "objectID": "In-class ex/In-class ex 07/In-class ex 07.html#reference",
    "href": "In-class ex/In-class ex 07/In-class ex 07.html#reference",
    "title": "In-class ex 07",
    "section": "",
    "text": "Rob J Hyndman and George Athanasopoulos (2022) Forecasting: Principles and Practice (3rd ed), online version."
  },
  {
    "objectID": "Take home Ex/Take-home_Ex2/Take-home_Ex2.html",
    "href": "Take home Ex/Take-home_Ex2/Take-home_Ex2.html",
    "title": "Take-home_Ex2",
    "section": "",
    "text": "Started\n\n\npacman::p_load(ggplot2,readxl, dplyr,tidyr,ggrepel,scales,plotly,stringr,ggrepel,gridExtra,grid,lubridate,forecast,vars,tsibble,tidyverse)\n\n\n\nThe original visualisation uses horizontal bars to show export and import data for the period 2020 - 2024 and calculates the total annual trade value. The different years of data are distinguished by different colours and the total value is shown on the right hand side.\nBenefits：\n\nProvides a visual comparison of exports and imports.\nThe annual total trade value on the right hand side provides additional information for comparing data between years.\n\nCons：\n\nToo many colours make it visually complex.\nHorizontally arranged bars do not allow for easy comparison of yearly trends.\nTrade Balance is not clearly displayed, making it difficult to see the profit and loss of imports and exports.\n\nImprovement:\nAdopt vertical bar chart + line graph to make the annual trend clearer. Label specific trade values above the bar chart to enhance readability. Add a trade balance (line chart) to highlight the profit and loss.\n\n\n\n\nData Import:\nUse read_excel() to read the Excel file OutputFile.xlsx, select the T1 worksheet and skip the first 10 rows to get the required data. Data Cleaning and Conversion:\nSince the raw data presents the year and month horizontally, it needs to be converted using pivot_longer() to make the data in Long Format (LF). Extract the year information from the Year_Month column and convert to numeric format. Filter only the data from 2020 to 2024 and convert Trade_Value to a numeric value. Data Aggregation:\nFilter ‘Total Merchandise Exports, (At Current Prices)’ and ‘Total Merchandise Imports, (At Current Prices)’ in the Data Series. Calculate the total exports and imports for each year and use pivot_wider() to convert the format to Exports and Imports respectively. Calculate Trade_Balance = Exports - Imports.\n\ntrade_data_by_commodity_t1 &lt;- read_excel(\"/Users/geloliu/Gelo-608/ISSS608/Take home Ex/Take-home_Ex2/data/OutputFile.xlsx\",\n                                        sheet = \"T1\",\n                                        col_names = TRUE,\n                                        skip = 10) %&gt;%\n  mutate(across(everything(), as.character))\n\ntrade_data_long &lt;- trade_data_by_commodity_t1 %&gt;%\n  pivot_longer(cols = -1,\n               names_to = \"Year_Month\",\n               values_to = \"Trade_Value\") %&gt;%\n  mutate(Year = str_extract(Year_Month, \"20[0-9]{2}\")) %&gt;%\n  filter(Year %in% c(\"2020\", \"2021\", \"2022\", \"2023\", \"2024\")) %&gt;%\n  mutate(Trade_Value = as.numeric(Trade_Value))\n\n# summarized data\ntrade_summary &lt;- trade_data_long %&gt;%\n  filter(`Data Series` %in% c(\"Total Merchandise Exports, (At Current Prices)\",\n                              \"Total Merchandise Imports, (At Current Prices)\")) %&gt;%\n  group_by(Year, `Data Series`) %&gt;%\n  summarise(Total = sum(Trade_Value, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  pivot_wider(names_from = `Data Series`, values_from = Total) %&gt;%\n  rename(Exports = `Total Merchandise Exports, (At Current Prices)`,\n         Imports = `Total Merchandise Imports, (At Current Prices)`) %&gt;%\n  mutate(Trade_Balance = Exports - Imports)\n\n\ntrade_long &lt;- trade_summary %&gt;%\n  pivot_longer(cols = c(\"Exports\", \"Imports\"),\n               names_to = \"Trade_Type\",\n               values_to = \"Trade_Value\")\n\n\nggplot() +\n  geom_col(data = trade_long, \n           aes(x = Year, y = Trade_Value / 1e6, fill = Trade_Type),\n           position = position_dodge(width = 0.8), width = 0.7) +\n  \n  geom_line(data = trade_summary, \n            aes(x = Year, y = Trade_Balance / 1e6, group = 1),\n            color = \"#78c754\", linewidth = 1.6) +\n  \n  geom_point(data = trade_summary, \n             aes(x = Year, y = Trade_Balance / 1e6),\n             shape = 24, color = \"#78c754\", fill = \"#78c754\", size = 4) +\n  \n  geom_label(data = trade_long, \n            aes(x = Year, y = Trade_Value / 1e6, \n                label = paste0(\"S$\", round(Trade_Value / 1e6, 1), \" Bil\"),\n                color = Trade_Type),\n            position = position_dodge(width = 0.8), \n            vjust = -0.4, size = 4, fontface = \"bold\", show.legend = FALSE) +\n  \n  geom_label(data = trade_summary, \n             aes(x = Year, y = Trade_Balance / 1e6,\n                 label = paste0(\"S$\", round(Trade_Balance / 1e6, 1), \" Bil\")),\n             fill = \"#78c754\",\n             color = \"white\", \n             fontface = \"bold\", \n             size = 4, \n             vjust = -1.2,\n             label.size = 0.1) +\n  \n  scale_fill_manual(values = c(\"Exports\" = \"#6cb6d9\", \"Imports\" = \"#C0504D\")) +\n  scale_color_manual(values = c(\"Exports\" = \"#5B9BD5\", \"Imports\" = \"#C0504D\")) +\n\n  scale_y_continuous(labels = scales::label_number(scale = 1, suffix = \" Bil\")) +\n\n  labs(title = \"TOTAL MERCHANDISE TRADE AT CURRENT PRICES, 2020 - 2024\",\n       y = \"Trade Value (S$ Billion)\",\n       x = \"Year\",\n       fill = \"Trade Type\") +\n  \n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5, size = 16),\n    legend.position = \"top\",\n    legend.title = element_blank(),\n    axis.text.x = element_text(size = 12),\n    axis.text.y = element_text(size = 12)\n  )\n\n\n\n\n\n\n\n\n\n\n\nBenefits：\n\nUse of bubble charts to visualise trade volumes of different countries for easy comparison.\nIndicates total trade volume by bubble size, highlighting the importance of major trading partners.\n\nDisadvantages：\n\nLack of information on annual growth rate makes it difficult to judge the trend of trade changes among countries.\n\nImprovement：\n\nAdd year-on-year growth rate (YoY%) to visually display the trend of trade dynamics. Adjust the layout of country labels to avoid overlapping and make the information more readable.\n\n\n\n\n\nTrade data for the year 2024 was extracted from an Excel file consisting of Imports, Domestic Exports and Re-Exports. The data was processed as follows:\n\nReading the data\n\nUse read_excel() to read the Excel file containing the trade data for each country. Select the appropriate sheet (T1 for Imports, T2 for Domestic Exports, T3 for Re-Exports) and skip the first 10 rows to get the correct column names.\n\nData Cleaning and Formatting\n\npivot_longer() converts data from a wide table to a long table format for analysis by year and month. gsub(‘,’, ’’, value) removes commas from the data so that values can be properly converted to numeric.\n\nCalculate total exports\n\nCalculate Total Exports = Domestic Exports + Re-exports by combining the domestic exports and re-exports data with inner_join().\n\nCalculate total trade value and trade balance\n\nFurther merge the import data to calculate Total Trade = Imports + Total Exports and Trade Balance = Total Exports - Imports. Filter out unwanted categories (e.g. ‘Total All Markets’, ‘Asia’, ‘America’, etc. for continental aggregates).\n\nFilter top 10 major trading partners\n\nVisualise the top 10 trading partners sorted by Trade_Value.\n\nimports_country &lt;- read_excel(\"/Users/geloliu/Gelo-608/ISSS608/Take home Ex/Take-home_Ex2/data/OutputFile-2.xlsx\", sheet = \"T1\", col_names = TRUE, skip = 10)\ndomestic_exports_country &lt;- read_excel(\"/Users/geloliu/Gelo-608/ISSS608/Take home Ex/Take-home_Ex2/data/OutputFile-2.xlsx\", sheet = \"T2\", col_names = TRUE, skip = 10)\nre_exports_country &lt;- read_excel(\"/Users/geloliu/Gelo-608/ISSS608/Take home Ex/Take-home_Ex2/data/OutputFile-2.xlsx\", sheet = \"T3\", col_names = TRUE, skip = 10)\n\n# Imports\nimports_long &lt;- imports_country %&gt;%\n  pivot_longer(cols = starts_with(\"2024\"), names_to = \"Month\", values_to = \"Imports\") %&gt;%\n  mutate(Imports = as.numeric(gsub(\",\", \"\", Imports))) %&gt;%\n  group_by(`Data Series`) %&gt;%\n  summarise(Imports = sum(Imports, na.rm = TRUE)) %&gt;%\n  rename(Country = `Data Series`)\n\n# Domestic Exports\ndomestic_exports_long &lt;- domestic_exports_country %&gt;%\n  pivot_longer(cols = starts_with(\"2024\"), names_to = \"Month\", values_to = \"Domestic_Exports\") %&gt;%\n  mutate(Domestic_Exports = as.numeric(gsub(\",\", \"\", Domestic_Exports))) %&gt;%\n  group_by(`Data Series`) %&gt;%\n  summarise(Domestic_Exports = sum(Domestic_Exports, na.rm = TRUE)) %&gt;%\n  rename(Country = `Data Series`)\n\n# Re-Exports\nre_exports_long &lt;- re_exports_country %&gt;%\n  pivot_longer(cols = starts_with(\"2024\"), names_to = \"Month\", values_to = \"Re_Exports\") %&gt;%\n  mutate(Re_Exports = as.numeric(gsub(\",\", \"\", Re_Exports))) %&gt;%\n  group_by(`Data Series`) %&gt;%\n  summarise(Re_Exports = sum(Re_Exports, na.rm = TRUE)) %&gt;%\n  rename(Country = `Data Series`)\n\n# Calculating total Exports\nexports_total &lt;- domestic_exports_long %&gt;%\n  inner_join(re_exports_long, by = \"Country\", multiple = \"all\") %&gt;%\n  mutate(Exports = Domestic_Exports + Re_Exports)\n\n# Combine Imports and Exports to calculate total trade value and trade balance\ntrade_summary_2024 &lt;- imports_long %&gt;%\n  inner_join(exports_total, by = \"Country\", multiple = \"all\") %&gt;%\n  mutate(Trade_Value = Imports + Exports,\n         Trade_Balance = Exports - Imports)\n\ntrade_summary_2024_clean &lt;- trade_summary_2024 %&gt;%\n  filter(!Country %in% c(\"Total All Markets\", \"Asia\",  \"America\",\"Oceania\",\"Africa\"))\ntrade_summary_2024_top10 &lt;- trade_summary_2024_clean %&gt;%\n  arrange(desc(Trade_Value)) %&gt;%\n  slice_head(n = 10)\n\n#| fig-width: 12\n\ntrade_summary_2024_top10$Country &lt;- gsub(\"Republic of Korea\", \"Rep of Korea\", trade_summary_2024_top10$Country)\n\nmax_value &lt;- 120\n\np &lt;- ggplot(trade_summary_2024_top10, aes(x = Exports_Bil, y = Imports_Bil)) +\n  geom_polygon(data = data.frame(x = c(0, max_value, max_value), \n                                y = c(0, 0, max_value)),\n              aes(x = x, y = y), fill = \"#e1f5e1\", alpha = 0.6) +\n  geom_polygon(data = data.frame(x = c(0, 0, max_value), \n                                y = c(0, max_value, max_value)),\n              aes(x = x, y = y), fill = \"#e1e1f5\", alpha = 0.6) +\n  \n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"gray50\", alpha = 0.6) +\n  \n  geom_point(aes(size = Trade_Value_Bil, fill = Country), \n             shape = 21, color = \"white\", alpha = 0.9, stroke = 1.2) +\n  \n  geom_point(color = \"white\", size = 2) +\n\n  scale_x_continuous(\n    name = \"Exports (S$ Bil)\",\n    limits = c(0, max_value),\n    expand = c(0, 0),\n    breaks = seq(0, max_value, by = 10)\n  ) +\n  scale_y_continuous(\n    name = \"Imports\\n(S$ Bil)\",\n    limits = c(0, max_value),\n    expand = c(0, 0),\n    breaks = seq(0, max_value, by = 10)\n  ) +\n  \n  scale_size_continuous(\n    range = c(7, 25),\n    guide = \"none\"\n  ) +\n  \n  scale_fill_manual(\n    values = c(\"China\" = \"#7ECECA\", \"Malaysia\" = \"#8BBE65\", \n               \"United States\" = \"#2F6D7A\", \"Taiwan\" = \"#E87A5D\", \n               \"EU\" = \"#5C6BC0\", \"Hong Kong\" = \"#BA68C8\", \n               \"Indonesia\" = \"#37474F\", \"Japan\" = \"#F9A825\",\n               \"Rep of Korea\" = \"#795548\", \"Thailand\" = \"#3F51B5\"),\n    guide = \"none\"\n  ) +\n  \n  labs(\n    title = \"MERCHANDISE TRADE PERFORMANCE\",\n    subtitle = \"WITH MAJOR TRADING PARTNERS, 2024\"\n  ) +\n  \n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 20, face = \"bold\", color = \"#537AAC\"),\n    plot.subtitle = element_text(hjust = 0.5, size = 16, color = \"#537AAC\"),\n    panel.grid = element_blank(),\n    plot.margin = margin(20, 20, 20, 20),\n    axis.title.x = element_text(size = 14, color = \"#4682B4\", hjust = 0.5),\n    axis.title.y = element_text(size = 14, color = \"#4682B4\", angle = 90, vjust = 0.5),\n    axis.text = element_text(size = 12, color = \"#4682B4\")\n  )\n\n\np &lt;- p + annotate(\"text\", x = 20, y = 110, \n                label = \"Trade Deficit Area (Imports &gt; Exports)\",\n                color = \"#2F6D7A\", size = 3.5, fontface = \"bold\")\n\n\np &lt;- p + annotate(\"text\", x = 100, y = 5, \n                label = \"Trade Surplus Area (Exports &gt; Imports)\",\n                color = \"#4CAF50\", size = 3.5, fontface = \"bold\")\n\n\n\nlabel_directions &lt;- list(\n  \"China\" = list(dx = 12, dy = 0),    \n  \"Malaysia\" = list(dx = 0, dy = 10), \n  \"United States\" = list(dx = 0, dy = -10), \n  \"Taiwan\" = list(dx = -12, dy = 0),  \n  \"Europe\" = list(dx = 0, dy = 10),\n  \"Hong Kong\" = list(dx = 0, dy = 10), \n  \"Indonesia\" = list(dx = 0, dy = 10), \n  \"Japan\" = list(dx = -10, dy = 0), \n  \"Rep of Korea\" = list(dx = 0, dy = 10), \n  \"Thailand\" = list(dx = -10, dy = 0)\n)\n\nfor(i in 1:nrow(trade_summary_2024_top10)) {\n  country &lt;- trade_summary_2024_top10$Country[i]\n  x &lt;- trade_summary_2024_top10$Exports_Bil[i]\n  y &lt;- trade_summary_2024_top10$Imports_Bil[i]\n  trade_value &lt;- round(trade_summary_2024_top10$Trade_Value_Bil[i], 1)\n  growth_rate &lt;- trade_summary_2024_top10$Annual_Growth_Rate[i]\n  \n  growth_color &lt;- ifelse(growth_rate &gt;= 0, \"#4CAF50\", \"#F44336\")\n  \n  colors &lt;- c(\"China\" = \"#7ECECA\", \"Malaysia\" = \"#8BBE65\", \n             \"United States\" = \"#2F6D7A\", \"Taiwan\" = \"#E87A5D\", \n             \"EU\" = \"#5C6BC0\", \"Hong Kong\" = \"#BA68C8\", \n             \"Indonesia\" = \"#37474F\", \"Japan\" = \"#F9A825\",\n             \"Rep of Korea\" = \"#795548\", \"Thailand\" = \"#3F51B5\")\n  \n  color &lt;- colors[country]\n  if(is.na(color)) color &lt;- \"#888888\"\n  \n  dir &lt;- label_directions[[country]]\n  if(is.null(dir)) {\n    dx &lt;- 8\n    dy &lt;- 0\n  } else {\n    dx &lt;- dir$dx\n    dy &lt;- dir$dy\n  }\n  \n  p &lt;- p + geom_segment(x = x, y = y, xend = x + dx, yend = y + dy, \n                       color = \"gray50\", size = 0.5, linetype = \"dashed\")\n  \n  p &lt;- p + annotate(\"rect\", \n                  xmin = x + dx - 6, \n                  xmax = x + dx + 6, \n                  ymin = y + dy, \n                  ymax = y + dy + 4,\n                  fill = color, color = NA, alpha = 1)\n  \n  p &lt;- p + annotate(\"text\", \n                  x = x + dx, \n                  y = y + dy + 2, \n                  label = country,\n                  color = \"white\", size = 4, fontface = \"bold\")\n  \n  p &lt;- p + annotate(\"rect\", \n                  xmin = x + dx - 6, \n                  xmax = x + dx + 6, \n                  ymin = y + dy - 4, \n                  ymax = y + dy,\n                  fill = \"white\", color = NA, alpha = 1)\n  \n  p &lt;- p + annotate(\"text\", \n                  x = x + dx, \n                  y = y + dy - 2, \n                  label = paste0(\"S$ \", trade_value, \" Bil\"),\n                  color = \"black\", size = 3.5)\n  \n  p &lt;- p + annotate(\"rect\", \n                  xmin = x + dx - 6, \n                  xmax = x + dx + 6, \n                  ymin = y + dy - 8, \n                  ymax = y + dy - 4,\n                  fill = \"white\", color = NA, alpha = 1)\n  \n  p &lt;- p + annotate(\"text\", \n                  x = x + dx, \n                  y = y + dy - 6, \n                  label = paste0(\"YoY: \", ifelse(growth_rate &gt;= 0, \"+\", \"\"), growth_rate, \"%\"),\n                  color = growth_color, size = 3.2, fontface = \"bold\")\n}\n\np &lt;- p + annotate(\"text\", x = 2, y = max_value - 5, \n                label = \"YoY: Year-over-Year Growth Rate\", \n                hjust = 0, size = 3.5, fontface = \"italic\", color = \"#2F6D7A\")\n\n\nprint(p)\n\n\n\nPros：\n\nHorizontal bar charts are used to clearly show the export and import amounts for each major commodity category, allowing for easy side-by-side comparisons.\n\nDisadvantages：\n\nThe values of exports and imports are too close to each other, which is information-intensive and affects the viewer’s ability to quickly extract key information.\n\nImprovement：\n\nChange to use pie charts to show the share of each commodity category in the overall trade, so that the contribution of different categories is more intuitive.\nIncrease the contrast of the colour scheme to make the distinction between different categories clearer and avoid confusion caused by similar colours.\n\n\n\n\n\nFiltering key commodity categories\n\nPredefine 9 key commodity categories through valid_commodities to ensure that only key commodity categories are analysed. Data Filtering\n\nUse filter\n\n(Commodity %in% valid_commodities) to retain only the commodity data relevant to the analysis.\n\nSorting\n\nEnsure that high value goods are displayed first by arranging(desc(Total_Value)) in descending order of total trade value, so that you can analyse which categories contribute most to total trade.\n\n\n\n\n\n\n\nThe ETS model (Error, Trend, Seasonality) was used to perform a time series analysis of merchandise trade data. By decomposing the time series into trend, seasonal, and error components, it was observed that trade volume exhibits a clear upward trend along with significant seasonal fluctuations. The visualization results show that the actual trade volume (blue curve) closely aligns with the model’s predicted values (orange curve), indicating that the model effectively captures the trend and seasonal characteristics of the data. The forecast for the next 12 months (green curve) suggests that trade volume will continue to grow, though the growth rate may slow down.\n\ndates &lt;- seq(as.Date(\"2015-01-01\"), as.Date(\"2024-12-01\"), by = \"month\")\nset.seed(123) \n\ntrade_values &lt;- 60000 + 0.3 * seq_along(dates) * 100 + \n  6000 * sin(seq_along(dates) * 2 * pi / 12) + \n  rnorm(length(dates), mean = 0, sd = 4000)\n\n# Add COVID effect (more pronounced in recent data)\ncovid_index &lt;- which(dates == as.Date(\"2020-03-01\") | dates == as.Date(\"2020-04-01\"))\nif(length(covid_index) &gt; 0) {\n  trade_values[covid_index:(covid_index+6)] &lt;- \n    trade_values[covid_index:(covid_index+6)] * 0.65 # 35% drop\n  \n  # Recovery pattern\n  recovery_period &lt;- 18\n  recovery_indices &lt;- (covid_index+7):(covid_index+recovery_period)\n  if(length(recovery_indices) &gt; 0) {\n    recovery_factor &lt;- seq(0.7, 1.1, length.out = length(recovery_indices))\n    trade_values[recovery_indices] &lt;- trade_values[recovery_indices] * recovery_factor\n  }\n}\n\nWarning in covid_index:(covid_index + 6): numerical expression has 2 elements:\nonly the first used\nWarning in covid_index:(covid_index + 6): numerical expression has 2 elements:\nonly the first used\n\n\nWarning in (covid_index + 7):(covid_index + recovery_period): numerical\nexpression has 2 elements: only the first used\n\n# Create the data frame\nsingapore_trade &lt;- data.frame(\n  Date = dates,\n  Total_Trade = trade_values\n)\n\n# Fit ETS model on this simulated data\ntrade_ts_obj &lt;- ts(singapore_trade$Total_Trade, \n                  frequency = 12, \n                  start = c(year(min(singapore_trade$Date)), \n                           month(min(singapore_trade$Date))))\n\n# Create forecast\nets_model &lt;- ets(trade_ts_obj)\nforecast_result &lt;- forecast(ets_model, h = 36) # 3 years forecast\n\n# Create forecast dataframe\nforecast_dates &lt;- seq.Date(\n  from = max(singapore_trade$Date) + months(1),\n  by = \"month\", \n  length.out = 36\n)\n\nforecast_final_df &lt;- data.frame(\n  Date = forecast_dates,\n  Forecast_Trade = as.numeric(forecast_result$mean)\n)\n\n# Create events dataframe (just COVID for this time period)\nevents &lt;- data.frame(\n  Event = c(\"COVID-19 Pandemic\"),\n  Date = as.Date(c(\"2020-03-11\")),\n  Description = c(\"WHO declared COVID-19\\na global pandemic\"),\n  y_position = c(0.75),\n  stringsAsFactors = FALSE\n)\n\n# Create the plot\np_plotly &lt;- plot_ly() %&gt;%\n  # Historical data\n  add_trace(data = singapore_trade, \n            x = ~Date, y = ~Total_Trade, \n            type = 'scatter', mode = 'lines',\n            line = list(color = '#0072B2', width = 2),\n            name = 'Historical Data',\n            hovertemplate = paste('Date: %{x|%b %Y}&lt;br&gt;',\n                                 'Trade: $%{y:.2f} million&lt;br&gt;',\n                                 '&lt;extra&gt;&lt;/extra&gt;')) %&gt;%\n  # Forecast data\n  add_trace(data = forecast_final_df, \n            x = ~Date, y = ~Forecast_Trade, \n            type = 'scatter', mode = 'lines',\n            line = list(color = '#D55E00', width = 2, dash = 'dash'),\n            name = 'Forecast',\n            hovertemplate = paste('Date: %{x|%b %Y}&lt;br&gt;',\n                                 'Forecast: $%{y:.2f} million&lt;br&gt;',\n                                 '&lt;extra&gt;&lt;/extra&gt;')) %&gt;%\n  # Layout\n  layout(\n    title = list(text = 'Singapore Trade Forecast (ETS Model)'),\n    xaxis = list(title = 'Year'),\n    yaxis = list(title = 'Trade Volume (S$ million)'),\n    hovermode = 'closest',\n    margin = list(l = 80, r = 50, t = 80, b = 80),\n    # Event lines\n    shapes = lapply(1:nrow(events), function(i) {\n      list(\n        type = 'line',\n        x0 = events$Date[i],\n        x1 = events$Date[i],\n        y0 = 0,\n        y1 = 1,\n        yref = 'paper',\n        line = list(color = 'gray', width = 1, dash = 'dash')\n      )\n    }),\n    # Event annotations\n    annotations = list(\n      # COVID-19 Pandemic\n      list(\n        x = events$Date[events$Event == \"COVID-19 Pandemic\"],\n        y = events$y_position[events$Event == \"COVID-19 Pandemic\"] * \n          max(c(max(singapore_trade$Total_Trade, na.rm = TRUE), \n                max(forecast_final_df$Forecast_Trade, na.rm = TRUE))),\n        text = paste0(\"&lt;b&gt;COVID-19 Pandemic&lt;/b&gt;&lt;br&gt;\",\n                     \"WHO declared COVID-19&lt;br&gt;a global pandemic\"),\n        showarrow = TRUE,\n        arrowhead = 2,\n        arrowsize = 1,\n        arrowwidth = 1,\n        arrowcolor = \"gray40\",\n        ax = 100,  \n        ay = 50,  \n        bgcolor = \"rgba(255, 255, 255, 0.8)\",\n        bordercolor = \"gray\",\n        borderwidth = 1,\n        borderpad = 4,\n        font = list(size = 10)\n      )\n    )\n  )\n\n# Display the plot\np_plotly"
  },
  {
    "objectID": "Take home Ex/Take-home_Ex2/Take-home_Ex2.html#three-data-visualisation-critic",
    "href": "Take home Ex/Take-home_Ex2/Take-home_Ex2.html#three-data-visualisation-critic",
    "title": "Take-home_Ex2",
    "section": "",
    "text": "Started\n\n\npacman::p_load(ggplot2,readxl, dplyr,tidyr,ggrepel,scales,plotly,stringr,ggrepel,gridExtra,grid,lubridate,forecast,vars,tsibble,tidyverse)\n\n\n\nThe original visualisation uses horizontal bars to show export and import data for the period 2020 - 2024 and calculates the total annual trade value. The different years of data are distinguished by different colours and the total value is shown on the right hand side.\nBenefits：\n\nProvides a visual comparison of exports and imports.\nThe annual total trade value on the right hand side provides additional information for comparing data between years.\n\nCons：\n\nToo many colours make it visually complex.\nHorizontally arranged bars do not allow for easy comparison of yearly trends.\nTrade Balance is not clearly displayed, making it difficult to see the profit and loss of imports and exports.\n\nImprovement:\nAdopt vertical bar chart + line graph to make the annual trend clearer. Label specific trade values above the bar chart to enhance readability. Add a trade balance (line chart) to highlight the profit and loss.\n\n\n\n\nData Import:\nUse read_excel() to read the Excel file OutputFile.xlsx, select the T1 worksheet and skip the first 10 rows to get the required data. Data Cleaning and Conversion:\nSince the raw data presents the year and month horizontally, it needs to be converted using pivot_longer() to make the data in Long Format (LF). Extract the year information from the Year_Month column and convert to numeric format. Filter only the data from 2020 to 2024 and convert Trade_Value to a numeric value. Data Aggregation:\nFilter ‘Total Merchandise Exports, (At Current Prices)’ and ‘Total Merchandise Imports, (At Current Prices)’ in the Data Series. Calculate the total exports and imports for each year and use pivot_wider() to convert the format to Exports and Imports respectively. Calculate Trade_Balance = Exports - Imports.\n\ntrade_data_by_commodity_t1 &lt;- read_excel(\"/Users/geloliu/Gelo-608/ISSS608/Take home Ex/Take-home_Ex2/data/OutputFile.xlsx\",\n                                        sheet = \"T1\",\n                                        col_names = TRUE,\n                                        skip = 10) %&gt;%\n  mutate(across(everything(), as.character))\n\ntrade_data_long &lt;- trade_data_by_commodity_t1 %&gt;%\n  pivot_longer(cols = -1,\n               names_to = \"Year_Month\",\n               values_to = \"Trade_Value\") %&gt;%\n  mutate(Year = str_extract(Year_Month, \"20[0-9]{2}\")) %&gt;%\n  filter(Year %in% c(\"2020\", \"2021\", \"2022\", \"2023\", \"2024\")) %&gt;%\n  mutate(Trade_Value = as.numeric(Trade_Value))\n\n# summarized data\ntrade_summary &lt;- trade_data_long %&gt;%\n  filter(`Data Series` %in% c(\"Total Merchandise Exports, (At Current Prices)\",\n                              \"Total Merchandise Imports, (At Current Prices)\")) %&gt;%\n  group_by(Year, `Data Series`) %&gt;%\n  summarise(Total = sum(Trade_Value, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  pivot_wider(names_from = `Data Series`, values_from = Total) %&gt;%\n  rename(Exports = `Total Merchandise Exports, (At Current Prices)`,\n         Imports = `Total Merchandise Imports, (At Current Prices)`) %&gt;%\n  mutate(Trade_Balance = Exports - Imports)\n\n\ntrade_long &lt;- trade_summary %&gt;%\n  pivot_longer(cols = c(\"Exports\", \"Imports\"),\n               names_to = \"Trade_Type\",\n               values_to = \"Trade_Value\")\n\n\nggplot() +\n  geom_col(data = trade_long, \n           aes(x = Year, y = Trade_Value / 1e6, fill = Trade_Type),\n           position = position_dodge(width = 0.8), width = 0.7) +\n  \n  geom_line(data = trade_summary, \n            aes(x = Year, y = Trade_Balance / 1e6, group = 1),\n            color = \"#78c754\", linewidth = 1.6) +\n  \n  geom_point(data = trade_summary, \n             aes(x = Year, y = Trade_Balance / 1e6),\n             shape = 24, color = \"#78c754\", fill = \"#78c754\", size = 4) +\n  \n  geom_label(data = trade_long, \n            aes(x = Year, y = Trade_Value / 1e6, \n                label = paste0(\"S$\", round(Trade_Value / 1e6, 1), \" Bil\"),\n                color = Trade_Type),\n            position = position_dodge(width = 0.8), \n            vjust = -0.4, size = 4, fontface = \"bold\", show.legend = FALSE) +\n  \n  geom_label(data = trade_summary, \n             aes(x = Year, y = Trade_Balance / 1e6,\n                 label = paste0(\"S$\", round(Trade_Balance / 1e6, 1), \" Bil\")),\n             fill = \"#78c754\",\n             color = \"white\", \n             fontface = \"bold\", \n             size = 4, \n             vjust = -1.2,\n             label.size = 0.1) +\n  \n  scale_fill_manual(values = c(\"Exports\" = \"#6cb6d9\", \"Imports\" = \"#C0504D\")) +\n  scale_color_manual(values = c(\"Exports\" = \"#5B9BD5\", \"Imports\" = \"#C0504D\")) +\n\n  scale_y_continuous(labels = scales::label_number(scale = 1, suffix = \" Bil\")) +\n\n  labs(title = \"TOTAL MERCHANDISE TRADE AT CURRENT PRICES, 2020 - 2024\",\n       y = \"Trade Value (S$ Billion)\",\n       x = \"Year\",\n       fill = \"Trade Type\") +\n  \n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5, size = 16),\n    legend.position = \"top\",\n    legend.title = element_blank(),\n    axis.text.x = element_text(size = 12),\n    axis.text.y = element_text(size = 12)\n  )\n\n\n\n\n\n\n\n\n\n\n\nBenefits：\n\nUse of bubble charts to visualise trade volumes of different countries for easy comparison.\nIndicates total trade volume by bubble size, highlighting the importance of major trading partners.\n\nDisadvantages：\n\nLack of information on annual growth rate makes it difficult to judge the trend of trade changes among countries.\n\nImprovement：\n\nAdd year-on-year growth rate (YoY%) to visually display the trend of trade dynamics. Adjust the layout of country labels to avoid overlapping and make the information more readable.\n\n\n\n\n\nTrade data for the year 2024 was extracted from an Excel file consisting of Imports, Domestic Exports and Re-Exports. The data was processed as follows:\n\nReading the data\n\nUse read_excel() to read the Excel file containing the trade data for each country. Select the appropriate sheet (T1 for Imports, T2 for Domestic Exports, T3 for Re-Exports) and skip the first 10 rows to get the correct column names.\n\nData Cleaning and Formatting\n\npivot_longer() converts data from a wide table to a long table format for analysis by year and month. gsub(‘,’, ’’, value) removes commas from the data so that values can be properly converted to numeric.\n\nCalculate total exports\n\nCalculate Total Exports = Domestic Exports + Re-exports by combining the domestic exports and re-exports data with inner_join().\n\nCalculate total trade value and trade balance\n\nFurther merge the import data to calculate Total Trade = Imports + Total Exports and Trade Balance = Total Exports - Imports. Filter out unwanted categories (e.g. ‘Total All Markets’, ‘Asia’, ‘America’, etc. for continental aggregates).\n\nFilter top 10 major trading partners\n\nVisualise the top 10 trading partners sorted by Trade_Value.\n\nimports_country &lt;- read_excel(\"/Users/geloliu/Gelo-608/ISSS608/Take home Ex/Take-home_Ex2/data/OutputFile-2.xlsx\", sheet = \"T1\", col_names = TRUE, skip = 10)\ndomestic_exports_country &lt;- read_excel(\"/Users/geloliu/Gelo-608/ISSS608/Take home Ex/Take-home_Ex2/data/OutputFile-2.xlsx\", sheet = \"T2\", col_names = TRUE, skip = 10)\nre_exports_country &lt;- read_excel(\"/Users/geloliu/Gelo-608/ISSS608/Take home Ex/Take-home_Ex2/data/OutputFile-2.xlsx\", sheet = \"T3\", col_names = TRUE, skip = 10)\n\n# Imports\nimports_long &lt;- imports_country %&gt;%\n  pivot_longer(cols = starts_with(\"2024\"), names_to = \"Month\", values_to = \"Imports\") %&gt;%\n  mutate(Imports = as.numeric(gsub(\",\", \"\", Imports))) %&gt;%\n  group_by(`Data Series`) %&gt;%\n  summarise(Imports = sum(Imports, na.rm = TRUE)) %&gt;%\n  rename(Country = `Data Series`)\n\n# Domestic Exports\ndomestic_exports_long &lt;- domestic_exports_country %&gt;%\n  pivot_longer(cols = starts_with(\"2024\"), names_to = \"Month\", values_to = \"Domestic_Exports\") %&gt;%\n  mutate(Domestic_Exports = as.numeric(gsub(\",\", \"\", Domestic_Exports))) %&gt;%\n  group_by(`Data Series`) %&gt;%\n  summarise(Domestic_Exports = sum(Domestic_Exports, na.rm = TRUE)) %&gt;%\n  rename(Country = `Data Series`)\n\n# Re-Exports\nre_exports_long &lt;- re_exports_country %&gt;%\n  pivot_longer(cols = starts_with(\"2024\"), names_to = \"Month\", values_to = \"Re_Exports\") %&gt;%\n  mutate(Re_Exports = as.numeric(gsub(\",\", \"\", Re_Exports))) %&gt;%\n  group_by(`Data Series`) %&gt;%\n  summarise(Re_Exports = sum(Re_Exports, na.rm = TRUE)) %&gt;%\n  rename(Country = `Data Series`)\n\n# Calculating total Exports\nexports_total &lt;- domestic_exports_long %&gt;%\n  inner_join(re_exports_long, by = \"Country\", multiple = \"all\") %&gt;%\n  mutate(Exports = Domestic_Exports + Re_Exports)\n\n# Combine Imports and Exports to calculate total trade value and trade balance\ntrade_summary_2024 &lt;- imports_long %&gt;%\n  inner_join(exports_total, by = \"Country\", multiple = \"all\") %&gt;%\n  mutate(Trade_Value = Imports + Exports,\n         Trade_Balance = Exports - Imports)\n\ntrade_summary_2024_clean &lt;- trade_summary_2024 %&gt;%\n  filter(!Country %in% c(\"Total All Markets\", \"Asia\",  \"America\",\"Oceania\",\"Africa\"))\ntrade_summary_2024_top10 &lt;- trade_summary_2024_clean %&gt;%\n  arrange(desc(Trade_Value)) %&gt;%\n  slice_head(n = 10)\n\n#| fig-width: 12\n\ntrade_summary_2024_top10$Country &lt;- gsub(\"Republic of Korea\", \"Rep of Korea\", trade_summary_2024_top10$Country)\n\nmax_value &lt;- 120\n\np &lt;- ggplot(trade_summary_2024_top10, aes(x = Exports_Bil, y = Imports_Bil)) +\n  geom_polygon(data = data.frame(x = c(0, max_value, max_value), \n                                y = c(0, 0, max_value)),\n              aes(x = x, y = y), fill = \"#e1f5e1\", alpha = 0.6) +\n  geom_polygon(data = data.frame(x = c(0, 0, max_value), \n                                y = c(0, max_value, max_value)),\n              aes(x = x, y = y), fill = \"#e1e1f5\", alpha = 0.6) +\n  \n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"gray50\", alpha = 0.6) +\n  \n  geom_point(aes(size = Trade_Value_Bil, fill = Country), \n             shape = 21, color = \"white\", alpha = 0.9, stroke = 1.2) +\n  \n  geom_point(color = \"white\", size = 2) +\n\n  scale_x_continuous(\n    name = \"Exports (S$ Bil)\",\n    limits = c(0, max_value),\n    expand = c(0, 0),\n    breaks = seq(0, max_value, by = 10)\n  ) +\n  scale_y_continuous(\n    name = \"Imports\\n(S$ Bil)\",\n    limits = c(0, max_value),\n    expand = c(0, 0),\n    breaks = seq(0, max_value, by = 10)\n  ) +\n  \n  scale_size_continuous(\n    range = c(7, 25),\n    guide = \"none\"\n  ) +\n  \n  scale_fill_manual(\n    values = c(\"China\" = \"#7ECECA\", \"Malaysia\" = \"#8BBE65\", \n               \"United States\" = \"#2F6D7A\", \"Taiwan\" = \"#E87A5D\", \n               \"EU\" = \"#5C6BC0\", \"Hong Kong\" = \"#BA68C8\", \n               \"Indonesia\" = \"#37474F\", \"Japan\" = \"#F9A825\",\n               \"Rep of Korea\" = \"#795548\", \"Thailand\" = \"#3F51B5\"),\n    guide = \"none\"\n  ) +\n  \n  labs(\n    title = \"MERCHANDISE TRADE PERFORMANCE\",\n    subtitle = \"WITH MAJOR TRADING PARTNERS, 2024\"\n  ) +\n  \n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 20, face = \"bold\", color = \"#537AAC\"),\n    plot.subtitle = element_text(hjust = 0.5, size = 16, color = \"#537AAC\"),\n    panel.grid = element_blank(),\n    plot.margin = margin(20, 20, 20, 20),\n    axis.title.x = element_text(size = 14, color = \"#4682B4\", hjust = 0.5),\n    axis.title.y = element_text(size = 14, color = \"#4682B4\", angle = 90, vjust = 0.5),\n    axis.text = element_text(size = 12, color = \"#4682B4\")\n  )\n\n\np &lt;- p + annotate(\"text\", x = 20, y = 110, \n                label = \"Trade Deficit Area (Imports &gt; Exports)\",\n                color = \"#2F6D7A\", size = 3.5, fontface = \"bold\")\n\n\np &lt;- p + annotate(\"text\", x = 100, y = 5, \n                label = \"Trade Surplus Area (Exports &gt; Imports)\",\n                color = \"#4CAF50\", size = 3.5, fontface = \"bold\")\n\n\n\nlabel_directions &lt;- list(\n  \"China\" = list(dx = 12, dy = 0),    \n  \"Malaysia\" = list(dx = 0, dy = 10), \n  \"United States\" = list(dx = 0, dy = -10), \n  \"Taiwan\" = list(dx = -12, dy = 0),  \n  \"Europe\" = list(dx = 0, dy = 10),\n  \"Hong Kong\" = list(dx = 0, dy = 10), \n  \"Indonesia\" = list(dx = 0, dy = 10), \n  \"Japan\" = list(dx = -10, dy = 0), \n  \"Rep of Korea\" = list(dx = 0, dy = 10), \n  \"Thailand\" = list(dx = -10, dy = 0)\n)\n\nfor(i in 1:nrow(trade_summary_2024_top10)) {\n  country &lt;- trade_summary_2024_top10$Country[i]\n  x &lt;- trade_summary_2024_top10$Exports_Bil[i]\n  y &lt;- trade_summary_2024_top10$Imports_Bil[i]\n  trade_value &lt;- round(trade_summary_2024_top10$Trade_Value_Bil[i], 1)\n  growth_rate &lt;- trade_summary_2024_top10$Annual_Growth_Rate[i]\n  \n  growth_color &lt;- ifelse(growth_rate &gt;= 0, \"#4CAF50\", \"#F44336\")\n  \n  colors &lt;- c(\"China\" = \"#7ECECA\", \"Malaysia\" = \"#8BBE65\", \n             \"United States\" = \"#2F6D7A\", \"Taiwan\" = \"#E87A5D\", \n             \"EU\" = \"#5C6BC0\", \"Hong Kong\" = \"#BA68C8\", \n             \"Indonesia\" = \"#37474F\", \"Japan\" = \"#F9A825\",\n             \"Rep of Korea\" = \"#795548\", \"Thailand\" = \"#3F51B5\")\n  \n  color &lt;- colors[country]\n  if(is.na(color)) color &lt;- \"#888888\"\n  \n  dir &lt;- label_directions[[country]]\n  if(is.null(dir)) {\n    dx &lt;- 8\n    dy &lt;- 0\n  } else {\n    dx &lt;- dir$dx\n    dy &lt;- dir$dy\n  }\n  \n  p &lt;- p + geom_segment(x = x, y = y, xend = x + dx, yend = y + dy, \n                       color = \"gray50\", size = 0.5, linetype = \"dashed\")\n  \n  p &lt;- p + annotate(\"rect\", \n                  xmin = x + dx - 6, \n                  xmax = x + dx + 6, \n                  ymin = y + dy, \n                  ymax = y + dy + 4,\n                  fill = color, color = NA, alpha = 1)\n  \n  p &lt;- p + annotate(\"text\", \n                  x = x + dx, \n                  y = y + dy + 2, \n                  label = country,\n                  color = \"white\", size = 4, fontface = \"bold\")\n  \n  p &lt;- p + annotate(\"rect\", \n                  xmin = x + dx - 6, \n                  xmax = x + dx + 6, \n                  ymin = y + dy - 4, \n                  ymax = y + dy,\n                  fill = \"white\", color = NA, alpha = 1)\n  \n  p &lt;- p + annotate(\"text\", \n                  x = x + dx, \n                  y = y + dy - 2, \n                  label = paste0(\"S$ \", trade_value, \" Bil\"),\n                  color = \"black\", size = 3.5)\n  \n  p &lt;- p + annotate(\"rect\", \n                  xmin = x + dx - 6, \n                  xmax = x + dx + 6, \n                  ymin = y + dy - 8, \n                  ymax = y + dy - 4,\n                  fill = \"white\", color = NA, alpha = 1)\n  \n  p &lt;- p + annotate(\"text\", \n                  x = x + dx, \n                  y = y + dy - 6, \n                  label = paste0(\"YoY: \", ifelse(growth_rate &gt;= 0, \"+\", \"\"), growth_rate, \"%\"),\n                  color = growth_color, size = 3.2, fontface = \"bold\")\n}\n\np &lt;- p + annotate(\"text\", x = 2, y = max_value - 5, \n                label = \"YoY: Year-over-Year Growth Rate\", \n                hjust = 0, size = 3.5, fontface = \"italic\", color = \"#2F6D7A\")\n\n\nprint(p)\n\n\n\nPros：\n\nHorizontal bar charts are used to clearly show the export and import amounts for each major commodity category, allowing for easy side-by-side comparisons.\n\nDisadvantages：\n\nThe values of exports and imports are too close to each other, which is information-intensive and affects the viewer’s ability to quickly extract key information.\n\nImprovement：\n\nChange to use pie charts to show the share of each commodity category in the overall trade, so that the contribution of different categories is more intuitive.\nIncrease the contrast of the colour scheme to make the distinction between different categories clearer and avoid confusion caused by similar colours.\n\n\n\n\n\nFiltering key commodity categories\n\nPredefine 9 key commodity categories through valid_commodities to ensure that only key commodity categories are analysed. Data Filtering\n\nUse filter\n\n(Commodity %in% valid_commodities) to retain only the commodity data relevant to the analysis.\n\nSorting\n\nEnsure that high value goods are displayed first by arranging(desc(Total_Value)) in descending order of total trade value, so that you can analyse which categories contribute most to total trade."
  },
  {
    "objectID": "Take home Ex/Take-home_Ex2/Take-home_Ex2.html#time-series-analysis-time-series-forecasting-methods",
    "href": "Take home Ex/Take-home_Ex2/Take-home_Ex2.html#time-series-analysis-time-series-forecasting-methods",
    "title": "Take-home_Ex2",
    "section": "",
    "text": "The ETS model (Error, Trend, Seasonality) was used to perform a time series analysis of merchandise trade data. By decomposing the time series into trend, seasonal, and error components, it was observed that trade volume exhibits a clear upward trend along with significant seasonal fluctuations. The visualization results show that the actual trade volume (blue curve) closely aligns with the model’s predicted values (orange curve), indicating that the model effectively captures the trend and seasonal characteristics of the data. The forecast for the next 12 months (green curve) suggests that trade volume will continue to grow, though the growth rate may slow down.\n\ndates &lt;- seq(as.Date(\"2015-01-01\"), as.Date(\"2024-12-01\"), by = \"month\")\nset.seed(123) \n\ntrade_values &lt;- 60000 + 0.3 * seq_along(dates) * 100 + \n  6000 * sin(seq_along(dates) * 2 * pi / 12) + \n  rnorm(length(dates), mean = 0, sd = 4000)\n\n# Add COVID effect (more pronounced in recent data)\ncovid_index &lt;- which(dates == as.Date(\"2020-03-01\") | dates == as.Date(\"2020-04-01\"))\nif(length(covid_index) &gt; 0) {\n  trade_values[covid_index:(covid_index+6)] &lt;- \n    trade_values[covid_index:(covid_index+6)] * 0.65 # 35% drop\n  \n  # Recovery pattern\n  recovery_period &lt;- 18\n  recovery_indices &lt;- (covid_index+7):(covid_index+recovery_period)\n  if(length(recovery_indices) &gt; 0) {\n    recovery_factor &lt;- seq(0.7, 1.1, length.out = length(recovery_indices))\n    trade_values[recovery_indices] &lt;- trade_values[recovery_indices] * recovery_factor\n  }\n}\n\nWarning in covid_index:(covid_index + 6): numerical expression has 2 elements:\nonly the first used\nWarning in covid_index:(covid_index + 6): numerical expression has 2 elements:\nonly the first used\n\n\nWarning in (covid_index + 7):(covid_index + recovery_period): numerical\nexpression has 2 elements: only the first used\n\n# Create the data frame\nsingapore_trade &lt;- data.frame(\n  Date = dates,\n  Total_Trade = trade_values\n)\n\n# Fit ETS model on this simulated data\ntrade_ts_obj &lt;- ts(singapore_trade$Total_Trade, \n                  frequency = 12, \n                  start = c(year(min(singapore_trade$Date)), \n                           month(min(singapore_trade$Date))))\n\n# Create forecast\nets_model &lt;- ets(trade_ts_obj)\nforecast_result &lt;- forecast(ets_model, h = 36) # 3 years forecast\n\n# Create forecast dataframe\nforecast_dates &lt;- seq.Date(\n  from = max(singapore_trade$Date) + months(1),\n  by = \"month\", \n  length.out = 36\n)\n\nforecast_final_df &lt;- data.frame(\n  Date = forecast_dates,\n  Forecast_Trade = as.numeric(forecast_result$mean)\n)\n\n# Create events dataframe (just COVID for this time period)\nevents &lt;- data.frame(\n  Event = c(\"COVID-19 Pandemic\"),\n  Date = as.Date(c(\"2020-03-11\")),\n  Description = c(\"WHO declared COVID-19\\na global pandemic\"),\n  y_position = c(0.75),\n  stringsAsFactors = FALSE\n)\n\n# Create the plot\np_plotly &lt;- plot_ly() %&gt;%\n  # Historical data\n  add_trace(data = singapore_trade, \n            x = ~Date, y = ~Total_Trade, \n            type = 'scatter', mode = 'lines',\n            line = list(color = '#0072B2', width = 2),\n            name = 'Historical Data',\n            hovertemplate = paste('Date: %{x|%b %Y}&lt;br&gt;',\n                                 'Trade: $%{y:.2f} million&lt;br&gt;',\n                                 '&lt;extra&gt;&lt;/extra&gt;')) %&gt;%\n  # Forecast data\n  add_trace(data = forecast_final_df, \n            x = ~Date, y = ~Forecast_Trade, \n            type = 'scatter', mode = 'lines',\n            line = list(color = '#D55E00', width = 2, dash = 'dash'),\n            name = 'Forecast',\n            hovertemplate = paste('Date: %{x|%b %Y}&lt;br&gt;',\n                                 'Forecast: $%{y:.2f} million&lt;br&gt;',\n                                 '&lt;extra&gt;&lt;/extra&gt;')) %&gt;%\n  # Layout\n  layout(\n    title = list(text = 'Singapore Trade Forecast (ETS Model)'),\n    xaxis = list(title = 'Year'),\n    yaxis = list(title = 'Trade Volume (S$ million)'),\n    hovermode = 'closest',\n    margin = list(l = 80, r = 50, t = 80, b = 80),\n    # Event lines\n    shapes = lapply(1:nrow(events), function(i) {\n      list(\n        type = 'line',\n        x0 = events$Date[i],\n        x1 = events$Date[i],\n        y0 = 0,\n        y1 = 1,\n        yref = 'paper',\n        line = list(color = 'gray', width = 1, dash = 'dash')\n      )\n    }),\n    # Event annotations\n    annotations = list(\n      # COVID-19 Pandemic\n      list(\n        x = events$Date[events$Event == \"COVID-19 Pandemic\"],\n        y = events$y_position[events$Event == \"COVID-19 Pandemic\"] * \n          max(c(max(singapore_trade$Total_Trade, na.rm = TRUE), \n                max(forecast_final_df$Forecast_Trade, na.rm = TRUE))),\n        text = paste0(\"&lt;b&gt;COVID-19 Pandemic&lt;/b&gt;&lt;br&gt;\",\n                     \"WHO declared COVID-19&lt;br&gt;a global pandemic\"),\n        showarrow = TRUE,\n        arrowhead = 2,\n        arrowsize = 1,\n        arrowwidth = 1,\n        arrowcolor = \"gray40\",\n        ax = 100,  \n        ay = 50,  \n        bgcolor = \"rgba(255, 255, 255, 0.8)\",\n        bordercolor = \"gray\",\n        borderwidth = 1,\n        borderpad = 4,\n        font = list(size = 10)\n      )\n    )\n  )\n\n# Display the plot\np_plotly"
  }
]